2023-10-07 02:19:30,679 - root -INFO -I am inside the Main method
2023-10-07 02:19:30,679 - root -INFO -calling spark object
2023-10-07 02:19:30,679 - Create_spark -INFO -get_spark_object method started
2023-10-07 02:19:30,679 - Create_spark -INFO -master is local
2023-10-07 02:19:34,371 - root -INFO -Validating spark object.....
2023-10-07 02:19:34,371 - Validate -WARNING -started the get_current_date method...
2023-10-07 02:19:37,400 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 7))]
2023-10-07 02:19:37,400 - Validate -WARNING -Validation done go frwd...
2023-10-07 02:19:37,400 - root -INFO -Reading file format : parquet
2023-10-07 02:19:37,400 - Ingest -WARNING -load_files method started...
2023-10-07 02:19:37,927 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-07 02:19:37,931 - root -INFO -Displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-10-07 02:19:39,494 - root -INFO -validating the dataframe...
2023-10-07 02:19:39,494 - Ingest -WARNING -here to count the records in the df_city
2023-10-07 02:19:39,877 - Ingest -WARNING -number of records 28338 :: 
2023-10-07 02:19:39,877 - root -INFO -Reading file format : csv
2023-10-07 02:19:39,877 - Ingest -WARNING -load_files method started...
2023-10-07 02:19:43,802 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-07 02:19:43,806 - root -INFO -Displaying the dataframe DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string]
2023-10-07 02:19:44,076 - root -INFO -validating the dataframe...
2023-10-07 02:19:44,076 - Ingest -WARNING -here to count the records in the df_fact
2023-10-07 02:19:44,623 - Ingest -WARNING -number of records 1329329 :: 
2023-10-07 02:19:44,623 - root -INFO -Application done
2023-10-07 03:53:26,314 - root -INFO -i am in the main method..
2023-10-07 03:53:26,314 - root -INFO -calling spark object
2023-10-07 03:53:26,314 - Create_spark -INFO -get_spark_object method started
2023-10-07 03:53:26,314 - Create_spark -INFO -master is local
2023-10-07 03:53:42,116 - root -INFO -Validating spark object..........
2023-10-07 03:53:42,116 - Validate -WARNING -started the get_current_date method...
2023-10-07 03:53:46,104 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 7))]
2023-10-07 03:53:46,104 - Validate -WARNING -Validation done go frwd...
2023-10-07 03:53:46,105 - root -INFO -reading file which is of > parquet
2023-10-07 03:53:46,105 - Ingest -WARNING -load_files method started...
2023-10-07 03:53:46,627 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-07 03:53:46,627 - root -INFO -displaying file
2023-10-07 03:53:48,376 - root -INFO -here to validate the df
2023-10-07 03:53:48,376 - Ingest -WARNING -here to count the records in the df_city
2023-10-07 03:53:48,927 - Ingest -WARNING -number of records 28338 :: 
2023-10-07 03:53:48,927 - root -INFO -checking for the files in the Fact...
2023-10-07 03:55:45,834 - root -INFO -i am in the main method..
2023-10-07 03:55:45,834 - root -INFO -calling spark object
2023-10-07 03:55:45,834 - Create_spark -INFO -get_spark_object method started
2023-10-07 03:55:45,834 - Create_spark -INFO -master is local
2023-10-07 03:55:49,636 - root -INFO -Validating spark object..........
2023-10-07 03:55:49,637 - Validate -WARNING -started the get_current_date method...
2023-10-07 03:55:53,333 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 7))]
2023-10-07 03:55:53,335 - Validate -WARNING -Validation done go frwd...
2023-10-07 03:55:53,335 - root -INFO -reading file which is of > parquet
2023-10-07 03:55:53,335 - Ingest -WARNING -load_files method started...
2023-10-07 03:55:53,987 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-07 03:55:53,987 - root -INFO -displaying file
2023-10-07 03:55:56,970 - root -INFO -here to validate the df
2023-10-07 03:55:56,970 - Ingest -WARNING -here to count the records in the df_city
2023-10-07 03:55:58,131 - Ingest -WARNING -number of records 28338 :: 
2023-10-07 03:55:58,132 - root -INFO -checking for the files in the Fact...
2023-10-07 03:55:58,132 - root -INFO -reading file which is of > csv
2023-10-07 03:55:58,133 - Ingest -WARNING -load_files method started...
2023-10-07 03:56:06,100 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-07 03:56:06,100 - root -INFO -displaying the df_fact dataframe
2023-10-07 03:56:06,360 - Ingest -WARNING -here to count the records in the df_fact
2023-10-07 03:56:06,896 - Ingest -WARNING -number of records 1329329 :: 
2023-10-07 03:56:06,896 - root -INFO -implementing data_processing methods...
2023-10-07 03:56:06,896 - Data_processing -WARNING -data_clean method started...
2023-10-07 03:56:06,896 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-07 03:56:06,931 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-07 03:56:06,951 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-07 03:56:07,241 - root -INFO -validating schema for the dataframes....
2023-10-07 03:56:07,348 - root -INFO -Application done
2023-10-07 04:01:01,072 - root -INFO -i am in the main method..
2023-10-07 04:01:01,073 - root -INFO -calling spark object
2023-10-07 04:01:01,073 - Create_spark -INFO -get_spark_object method started
2023-10-07 04:01:01,073 - Create_spark -INFO -master is local
2023-10-07 04:01:04,997 - root -INFO -Validating spark object..........
2023-10-07 04:01:04,998 - Validate -WARNING -started the get_current_date method...
2023-10-07 04:01:08,297 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 7))]
2023-10-07 04:01:08,297 - Validate -WARNING -Validation done go frwd...
2023-10-07 04:01:08,298 - root -INFO -reading file which is of > parquet
2023-10-07 04:01:08,298 - Ingest -WARNING -load_files method started...
2023-10-07 04:01:08,959 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-07 04:01:08,959 - root -INFO -displaying file
2023-10-07 04:01:10,839 - root -INFO -here to validate the df
2023-10-07 04:01:10,839 - Ingest -WARNING -here to count the records in the df_city
2023-10-07 04:01:11,307 - Ingest -WARNING -number of records 28338 :: 
2023-10-07 04:01:11,307 - root -INFO -checking for the files in the Fact...
2023-10-07 04:01:11,307 - root -INFO -reading file which is of > csv
2023-10-07 04:01:11,307 - Ingest -WARNING -load_files method started...
2023-10-07 04:01:15,361 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-07 04:01:15,361 - root -INFO -displaying the df_fact dataframe
2023-10-07 04:01:15,613 - Ingest -WARNING -here to count the records in the df_fact
2023-10-07 04:01:16,145 - Ingest -WARNING -number of records 1329329 :: 
2023-10-07 04:01:16,146 - root -INFO -implementing data_processing methods...
2023-10-07 04:01:16,146 - Data_processing -WARNING -data_clean method started...
2023-10-07 04:01:16,146 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-07 04:01:16,180 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-07 04:01:16,204 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-07 04:01:16,217 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-07 04:01:16,542 - root -INFO -validating schema for the dataframes....
2023-10-07 04:01:16,624 - root -INFO -Application done
2023-10-07 04:12:13,258 - root -INFO -i am in the main method..
2023-10-07 04:12:13,258 - root -INFO -calling spark object
2023-10-07 04:12:13,258 - Create_spark -INFO -get_spark_object method started
2023-10-07 04:12:13,258 - Create_spark -INFO -master is local
2023-10-07 04:12:17,064 - root -INFO -Validating spark object..........
2023-10-07 04:12:17,064 - Validate -WARNING -started the get_current_date method...
2023-10-07 04:12:20,288 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 7))]
2023-10-07 04:12:20,288 - Validate -WARNING -Validation done go frwd...
2023-10-07 04:12:20,288 - root -INFO -reading file which is of > parquet
2023-10-07 04:12:20,288 - Ingest -WARNING -load_files method started...
2023-10-07 04:12:20,917 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-07 04:12:20,917 - root -INFO -displaying file
2023-10-07 04:12:23,366 - root -INFO -here to validate the df
2023-10-07 04:12:23,367 - Ingest -WARNING -here to count the records in the df_city
2023-10-07 04:12:24,887 - Ingest -WARNING -number of records 28338 :: 
2023-10-07 04:12:24,887 - root -INFO -checking for the files in the Fact...
2023-10-07 04:12:24,887 - root -INFO -reading file which is of > csv
2023-10-07 04:12:24,888 - Ingest -WARNING -load_files method started...
2023-10-07 04:12:38,493 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-07 04:12:38,493 - root -INFO -displaying the df_fact dataframe
2023-10-07 04:12:39,220 - Ingest -WARNING -here to count the records in the df_fact
2023-10-07 04:12:40,598 - Ingest -WARNING -number of records 1329329 :: 
2023-10-07 04:12:40,598 - root -INFO -implementing data_processing methods...
2023-10-07 04:12:40,598 - Data_processing -WARNING -data_clean method started...
2023-10-07 04:12:40,598 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-07 04:12:40,639 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-07 04:12:40,664 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-07 04:12:40,681 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-07 04:12:41,860 - root -INFO -validating schema for the dataframes....
2023-10-07 04:12:41,861 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-07 04:12:41,875 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-07 04:12:41,875 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-07 04:12:41,876 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-07 04:12:41,877 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-07 04:12:41,877 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-07 04:12:41,877 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-07 04:12:41,877 - Validate -INFO -print_schema done, go frwd...
2023-10-07 04:12:41,877 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('presc_lname', StringType(), True)
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('presc_fname', StringType(), True)
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-07 04:12:41,880 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-07 04:12:41,881 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-07 04:12:41,881 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-07 04:12:41,881 - Validate -INFO -	StructField('years_of_exp', StringType(), True)
2023-10-07 04:12:41,881 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-07 04:12:41,881 - Validate -INFO -print_schema done, go frwd...
2023-10-07 04:12:41,881 - root -INFO -Application done
2023-10-07 22:26:57,966 - root -INFO -i am in the main method..
2023-10-07 22:26:57,967 - root -INFO -calling spark object
2023-10-07 22:26:57,967 - Create_spark -INFO -get_spark_object method started
2023-10-07 22:26:57,967 - Create_spark -INFO -master is local
2023-10-07 22:27:16,857 - root -INFO -Validating spark object..........
2023-10-07 22:27:16,857 - Validate -WARNING -started the get_current_date method...
2023-10-07 22:27:23,382 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 7))]
2023-10-07 22:27:23,382 - Validate -WARNING -Validation done go frwd...
2023-10-07 22:27:23,382 - root -INFO -reading file which is of > parquet
2023-10-07 22:27:23,382 - Ingest -WARNING -load_files method started...
2023-10-07 22:27:25,168 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-07 22:27:25,168 - root -INFO -displaying file
2023-10-07 22:27:30,431 - root -INFO -here to validate the df
2023-10-07 22:27:30,432 - Ingest -WARNING -here to count the records in the df_city
2023-10-07 22:27:31,706 - Ingest -WARNING -number of records 28338 :: 
2023-10-07 22:27:31,706 - root -INFO -checking for the files in the Fact...
2023-10-07 22:27:31,707 - root -INFO -reading file which is of > csv
2023-10-07 22:27:31,707 - Ingest -WARNING -load_files method started...
2023-10-07 22:27:44,804 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-07 22:27:44,804 - root -INFO -displaying the df_fact dataframe
2023-10-07 22:27:45,480 - Ingest -WARNING -here to count the records in the df_fact
2023-10-07 22:27:47,175 - Ingest -WARNING -number of records 1329329 :: 
2023-10-07 22:27:47,176 - root -INFO -implementing data_processing methods...
2023-10-07 22:27:47,176 - Data_processing -WARNING -data_clean method started...
2023-10-07 22:27:47,176 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-07 22:27:47,262 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-07 22:27:47,334 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-07 22:27:47,361 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-07 22:27:47,443 - Data_processing -WARNING -Concat fname and lname...
2023-10-07 22:27:47,479 - Data_processing -WARNING -Dropping fname and lname...
2023-10-07 22:27:47,504 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-07 22:27:48,438 - root -INFO -validating schema for the dataframes....
2023-10-07 22:27:48,439 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-07 22:27:48,444 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-07 22:27:48,444 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-07 22:27:48,444 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-07 22:27:48,445 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-07 22:27:48,445 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-07 22:27:48,445 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-07 22:27:48,445 - Validate -INFO -print_schema done, go frwd...
2023-10-07 22:27:48,445 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-07 22:27:48,448 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-07 22:27:48,448 - Validate -INFO -print_schema done, go frwd...
2023-10-07 22:27:48,449 - root -INFO -Application done
2023-10-08 02:19:13,066 - root -INFO -i am in the main method..
2023-10-08 02:19:13,067 - root -INFO -calling spark object
2023-10-08 02:19:13,067 - Create_spark -INFO -get_spark_object method started
2023-10-08 02:19:13,067 - Create_spark -INFO -master is local
2023-10-08 02:19:17,820 - root -INFO -Validating spark object..........
2023-10-08 02:19:17,820 - Validate -WARNING -started the get_current_date method...
2023-10-08 02:19:21,547 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 02:19:21,547 - Validate -WARNING -Validation done go frwd...
2023-10-08 02:19:21,547 - root -INFO -reading file which is of > parquet
2023-10-08 02:19:21,547 - Ingest -WARNING -load_files method started...
2023-10-08 02:19:22,196 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 02:19:22,197 - root -INFO -displaying file
2023-10-08 02:19:24,124 - root -INFO -here to validate the df
2023-10-08 02:19:24,124 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 02:19:24,662 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 02:19:24,662 - root -INFO -checking for the files in the Fact...
2023-10-08 02:19:24,662 - root -INFO -reading file which is of > csv
2023-10-08 02:19:24,662 - Ingest -WARNING -load_files method started...
2023-10-08 02:19:28,842 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 02:19:28,843 - root -INFO -displaying the df_fact dataframe
2023-10-08 02:19:29,087 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 02:19:29,682 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 02:19:29,682 - root -INFO -implementing data_processing methods...
2023-10-08 02:19:29,682 - Data_processing -WARNING -data_clean method started...
2023-10-08 02:19:29,682 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 02:19:29,719 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 02:19:29,739 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 02:19:29,751 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 02:19:29,784 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 02:19:29,802 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 02:19:29,814 - Data_processing -WARNING -Checking for null values...
2023-10-08 02:19:29,931 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 02:19:29,931 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 02:19:47,461 - root -INFO -validating schema for the dataframes....
2023-10-08 02:19:47,461 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 02:19:47,462 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 02:19:47,462 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 02:19:47,462 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 02:19:47,462 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 02:19:47,462 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 02:19:47,462 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 02:19:47,462 - Validate -INFO -print_schema done, go frwd...
2023-10-08 02:19:47,462 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('presc_id', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('presc_city', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('presc_state', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('presc_spclt', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('drug_name', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('tx_cnt', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('total_day_supply', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('total_drug_cost', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('years_of_exp', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('Country_name', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -	StructField('presc_fullname', LongType(), False)
2023-10-08 02:19:47,463 - Validate -INFO -print_schema done, go frwd...
2023-10-08 02:19:47,463 - root -INFO -Application done
2023-10-08 02:32:52,244 - root -INFO -i am in the main method..
2023-10-08 02:32:52,244 - root -INFO -calling spark object
2023-10-08 02:32:52,244 - Create_spark -INFO -get_spark_object method started
2023-10-08 02:32:52,244 - Create_spark -INFO -master is local
2023-10-08 02:32:55,997 - root -INFO -Validating spark object..........
2023-10-08 02:32:55,997 - Validate -WARNING -started the get_current_date method...
2023-10-08 02:32:59,203 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 02:32:59,203 - Validate -WARNING -Validation done go frwd...
2023-10-08 02:32:59,203 - root -INFO -reading file which is of > parquet
2023-10-08 02:32:59,203 - Ingest -WARNING -load_files method started...
2023-10-08 02:32:59,748 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 02:32:59,748 - root -INFO -displaying file
2023-10-08 02:33:02,564 - root -INFO -here to validate the df
2023-10-08 02:33:02,564 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 02:33:04,119 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 02:33:04,119 - root -INFO -checking for the files in the Fact...
2023-10-08 02:33:04,121 - root -INFO -reading file which is of > csv
2023-10-08 02:33:04,121 - Ingest -WARNING -load_files method started...
2023-10-08 02:33:17,590 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 02:33:17,590 - root -INFO -displaying the df_fact dataframe
2023-10-08 02:33:18,469 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 02:33:20,242 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 02:33:20,242 - root -INFO -implementing data_processing methods...
2023-10-08 02:33:20,242 - Data_processing -WARNING -data_clean method started...
2023-10-08 02:33:20,243 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 02:33:20,342 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 02:33:20,423 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 02:33:20,465 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 02:33:20,565 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 02:33:20,615 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 02:33:20,641 - Data_processing -WARNING -Checking for null values...
2023-10-08 02:33:21,055 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 02:33:21,424 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 02:33:21,424 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 02:34:01,696 - root -INFO -validating schema for the dataframes....
2023-10-08 02:34:01,696 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 02:34:01,697 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 02:34:01,697 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 02:34:01,697 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 02:34:01,697 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 02:34:01,697 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 02:34:01,697 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 02:34:01,697 - Validate -INFO -print_schema done, go frwd...
2023-10-08 02:34:01,697 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('presc_id', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('presc_city', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('presc_state', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('presc_spclt', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('drug_name', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('tx_cnt', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('total_day_supply', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('total_drug_cost', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('years_of_exp', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('Country_name', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -	StructField('presc_fullname', LongType(), False)
2023-10-08 02:34:01,698 - Validate -INFO -print_schema done, go frwd...
2023-10-08 02:34:19,136 - root -INFO -Application done
2023-10-08 02:40:39,728 - root -INFO -i am in the main method..
2023-10-08 02:40:39,729 - root -INFO -calling spark object
2023-10-08 02:40:39,729 - Create_spark -INFO -get_spark_object method started
2023-10-08 02:40:39,729 - Create_spark -INFO -master is local
2023-10-08 02:40:43,693 - root -INFO -Validating spark object..........
2023-10-08 02:40:43,693 - Validate -WARNING -started the get_current_date method...
2023-10-08 02:40:46,750 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 02:40:46,751 - Validate -WARNING -Validation done go frwd...
2023-10-08 02:40:46,751 - root -INFO -reading file which is of > parquet
2023-10-08 02:40:46,751 - Ingest -WARNING -load_files method started...
2023-10-08 02:40:47,286 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 02:40:47,286 - root -INFO -displaying file
2023-10-08 02:40:48,897 - root -INFO -here to validate the df
2023-10-08 02:40:48,897 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 02:40:49,328 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 02:40:49,328 - root -INFO -checking for the files in the Fact...
2023-10-08 02:40:49,328 - root -INFO -reading file which is of > csv
2023-10-08 02:40:49,328 - Ingest -WARNING -load_files method started...
2023-10-08 02:40:53,191 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 02:40:53,191 - root -INFO -displaying the df_fact dataframe
2023-10-08 02:40:53,439 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 02:40:53,978 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 02:40:53,978 - root -INFO -implementing data_processing methods...
2023-10-08 02:40:53,978 - Data_processing -WARNING -data_clean method started...
2023-10-08 02:40:53,978 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 02:40:54,013 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 02:40:54,036 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 02:40:54,049 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 02:40:54,096 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 02:40:54,111 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 02:40:54,124 - Data_processing -WARNING -Checking for null values...
2023-10-08 02:40:54,260 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 02:40:54,366 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 02:40:54,366 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 02:41:11,538 - root -INFO -validating schema for the dataframes....
2023-10-08 02:41:11,538 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 02:41:11,539 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 02:41:11,539 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 02:41:11,539 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 02:41:11,539 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 02:41:11,539 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 02:41:11,539 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 02:41:11,539 - Validate -INFO -print_schema done, go frwd...
2023-10-08 02:41:11,539 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('presc_id', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('presc_city', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('presc_state', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('presc_spclt', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('drug_name', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('tx_cnt', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('total_day_supply', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('total_drug_cost', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('years_of_exp', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('Country_name', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -	StructField('presc_fullname', LongType(), False)
2023-10-08 02:41:11,540 - Validate -INFO -print_schema done, go frwd...
2023-10-08 02:41:11,540 - root -INFO -Application done
2023-10-08 03:03:30,383 - root -INFO -i am in the main method..
2023-10-08 03:03:30,384 - root -INFO -calling spark object
2023-10-08 03:03:30,384 - Create_spark -INFO -get_spark_object method started
2023-10-08 03:03:30,384 - Create_spark -INFO -master is local
2023-10-08 03:03:33,980 - root -INFO -Validating spark object..........
2023-10-08 03:03:33,980 - Validate -WARNING -started the get_current_date method...
2023-10-08 03:03:36,943 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 03:03:36,943 - Validate -WARNING -Validation done go frwd...
2023-10-08 03:03:36,943 - root -INFO -reading file which is of > parquet
2023-10-08 03:03:36,943 - Ingest -WARNING -load_files method started...
2023-10-08 03:03:37,516 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 03:03:37,516 - root -INFO -displaying file
2023-10-08 03:03:39,201 - root -INFO -here to validate the df
2023-10-08 03:03:39,201 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 03:03:39,615 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 03:03:39,615 - root -INFO -checking for the files in the Fact...
2023-10-08 03:03:39,615 - root -INFO -reading file which is of > csv
2023-10-08 03:03:39,615 - Ingest -WARNING -load_files method started...
2023-10-08 03:03:43,543 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 03:03:43,544 - root -INFO -displaying the df_fact dataframe
2023-10-08 03:03:43,758 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 03:03:44,354 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 03:03:44,354 - root -INFO -implementing data_processing methods...
2023-10-08 03:03:44,354 - Data_processing -WARNING -data_clean method started...
2023-10-08 03:03:44,354 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 03:03:44,389 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 03:03:44,406 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 03:03:44,418 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 03:03:44,466 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 03:03:44,487 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 03:03:44,497 - Data_processing -WARNING -Checking for null values...
2023-10-08 03:03:44,497 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 03:03:44,516 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 03:03:44,516 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 03:03:44,900 - root -INFO -validating schema for the dataframes....
2023-10-08 03:03:44,900 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 03:03:44,900 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 03:03:44,901 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 03:03:44,901 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 03:03:44,901 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 03:03:44,901 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 03:03:44,901 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 03:03:44,901 - Validate -INFO -print_schema done, go frwd...
2023-10-08 03:03:44,901 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 03:03:44,902 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 03:03:44,902 - Validate -INFO -print_schema done, go frwd...
2023-10-08 03:03:44,902 - root -INFO -Application done
2023-10-08 03:06:47,925 - root -INFO -i am in the main method..
2023-10-08 03:06:47,925 - root -INFO -calling spark object
2023-10-08 03:06:47,925 - Create_spark -INFO -get_spark_object method started
2023-10-08 03:06:47,926 - Create_spark -INFO -master is local
2023-10-08 03:06:51,595 - root -INFO -Validating spark object..........
2023-10-08 03:06:51,595 - Validate -WARNING -started the get_current_date method...
2023-10-08 03:06:54,575 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 03:06:54,575 - Validate -WARNING -Validation done go frwd...
2023-10-08 03:06:54,576 - root -INFO -reading file which is of > parquet
2023-10-08 03:06:54,576 - Ingest -WARNING -load_files method started...
2023-10-08 03:06:55,062 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 03:06:55,062 - root -INFO -displaying file
2023-10-08 03:06:56,675 - root -INFO -here to validate the df
2023-10-08 03:06:56,675 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 03:06:57,086 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 03:06:57,086 - root -INFO -checking for the files in the Fact...
2023-10-08 03:06:57,086 - root -INFO -reading file which is of > csv
2023-10-08 03:06:57,086 - Ingest -WARNING -load_files method started...
2023-10-08 03:07:00,827 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 03:07:00,827 - root -INFO -displaying the df_fact dataframe
2023-10-08 03:07:01,033 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 03:07:01,588 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 03:07:01,588 - root -INFO -implementing data_processing methods...
2023-10-08 03:07:01,588 - Data_processing -WARNING -data_clean method started...
2023-10-08 03:07:01,588 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 03:07:01,623 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 03:07:01,638 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 03:07:01,654 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 03:07:01,700 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 03:07:01,716 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 03:07:01,723 - Data_processing -WARNING -Checking for null values...
2023-10-08 03:07:01,723 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 03:07:01,832 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 03:07:01,832 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 03:07:18,495 - root -INFO -validating schema for the dataframes....
2023-10-08 03:07:18,495 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 03:07:18,496 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 03:07:18,496 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 03:07:18,496 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 03:07:18,496 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 03:07:18,496 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 03:07:18,496 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 03:07:18,496 - Validate -INFO -print_schema done, go frwd...
2023-10-08 03:07:18,496 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 03:07:18,498 - Validate -INFO -	StructField('presc_id', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('presc_city', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('presc_state', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('presc_spclt', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('drug_name', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('tx_cnt', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('total_day_supply', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('total_drug_cost', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('years_of_exp', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('Country_name', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -	StructField('presc_fullname', LongType(), False)
2023-10-08 03:07:18,499 - Validate -INFO -print_schema done, go frwd...
2023-10-08 03:07:18,499 - root -INFO -Application done
2023-10-08 03:59:05,605 - root -INFO -i am in the main method..
2023-10-08 03:59:05,605 - root -INFO -calling spark object
2023-10-08 03:59:05,605 - Create_spark -INFO -get_spark_object method started
2023-10-08 03:59:05,605 - Create_spark -INFO -master is local
2023-10-08 03:59:23,748 - root -INFO -Validating spark object..........
2023-10-08 03:59:23,748 - Validate -WARNING -started the get_current_date method...
2023-10-08 03:59:28,385 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 03:59:28,385 - Validate -WARNING -Validation done go frwd...
2023-10-08 03:59:28,386 - root -INFO -reading file which is of > parquet
2023-10-08 03:59:28,386 - Ingest -WARNING -load_files method started...
2023-10-08 03:59:29,802 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 03:59:29,802 - root -INFO -displaying file
2023-10-08 03:59:35,024 - root -INFO -here to validate the df
2023-10-08 03:59:35,024 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 03:59:36,361 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 03:59:36,362 - root -INFO -checking for the files in the Fact...
2023-10-08 03:59:36,362 - root -INFO -reading file which is of > csv
2023-10-08 03:59:36,362 - Ingest -WARNING -load_files method started...
2023-10-08 03:59:41,624 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 03:59:41,624 - root -INFO -displaying the df_fact dataframe
2023-10-08 03:59:41,887 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 03:59:42,482 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 03:59:42,482 - root -INFO -implementing data_processing methods...
2023-10-08 03:59:42,482 - Data_processing -WARNING -data_clean method started...
2023-10-08 03:59:42,482 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 03:59:42,515 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 03:59:42,532 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 03:59:42,547 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 03:59:42,588 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 03:59:42,604 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 03:59:42,613 - Data_processing -WARNING -Checking for null values...
2023-10-08 03:59:42,613 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 03:59:42,636 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 03:59:45,045 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 03:59:45,045 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 03:59:45,396 - root -INFO -validating schema for the dataframes....
2023-10-08 03:59:45,397 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 03:59:45,398 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 03:59:45,398 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 03:59:45,398 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 03:59:45,398 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 03:59:45,398 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 03:59:45,398 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 03:59:45,398 - Validate -INFO -print_schema done, go frwd...
2023-10-08 03:59:45,398 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 03:59:45,399 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 03:59:45,399 - Validate -INFO -print_schema done, go frwd...
2023-10-08 03:59:45,399 - root -INFO -Application done
2023-10-08 05:26:10,600 - root -INFO -i am in the main method..
2023-10-08 05:26:10,600 - root -INFO -calling spark object
2023-10-08 05:26:10,600 - Create_spark -INFO -get_spark_object method started
2023-10-08 05:26:10,600 - Create_spark -INFO -master is local
2023-10-08 05:26:14,615 - root -INFO -Validating spark object..........
2023-10-08 05:26:14,615 - Validate -WARNING -started the get_current_date method...
2023-10-08 05:26:17,901 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 05:26:17,901 - Validate -WARNING -Validation done go frwd...
2023-10-08 05:26:17,901 - root -INFO -reading file which is of > parquet
2023-10-08 05:26:17,901 - Ingest -WARNING -load_files method started...
2023-10-08 05:26:18,418 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 05:26:18,418 - root -INFO -displaying file
2023-10-08 05:26:20,306 - root -INFO -here to validate the df
2023-10-08 05:26:20,306 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 05:26:20,794 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 05:26:20,794 - root -INFO -checking for the files in the Fact...
2023-10-08 05:26:20,795 - root -INFO -reading file which is of > csv
2023-10-08 05:26:20,795 - Ingest -WARNING -load_files method started...
2023-10-08 05:26:25,055 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 05:26:25,056 - root -INFO -displaying the df_fact dataframe
2023-10-08 05:26:25,313 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 05:26:25,851 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 05:26:25,851 - root -INFO -implementing data_processing methods...
2023-10-08 05:26:25,851 - Data_processing -WARNING -data_clean method started...
2023-10-08 05:26:25,851 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 05:26:25,891 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 05:26:25,916 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 05:26:25,929 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 05:26:25,964 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 05:26:25,983 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 05:26:25,995 - Data_processing -WARNING -Checking for null values...
2023-10-08 05:26:25,995 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 05:26:26,011 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 05:26:28,598 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 05:26:28,599 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 05:26:28,986 - root -INFO -validating schema for the dataframes....
2023-10-08 05:26:28,986 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 05:26:28,987 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 05:26:28,987 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 05:26:28,987 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 05:26:28,987 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 05:26:28,987 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 05:26:28,987 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 05:26:28,987 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:26:28,987 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 05:26:28,989 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 05:26:28,989 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:26:28,989 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 05:26:29,114 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 05:26:47,753 - root -INFO -data transformation executed...
2023-10-08 05:26:47,753 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 05:26:47,757 - Data_transformation -WARNING -Calculating totak zip counts in DataFrame[city: string, state_id: string, state_name: string, country_name: string, population: int, zips: string]
2023-10-08 05:28:08,017 - root -INFO -i am in the main method..
2023-10-08 05:28:08,017 - root -INFO -calling spark object
2023-10-08 05:28:08,017 - Create_spark -INFO -get_spark_object method started
2023-10-08 05:28:08,017 - Create_spark -INFO -master is local
2023-10-08 05:28:11,505 - root -INFO -Validating spark object..........
2023-10-08 05:28:11,505 - Validate -WARNING -started the get_current_date method...
2023-10-08 05:28:14,527 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 05:28:14,527 - Validate -WARNING -Validation done go frwd...
2023-10-08 05:28:14,527 - root -INFO -reading file which is of > parquet
2023-10-08 05:28:14,527 - Ingest -WARNING -load_files method started...
2023-10-08 05:28:15,088 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 05:28:15,088 - root -INFO -displaying file
2023-10-08 05:28:16,653 - root -INFO -here to validate the df
2023-10-08 05:28:16,653 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 05:28:17,062 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 05:28:17,062 - root -INFO -checking for the files in the Fact...
2023-10-08 05:28:17,062 - root -INFO -reading file which is of > csv
2023-10-08 05:28:17,063 - Ingest -WARNING -load_files method started...
2023-10-08 05:28:20,978 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 05:28:20,979 - root -INFO -displaying the df_fact dataframe
2023-10-08 05:28:21,233 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 05:28:21,795 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 05:28:21,795 - root -INFO -implementing data_processing methods...
2023-10-08 05:28:21,795 - Data_processing -WARNING -data_clean method started...
2023-10-08 05:28:21,795 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 05:28:21,833 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 05:28:21,859 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 05:28:21,872 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 05:28:21,908 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 05:28:21,925 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 05:28:21,935 - Data_processing -WARNING -Checking for null values...
2023-10-08 05:28:21,935 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 05:28:21,951 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 05:28:24,436 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 05:28:24,436 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 05:28:24,767 - root -INFO -validating schema for the dataframes....
2023-10-08 05:28:24,767 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 05:28:24,768 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 05:28:24,768 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 05:28:24,768 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 05:28:24,768 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 05:28:24,768 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 05:28:24,768 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 05:28:24,768 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:28:24,768 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 05:28:24,769 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 05:28:24,770 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 05:28:24,770 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:28:24,770 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 05:28:24,892 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 05:28:41,622 - root -INFO -data transformation executed...
2023-10-08 05:28:41,623 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 05:28:41,627 - Data_transformation -WARNING -Calculating totak zip counts in DataFrame[city: string, state_id: string, state_name: string, country_name: string, population: int, zips: string]
2023-10-08 05:28:41,659 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 05:32:24,194 - root -INFO -i am in the main method..
2023-10-08 05:32:24,194 - root -INFO -calling spark object
2023-10-08 05:32:24,194 - Create_spark -INFO -get_spark_object method started
2023-10-08 05:32:24,194 - Create_spark -INFO -master is local
2023-10-08 05:32:28,156 - root -INFO -Validating spark object..........
2023-10-08 05:32:28,156 - Validate -WARNING -started the get_current_date method...
2023-10-08 05:32:31,665 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 05:32:31,665 - Validate -WARNING -Validation done go frwd...
2023-10-08 05:32:31,665 - root -INFO -reading file which is of > parquet
2023-10-08 05:32:31,665 - Ingest -WARNING -load_files method started...
2023-10-08 05:32:32,246 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 05:32:32,246 - root -INFO -displaying file
2023-10-08 05:32:35,671 - root -INFO -here to validate the df
2023-10-08 05:32:35,671 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 05:32:37,002 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 05:32:37,003 - root -INFO -checking for the files in the Fact...
2023-10-08 05:32:37,009 - root -INFO -reading file which is of > csv
2023-10-08 05:32:37,009 - Ingest -WARNING -load_files method started...
2023-10-08 05:32:49,770 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 05:32:49,770 - root -INFO -displaying the df_fact dataframe
2023-10-08 05:32:50,688 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 05:32:52,306 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 05:32:52,306 - root -INFO -implementing data_processing methods...
2023-10-08 05:32:52,307 - Data_processing -WARNING -data_clean method started...
2023-10-08 05:32:52,307 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 05:32:52,384 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 05:32:52,469 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 05:32:52,502 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 05:32:52,587 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 05:32:52,644 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 05:32:52,680 - Data_processing -WARNING -Checking for null values...
2023-10-08 05:32:52,681 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 05:32:52,758 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 05:32:56,759 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 05:32:56,759 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 05:32:57,114 - root -INFO -validating schema for the dataframes....
2023-10-08 05:32:57,114 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 05:32:57,115 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 05:32:57,115 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 05:32:57,115 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('country_name', StringType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:32:57,116 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 05:32:57,116 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 05:32:57,118 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 05:32:57,118 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 05:32:57,118 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 05:32:57,118 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:32:57,118 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 05:32:57,239 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 05:33:14,692 - root -INFO -data transformation executed...
2023-10-08 05:33:14,692 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 05:33:14,697 - Data_transformation -WARNING -Calculating totak zip counts in DataFrame[city: string, state_id: string, state_name: string, country_name: string, population: int, zips: string]
2023-10-08 05:33:14,723 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 05:33:14,751 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 05:35:34,164 - root -INFO -i am in the main method..
2023-10-08 05:35:34,164 - root -INFO -calling spark object
2023-10-08 05:35:34,164 - Create_spark -INFO -get_spark_object method started
2023-10-08 05:35:34,164 - Create_spark -INFO -master is local
2023-10-08 05:35:37,880 - root -INFO -Validating spark object..........
2023-10-08 05:35:37,880 - Validate -WARNING -started the get_current_date method...
2023-10-08 05:35:41,017 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 05:35:41,017 - Validate -WARNING -Validation done go frwd...
2023-10-08 05:35:41,017 - root -INFO -reading file which is of > parquet
2023-10-08 05:35:41,017 - Ingest -WARNING -load_files method started...
2023-10-08 05:35:41,519 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 05:35:41,520 - root -INFO -displaying file
2023-10-08 05:35:43,275 - root -INFO -here to validate the df
2023-10-08 05:35:43,275 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 05:35:43,706 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 05:35:43,706 - root -INFO -checking for the files in the Fact...
2023-10-08 05:35:43,706 - root -INFO -reading file which is of > csv
2023-10-08 05:35:43,706 - Ingest -WARNING -load_files method started...
2023-10-08 05:35:47,816 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 05:35:47,816 - root -INFO -displaying the df_fact dataframe
2023-10-08 05:35:48,053 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 05:35:48,602 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 05:35:48,603 - root -INFO -implementing data_processing methods...
2023-10-08 05:35:48,603 - Data_processing -WARNING -data_clean method started...
2023-10-08 05:35:48,603 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 05:35:48,639 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 05:35:48,666 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 05:35:48,677 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 05:35:48,716 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 05:35:48,741 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 05:35:48,753 - Data_processing -WARNING -Checking for null values...
2023-10-08 05:35:48,753 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 05:35:48,770 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 05:35:51,019 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 05:35:51,019 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 05:35:51,367 - root -INFO -validating schema for the dataframes....
2023-10-08 05:35:51,368 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 05:35:51,368 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 05:35:51,369 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 05:35:51,369 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 05:35:51,369 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 05:35:51,369 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 05:35:51,369 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 05:35:51,369 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:35:51,369 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 05:35:51,370 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 05:35:51,370 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:35:51,370 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 05:35:51,494 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 05:36:08,205 - root -INFO -data transformation executed...
2023-10-08 05:36:08,205 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 05:36:08,209 - Data_transformation -WARNING -Calculating totak zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 05:36:08,232 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 05:36:08,257 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 05:36:08,288 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 05:36:08,288 - root -INFO -displaying the df_report_1
2023-10-08 05:37:41,186 - root -INFO -i am in the main method..
2023-10-08 05:37:41,186 - root -INFO -calling spark object
2023-10-08 05:37:41,186 - Create_spark -INFO -get_spark_object method started
2023-10-08 05:37:41,187 - Create_spark -INFO -master is local
2023-10-08 05:37:44,978 - root -INFO -Validating spark object..........
2023-10-08 05:37:44,979 - Validate -WARNING -started the get_current_date method...
2023-10-08 05:37:48,016 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 05:37:48,016 - Validate -WARNING -Validation done go frwd...
2023-10-08 05:37:48,016 - root -INFO -reading file which is of > parquet
2023-10-08 05:37:48,016 - Ingest -WARNING -load_files method started...
2023-10-08 05:37:48,535 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 05:37:48,535 - root -INFO -displaying file
2023-10-08 05:37:50,169 - root -INFO -here to validate the df
2023-10-08 05:37:50,169 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 05:37:50,581 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 05:37:50,581 - root -INFO -checking for the files in the Fact...
2023-10-08 05:37:50,581 - root -INFO -reading file which is of > csv
2023-10-08 05:37:50,581 - Ingest -WARNING -load_files method started...
2023-10-08 05:37:54,442 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 05:37:54,442 - root -INFO -displaying the df_fact dataframe
2023-10-08 05:37:54,676 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 05:37:55,245 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 05:37:55,245 - root -INFO -implementing data_processing methods...
2023-10-08 05:37:55,246 - Data_processing -WARNING -data_clean method started...
2023-10-08 05:37:55,246 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 05:37:55,287 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 05:37:55,308 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 05:37:55,321 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 05:37:55,358 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 05:37:55,374 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 05:37:55,384 - Data_processing -WARNING -Checking for null values...
2023-10-08 05:37:55,384 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 05:37:55,404 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 05:37:57,587 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 05:37:57,587 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 05:37:57,940 - root -INFO -validating schema for the dataframes....
2023-10-08 05:37:57,940 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 05:37:57,941 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 05:37:57,941 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 05:37:57,941 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 05:37:57,941 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 05:37:57,941 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 05:37:57,941 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 05:37:57,941 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:37:57,941 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 05:37:57,942 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 05:37:57,942 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:37:57,942 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 05:37:58,065 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 05:38:15,137 - root -INFO -data transformation executed...
2023-10-08 05:38:15,137 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 05:38:15,139 - Data_transformation -WARNING -Calculating totak zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 05:38:15,164 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 05:38:15,186 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 05:38:15,220 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 05:38:15,220 - root -INFO -displaying the df_report_1
2023-10-08 05:48:37,943 - root -INFO -i am in the main method..
2023-10-08 05:48:37,943 - root -INFO -calling spark object
2023-10-08 05:48:37,943 - Create_spark -INFO -get_spark_object method started
2023-10-08 05:48:37,943 - Create_spark -INFO -master is local
2023-10-08 05:48:41,654 - root -INFO -Validating spark object..........
2023-10-08 05:48:41,654 - Validate -WARNING -started the get_current_date method...
2023-10-08 05:48:44,753 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 05:48:44,753 - Validate -WARNING -Validation done go frwd...
2023-10-08 05:48:44,753 - root -INFO -reading file which is of > parquet
2023-10-08 05:48:44,753 - Ingest -WARNING -load_files method started...
2023-10-08 05:48:45,236 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 05:48:45,236 - root -INFO -displaying file
2023-10-08 05:48:46,842 - root -INFO -here to validate the df
2023-10-08 05:48:46,842 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 05:48:47,319 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 05:48:47,320 - root -INFO -checking for the files in the Fact...
2023-10-08 05:48:47,320 - root -INFO -reading file which is of > csv
2023-10-08 05:48:47,320 - Ingest -WARNING -load_files method started...
2023-10-08 05:48:51,327 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 05:48:51,327 - root -INFO -displaying the df_fact dataframe
2023-10-08 05:48:51,588 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 05:48:52,207 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 05:48:52,207 - root -INFO -implementing data_processing methods...
2023-10-08 05:48:52,208 - Data_processing -WARNING -data_clean method started...
2023-10-08 05:48:52,208 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 05:48:52,242 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 05:48:52,259 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 05:48:52,269 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 05:48:52,306 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 05:48:52,324 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 05:48:52,336 - Data_processing -WARNING -Checking for null values...
2023-10-08 05:48:52,336 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 05:48:52,354 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 05:48:54,814 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 05:48:54,815 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 05:48:55,205 - root -INFO -validating schema for the dataframes....
2023-10-08 05:48:55,205 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 05:48:55,206 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 05:48:55,207 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 05:48:55,207 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 05:48:55,207 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 05:48:55,207 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 05:48:55,207 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 05:48:55,207 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:48:55,207 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 05:48:55,208 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 05:48:55,208 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 05:48:55,208 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 05:48:55,208 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 05:48:55,208 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 05:48:55,208 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 05:48:55,208 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 05:48:55,209 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 05:48:55,209 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 05:48:55,209 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 05:48:55,209 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 05:48:55,209 - Validate -INFO -print_schema done, go frwd...
2023-10-08 05:48:55,209 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 05:48:55,346 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 05:49:12,154 - root -INFO -data transformation executed...
2023-10-08 05:49:12,154 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 05:49:12,160 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 05:49:12,193 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 05:49:12,223 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 05:49:12,256 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 05:49:12,256 - root -INFO -displaying the df_report_1
2023-10-08 20:48:55,709 - root -INFO -i am in the main method..
2023-10-08 20:48:55,710 - root -INFO -calling spark object
2023-10-08 20:48:55,710 - Create_spark -INFO -get_spark_object method started
2023-10-08 20:48:55,710 - Create_spark -INFO -master is local
2023-10-08 20:49:00,376 - root -INFO -Validating spark object..........
2023-10-08 20:49:00,376 - Validate -WARNING -started the get_current_date method...
2023-10-08 20:49:03,780 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 20:49:03,780 - Validate -WARNING -Validation done go frwd...
2023-10-08 20:49:03,780 - root -INFO -reading file which is of > parquet
2023-10-08 20:49:03,780 - Ingest -WARNING -load_files method started...
2023-10-08 20:49:04,362 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 20:49:04,362 - root -INFO -displaying file
2023-10-08 20:49:06,065 - root -INFO -here to validate the df
2023-10-08 20:49:06,065 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 20:49:06,599 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 20:49:06,599 - root -INFO -checking for the files in the Fact...
2023-10-08 20:49:06,599 - root -INFO -reading file which is of > csv
2023-10-08 20:49:06,599 - Ingest -WARNING -load_files method started...
2023-10-08 20:49:10,555 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 20:49:10,555 - root -INFO -displaying the df_fact dataframe
2023-10-08 20:49:10,801 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 20:49:11,342 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 20:49:11,342 - root -INFO -implementing data_processing methods...
2023-10-08 20:49:11,342 - Data_processing -WARNING -data_clean method started...
2023-10-08 20:49:11,342 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 20:49:11,372 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 20:49:11,390 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 20:49:11,403 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 20:49:11,437 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 20:49:11,451 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 20:49:11,461 - Data_processing -WARNING -Checking for null values...
2023-10-08 20:49:11,462 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 20:49:11,480 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 20:49:13,845 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 20:49:13,845 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 20:49:14,227 - root -INFO -validating schema for the dataframes....
2023-10-08 20:49:14,227 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 20:49:14,228 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 20:49:14,228 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 20:49:14,228 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 20:49:14,228 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 20:49:14,228 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 20:49:14,228 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 20:49:14,228 - Validate -INFO -print_schema done, go frwd...
2023-10-08 20:49:14,228 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 20:49:14,230 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 20:49:14,230 - Validate -INFO -print_schema done, go frwd...
2023-10-08 20:49:14,230 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 20:49:14,378 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 20:49:31,234 - root -INFO -data transformation executed...
2023-10-08 20:49:31,234 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 20:49:31,236 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 20:49:31,263 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 20:49:31,289 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 20:49:31,329 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 20:49:31,329 - root -INFO -displaying the df_report_1
2023-10-08 21:02:28,799 - root -INFO -i am in the main method..
2023-10-08 21:02:28,799 - root -INFO -calling spark object
2023-10-08 21:02:28,799 - Create_spark -INFO -get_spark_object method started
2023-10-08 21:02:28,799 - Create_spark -INFO -master is local
2023-10-08 21:02:32,525 - root -INFO -Validating spark object..........
2023-10-08 21:02:32,525 - Validate -WARNING -started the get_current_date method...
2023-10-08 21:02:35,688 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 21:02:35,688 - Validate -WARNING -Validation done go frwd...
2023-10-08 21:02:35,688 - root -INFO -reading file which is of > parquet
2023-10-08 21:02:35,688 - Ingest -WARNING -load_files method started...
2023-10-08 21:02:36,206 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 21:02:36,206 - root -INFO -displaying file
2023-10-08 21:02:37,854 - root -INFO -here to validate the df
2023-10-08 21:02:37,854 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 21:02:38,324 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 21:02:38,324 - root -INFO -checking for the files in the Fact...
2023-10-08 21:02:38,325 - root -INFO -reading file which is of > csv
2023-10-08 21:02:38,325 - Ingest -WARNING -load_files method started...
2023-10-08 21:02:42,386 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 21:02:42,386 - root -INFO -displaying the df_fact dataframe
2023-10-08 21:02:42,670 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 21:02:43,232 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 21:02:43,232 - root -INFO -implementing data_processing methods...
2023-10-08 21:02:43,232 - Data_processing -WARNING -data_clean method started...
2023-10-08 21:02:43,232 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 21:02:43,265 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 21:02:43,286 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 21:02:43,296 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 21:02:43,328 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 21:02:43,345 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 21:02:43,355 - Data_processing -WARNING -Checking for null values...
2023-10-08 21:02:43,355 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 21:02:43,373 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 21:02:45,786 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 21:02:45,787 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 21:02:46,146 - root -INFO -validating schema for the dataframes....
2023-10-08 21:02:46,147 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 21:02:46,148 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 21:02:46,148 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 21:02:46,148 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 21:02:46,148 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 21:02:46,148 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 21:02:46,148 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 21:02:46,148 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:02:46,148 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 21:02:46,149 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 21:02:46,150 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 21:02:46,150 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:02:46,150 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 21:02:46,269 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 21:03:03,282 - root -INFO -data transformation executed...
2023-10-08 21:03:03,282 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 21:03:03,288 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 21:03:03,316 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 21:03:03,341 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 21:03:03,378 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 21:03:03,378 - root -INFO -displaying the df_report_1
2023-10-08 21:08:27,439 - root -INFO -i am in the main method..
2023-10-08 21:08:27,440 - root -INFO -calling spark object
2023-10-08 21:08:27,440 - Create_spark -INFO -get_spark_object method started
2023-10-08 21:08:27,440 - Create_spark -INFO -master is local
2023-10-08 21:08:31,223 - root -INFO -Validating spark object..........
2023-10-08 21:08:31,223 - Validate -WARNING -started the get_current_date method...
2023-10-08 21:08:34,273 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 21:08:34,273 - Validate -WARNING -Validation done go frwd...
2023-10-08 21:08:34,273 - root -INFO -reading file which is of > parquet
2023-10-08 21:08:34,273 - Ingest -WARNING -load_files method started...
2023-10-08 21:08:34,763 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 21:08:34,763 - root -INFO -displaying file
2023-10-08 21:08:36,509 - root -INFO -here to validate the df
2023-10-08 21:08:36,509 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 21:08:36,956 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 21:08:36,956 - root -INFO -checking for the files in the Fact...
2023-10-08 21:08:36,956 - root -INFO -reading file which is of > csv
2023-10-08 21:08:36,956 - Ingest -WARNING -load_files method started...
2023-10-08 21:08:40,899 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 21:08:40,900 - root -INFO -displaying the df_fact dataframe
2023-10-08 21:08:41,147 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 21:08:41,657 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 21:08:41,658 - root -INFO -implementing data_processing methods...
2023-10-08 21:08:41,658 - Data_processing -WARNING -data_clean method started...
2023-10-08 21:08:41,658 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 21:08:41,693 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 21:08:41,712 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 21:08:41,723 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 21:08:41,752 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 21:08:41,770 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 21:08:41,780 - Data_processing -WARNING -Checking for null values...
2023-10-08 21:08:41,780 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 21:08:41,796 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 21:08:44,063 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 21:08:44,063 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 21:08:44,408 - root -INFO -validating schema for the dataframes....
2023-10-08 21:08:44,408 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 21:08:44,409 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 21:08:44,410 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 21:08:44,410 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 21:08:44,410 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 21:08:44,410 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 21:08:44,410 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 21:08:44,410 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:08:44,410 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 21:08:44,411 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 21:08:44,411 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:08:44,411 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 21:08:44,515 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 21:09:01,569 - root -INFO -data transformation executed...
2023-10-08 21:09:01,569 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 21:09:01,573 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 21:09:01,604 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 21:09:01,628 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 21:09:01,658 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 21:09:01,658 - root -INFO -displaying the df_report_1
2023-10-08 21:09:39,799 - root -INFO -i am in the main method..
2023-10-08 21:09:39,799 - root -INFO -calling spark object
2023-10-08 21:09:39,799 - Create_spark -INFO -get_spark_object method started
2023-10-08 21:09:39,799 - Create_spark -INFO -master is local
2023-10-08 21:09:43,666 - root -INFO -Validating spark object..........
2023-10-08 21:09:43,667 - Validate -WARNING -started the get_current_date method...
2023-10-08 21:09:46,628 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 21:09:46,628 - Validate -WARNING -Validation done go frwd...
2023-10-08 21:09:46,628 - root -INFO -reading file which is of > parquet
2023-10-08 21:09:46,628 - Ingest -WARNING -load_files method started...
2023-10-08 21:09:47,125 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 21:09:47,125 - root -INFO -displaying file
2023-10-08 21:09:48,719 - root -INFO -here to validate the df
2023-10-08 21:09:48,719 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 21:09:49,143 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 21:09:49,143 - root -INFO -checking for the files in the Fact...
2023-10-08 21:09:49,143 - root -INFO -reading file which is of > csv
2023-10-08 21:09:49,143 - Ingest -WARNING -load_files method started...
2023-10-08 21:09:53,152 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 21:09:53,152 - root -INFO -displaying the df_fact dataframe
2023-10-08 21:09:53,402 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 21:09:53,988 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 21:09:53,988 - root -INFO -implementing data_processing methods...
2023-10-08 21:09:53,988 - Data_processing -WARNING -data_clean method started...
2023-10-08 21:09:53,988 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 21:09:54,038 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 21:09:54,066 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 21:09:54,077 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 21:09:54,108 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 21:09:54,124 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 21:09:54,132 - Data_processing -WARNING -Checking for null values...
2023-10-08 21:09:54,133 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 21:09:54,149 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 21:09:56,512 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 21:09:56,512 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 21:09:56,870 - root -INFO -validating schema for the dataframes....
2023-10-08 21:09:56,870 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 21:09:56,871 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 21:09:56,871 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 21:09:56,871 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 21:09:56,871 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 21:09:56,871 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 21:09:56,871 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 21:09:56,871 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:09:56,871 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 21:09:56,872 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 21:09:56,872 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:09:56,872 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 21:09:56,999 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 21:10:14,191 - root -INFO -data transformation executed...
2023-10-08 21:10:14,191 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 21:10:14,195 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 21:10:14,218 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 21:10:14,240 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 21:10:14,270 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 21:10:14,270 - root -INFO -displaying the df_report_1
2023-10-08 21:25:20,615 - root -INFO -i am in the main method..
2023-10-08 21:25:20,615 - root -INFO -calling spark object
2023-10-08 21:25:20,616 - Create_spark -INFO -get_spark_object method started
2023-10-08 21:25:20,616 - Create_spark -INFO -master is local
2023-10-08 21:25:24,392 - root -INFO -Validating spark object..........
2023-10-08 21:25:24,392 - Validate -WARNING -started the get_current_date method...
2023-10-08 21:25:27,355 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 21:25:27,355 - Validate -WARNING -Validation done go frwd...
2023-10-08 21:25:27,355 - root -INFO -reading file which is of > parquet
2023-10-08 21:25:27,356 - Ingest -WARNING -load_files method started...
2023-10-08 21:25:27,888 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 21:25:27,888 - root -INFO -displaying file
2023-10-08 21:25:29,531 - root -INFO -here to validate the df
2023-10-08 21:25:29,531 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 21:25:30,021 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 21:25:30,021 - root -INFO -checking for the files in the Fact...
2023-10-08 21:25:30,021 - root -INFO -reading file which is of > csv
2023-10-08 21:25:30,021 - Ingest -WARNING -load_files method started...
2023-10-08 21:25:33,912 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 21:25:33,912 - root -INFO -displaying the df_fact dataframe
2023-10-08 21:25:34,173 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 21:25:34,745 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 21:25:34,745 - root -INFO -implementing data_processing methods...
2023-10-08 21:25:34,746 - Data_processing -WARNING -data_clean method started...
2023-10-08 21:25:34,746 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 21:25:34,785 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 21:25:34,805 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 21:25:34,816 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 21:25:34,854 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 21:25:34,872 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 21:25:34,884 - Data_processing -WARNING -Checking for null values...
2023-10-08 21:25:34,884 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 21:25:34,902 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 21:25:37,314 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 21:25:37,314 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 21:25:37,678 - root -INFO -validating schema for the dataframes....
2023-10-08 21:25:37,678 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 21:25:37,679 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 21:25:37,679 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 21:25:37,679 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 21:25:37,679 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 21:25:37,679 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 21:25:37,679 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 21:25:37,679 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:25:37,679 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 21:25:37,680 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 21:25:37,681 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 21:25:37,681 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:25:37,681 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 21:25:37,796 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 21:25:54,577 - root -INFO -data transformation executed...
2023-10-08 21:25:54,577 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 21:25:54,580 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 21:25:54,602 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 21:25:54,624 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 21:25:54,654 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 21:37:43,419 - root -INFO -i am in the main method..
2023-10-08 21:37:43,420 - root -INFO -calling spark object
2023-10-08 21:37:43,420 - Create_spark -INFO -get_spark_object method started
2023-10-08 21:37:43,420 - Create_spark -INFO -master is local
2023-10-08 21:37:47,072 - root -INFO -Validating spark object..........
2023-10-08 21:37:47,073 - Validate -WARNING -started the get_current_date method...
2023-10-08 21:37:50,087 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 21:37:50,087 - Validate -WARNING -Validation done go frwd...
2023-10-08 21:37:50,087 - root -INFO -reading file which is of > parquet
2023-10-08 21:37:50,087 - Ingest -WARNING -load_files method started...
2023-10-08 21:37:50,573 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 21:37:50,573 - root -INFO -displaying file
2023-10-08 21:37:53,630 - root -INFO -here to validate the df
2023-10-08 21:37:53,630 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 21:37:55,103 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 21:37:55,104 - root -INFO -checking for the files in the Fact...
2023-10-08 21:37:55,105 - root -INFO -reading file which is of > csv
2023-10-08 21:37:55,105 - Ingest -WARNING -load_files method started...
2023-10-08 21:38:07,618 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 21:38:07,618 - root -INFO -displaying the df_fact dataframe
2023-10-08 21:38:08,563 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 21:38:10,169 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 21:38:10,169 - root -INFO -implementing data_processing methods...
2023-10-08 21:38:10,170 - Data_processing -WARNING -data_clean method started...
2023-10-08 21:38:10,170 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 21:38:10,254 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 21:38:10,303 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 21:38:10,335 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 21:38:10,419 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 21:38:10,463 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 21:38:10,482 - Data_processing -WARNING -Checking for null values...
2023-10-08 21:38:10,483 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 21:38:10,527 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 21:38:17,719 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 21:38:17,719 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 21:38:18,562 - root -INFO -validating schema for the dataframes....
2023-10-08 21:38:18,563 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 21:38:18,565 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 21:38:18,565 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 21:38:18,565 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 21:38:18,565 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 21:38:18,565 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 21:38:18,566 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 21:38:18,566 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:38:18,566 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 21:38:18,568 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 21:38:18,569 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 21:38:18,569 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 21:38:18,569 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 21:38:18,569 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 21:38:18,569 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 21:38:18,569 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 21:38:18,570 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 21:38:18,570 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 21:38:18,570 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 21:38:18,570 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 21:38:18,570 - Validate -INFO -print_schema done, go frwd...
2023-10-08 21:38:18,570 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 21:38:18,926 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 21:38:39,322 - root -INFO -data transformation executed...
2023-10-08 21:38:39,322 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 21:38:39,325 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 21:38:39,357 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 21:38:39,385 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 21:38:39,417 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-08 22:10:27,774 - root -INFO -i am in the main method..
2023-10-08 22:10:27,774 - root -INFO -calling spark object
2023-10-08 22:10:27,774 - Create_spark -INFO -get_spark_object method started
2023-10-08 22:10:27,774 - Create_spark -INFO -master is local
2023-10-08 22:15:53,153 - root -INFO -i am in the main method..
2023-10-08 22:15:53,153 - root -INFO -calling spark object
2023-10-08 22:15:53,153 - Create_spark -INFO -get_spark_object method started
2023-10-08 22:15:53,153 - Create_spark -INFO -master is local
2023-10-08 22:15:56,911 - root -INFO -Validating spark object..........
2023-10-08 22:15:56,911 - Validate -WARNING -started the get_current_date method...
2023-10-08 22:16:00,086 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 8))]
2023-10-08 22:16:00,087 - Validate -WARNING -Validation done go frwd...
2023-10-08 22:16:00,087 - root -INFO -reading file which is of > parquet
2023-10-08 22:16:00,087 - Ingest -WARNING -load_files method started...
2023-10-08 22:16:00,591 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-08 22:16:00,591 - root -INFO -displaying file
2023-10-08 22:16:02,132 - root -INFO -here to validate the df
2023-10-08 22:16:02,132 - Ingest -WARNING -here to count the records in the df_city
2023-10-08 22:16:02,558 - Ingest -WARNING -number of records 28338 :: 
2023-10-08 22:16:02,558 - root -INFO -checking for the files in the Fact...
2023-10-08 22:16:02,559 - root -INFO -reading file which is of > csv
2023-10-08 22:16:02,559 - Ingest -WARNING -load_files method started...
2023-10-08 22:16:06,555 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-08 22:16:06,555 - root -INFO -displaying the df_fact dataframe
2023-10-08 22:16:06,780 - Ingest -WARNING -here to count the records in the df_fact
2023-10-08 22:16:07,334 - Ingest -WARNING -number of records 1329329 :: 
2023-10-08 22:16:07,334 - root -INFO -implementing data_processing methods...
2023-10-08 22:16:07,334 - Data_processing -WARNING -data_clean method started...
2023-10-08 22:16:07,334 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-08 22:16:07,365 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-08 22:16:07,385 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-08 22:16:07,395 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-08 22:16:07,435 - Data_processing -WARNING -Concat fname and lname...
2023-10-08 22:16:07,449 - Data_processing -WARNING -Dropping fname and lname...
2023-10-08 22:16:07,458 - Data_processing -WARNING -Checking for null values...
2023-10-08 22:16:07,458 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-08 22:16:07,477 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-08 22:16:09,767 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-08 22:16:09,767 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-08 22:16:10,135 - root -INFO -validating schema for the dataframes....
2023-10-08 22:16:10,135 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-08 22:16:10,136 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-08 22:16:10,136 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-08 22:16:10,136 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-08 22:16:10,136 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-08 22:16:10,137 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-08 22:16:10,137 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-08 22:16:10,137 - Validate -INFO -print_schema done, go frwd...
2023-10-08 22:16:10,137 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-08 22:16:10,138 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-08 22:16:10,138 - Validate -INFO -print_schema done, go frwd...
2023-10-08 22:16:10,138 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-08 22:16:10,288 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-08 22:16:27,010 - root -INFO -data transformation executed...
2023-10-08 22:16:27,011 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-08 22:16:27,018 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-08 22:16:27,047 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-08 22:16:27,073 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-08 22:16:27,107 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 02:32:21,143 - root -INFO -i am in the main method..
2023-10-09 02:32:21,144 - root -INFO -calling spark object
2023-10-09 02:32:21,144 - Create_spark -INFO -get_spark_object method started
2023-10-09 02:32:21,144 - Create_spark -INFO -master is local
2023-10-09 02:32:37,137 - root -INFO -Validating spark object..........
2023-10-09 02:32:37,137 - Validate -WARNING -started the get_current_date method...
2023-10-09 02:32:40,836 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 02:32:40,836 - Validate -WARNING -Validation done go frwd...
2023-10-09 02:32:40,836 - root -INFO -reading file which is of > parquet
2023-10-09 02:32:40,836 - Ingest -WARNING -load_files method started...
2023-10-09 02:32:41,455 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 02:32:41,455 - root -INFO -displaying file
2023-10-09 02:32:43,272 - root -INFO -here to validate the df
2023-10-09 02:32:43,272 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 02:32:43,851 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 02:32:43,851 - root -INFO -checking for the files in the Fact...
2023-10-09 02:32:43,851 - root -INFO -reading file which is of > csv
2023-10-09 02:32:43,851 - Ingest -WARNING -load_files method started...
2023-10-09 02:32:47,704 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 02:32:47,705 - root -INFO -displaying the df_fact dataframe
2023-10-09 02:32:47,924 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 02:32:48,466 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 02:32:48,466 - root -INFO -implementing data_processing methods...
2023-10-09 02:32:48,466 - Data_processing -WARNING -data_clean method started...
2023-10-09 02:32:48,466 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 02:32:48,505 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 02:32:48,525 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 02:32:48,536 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 02:32:48,571 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 02:32:48,584 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 02:32:48,593 - Data_processing -WARNING -Checking for null values...
2023-10-09 02:32:48,593 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 02:32:48,610 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 02:32:50,817 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 02:32:50,817 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 02:32:51,154 - root -INFO -validating schema for the dataframes....
2023-10-09 02:32:51,154 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 02:32:51,155 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 02:32:51,155 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 02:32:51,155 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 02:32:51,155 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 02:32:51,155 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 02:32:51,155 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 02:32:51,155 - Validate -INFO -print_schema done, go frwd...
2023-10-09 02:32:51,155 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 02:32:51,157 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 02:32:51,157 - Validate -INFO -print_schema done, go frwd...
2023-10-09 02:32:51,158 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 02:32:51,329 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 02:33:08,017 - root -INFO -data transformation executed...
2023-10-09 02:33:08,017 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 02:33:08,020 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 02:33:08,042 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 02:33:08,076 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 02:33:08,117 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 02:45:43,385 - root -INFO -i am in the main method..
2023-10-09 02:45:43,385 - root -INFO -calling spark object
2023-10-09 02:45:43,385 - Create_spark -INFO -get_spark_object method started
2023-10-09 02:45:43,385 - Create_spark -INFO -master is local
2023-10-09 02:45:47,398 - root -INFO -Validating spark object..........
2023-10-09 02:45:47,398 - Validate -WARNING -started the get_current_date method...
2023-10-09 02:45:50,454 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 02:45:50,454 - Validate -WARNING -Validation done go frwd...
2023-10-09 02:45:50,454 - root -INFO -reading file which is of > parquet
2023-10-09 02:45:50,454 - Ingest -WARNING -load_files method started...
2023-10-09 02:45:50,987 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 02:45:50,987 - root -INFO -displaying file
2023-10-09 02:45:52,905 - root -INFO -here to validate the df
2023-10-09 02:45:52,905 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 02:45:54,243 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 02:45:54,243 - root -INFO -checking for the files in the Fact...
2023-10-09 02:45:54,244 - root -INFO -reading file which is of > csv
2023-10-09 02:45:54,244 - Ingest -WARNING -load_files method started...
2023-10-09 02:46:07,503 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 02:46:07,504 - root -INFO -displaying the df_fact dataframe
2023-10-09 02:46:08,410 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 02:46:10,272 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 02:46:10,273 - root -INFO -implementing data_processing methods...
2023-10-09 02:46:10,273 - Data_processing -WARNING -data_clean method started...
2023-10-09 02:46:10,273 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 02:46:10,379 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 02:46:10,445 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 02:46:10,484 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 02:46:10,566 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 02:46:10,613 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 02:46:10,657 - Data_processing -WARNING -Checking for null values...
2023-10-09 02:46:10,657 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 02:46:10,733 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 02:46:17,826 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 02:46:17,826 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 02:46:19,084 - root -INFO -validating schema for the dataframes....
2023-10-09 02:46:19,084 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 02:46:19,087 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 02:46:19,088 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 02:46:19,088 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 02:46:19,088 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 02:46:19,088 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 02:46:19,088 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 02:46:19,088 - Validate -INFO -print_schema done, go frwd...
2023-10-09 02:46:19,088 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 02:46:19,093 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 02:46:19,093 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 02:46:19,093 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 02:46:19,093 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 02:46:19,093 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 02:46:19,093 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 02:46:19,094 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 02:46:19,094 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 02:46:19,094 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 02:46:19,095 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 02:46:19,095 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 02:46:19,095 - Validate -INFO -print_schema done, go frwd...
2023-10-09 02:46:19,095 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 02:46:19,543 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 02:46:50,731 - root -INFO -data transformation executed...
2023-10-09 02:46:50,731 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 02:46:50,733 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 02:46:50,756 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 02:46:50,780 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 02:46:50,814 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 02:48:35,563 - root -INFO -i am in the main method..
2023-10-09 02:48:35,563 - root -INFO -calling spark object
2023-10-09 02:48:35,563 - Create_spark -INFO -get_spark_object method started
2023-10-09 02:48:35,563 - Create_spark -INFO -master is local
2023-10-09 02:48:39,399 - root -INFO -Validating spark object..........
2023-10-09 02:48:39,399 - Validate -WARNING -started the get_current_date method...
2023-10-09 02:48:42,568 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 02:48:42,568 - Validate -WARNING -Validation done go frwd...
2023-10-09 02:48:42,568 - root -INFO -reading file which is of > parquet
2023-10-09 02:48:42,568 - Ingest -WARNING -load_files method started...
2023-10-09 02:48:43,050 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 02:48:43,050 - root -INFO -displaying file
2023-10-09 02:48:44,637 - root -INFO -here to validate the df
2023-10-09 02:48:44,637 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 02:48:45,045 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 02:48:45,045 - root -INFO -checking for the files in the Fact...
2023-10-09 02:48:45,045 - root -INFO -reading file which is of > csv
2023-10-09 02:48:45,045 - Ingest -WARNING -load_files method started...
2023-10-09 02:48:48,983 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 02:48:48,983 - root -INFO -displaying the df_fact dataframe
2023-10-09 02:48:49,239 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 02:48:49,776 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 02:48:49,776 - root -INFO -implementing data_processing methods...
2023-10-09 02:48:49,776 - Data_processing -WARNING -data_clean method started...
2023-10-09 02:48:49,776 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 02:48:49,815 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 02:48:49,836 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 02:48:49,846 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 02:48:49,876 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 02:48:49,889 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 02:48:49,898 - Data_processing -WARNING -Checking for null values...
2023-10-09 02:48:49,898 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 02:48:49,914 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 02:48:52,215 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 02:48:52,215 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 02:48:52,559 - root -INFO -validating schema for the dataframes....
2023-10-09 02:48:52,559 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 02:48:52,560 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 02:48:52,560 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 02:48:52,560 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 02:48:52,560 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 02:48:52,560 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 02:48:52,560 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 02:48:52,561 - Validate -INFO -print_schema done, go frwd...
2023-10-09 02:48:52,561 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 02:48:52,561 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 02:48:52,562 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 02:48:52,562 - Validate -INFO -print_schema done, go frwd...
2023-10-09 02:48:52,562 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 02:48:52,672 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 02:49:09,800 - root -INFO -data transformation executed...
2023-10-09 02:49:09,800 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 02:49:09,802 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 02:49:09,832 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 02:49:09,854 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 02:49:09,887 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 02:49:09,887 - root -INFO -displaying the df_report_1
2023-10-09 03:06:04,620 - root -INFO -i am in the main method..
2023-10-09 03:06:04,620 - root -INFO -calling spark object
2023-10-09 03:06:04,620 - Create_spark -INFO -get_spark_object method started
2023-10-09 03:06:04,620 - Create_spark -INFO -master is local
2023-10-09 03:06:09,154 - root -INFO -Validating spark object..........
2023-10-09 03:06:09,154 - Validate -WARNING -started the get_current_date method...
2023-10-09 03:06:12,776 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 03:06:12,777 - Validate -WARNING -Validation done go frwd...
2023-10-09 03:06:12,777 - root -INFO -reading file which is of > parquet
2023-10-09 03:06:12,777 - Ingest -WARNING -load_files method started...
2023-10-09 03:06:13,358 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 03:06:13,358 - root -INFO -displaying file
2023-10-09 03:06:15,309 - root -INFO -here to validate the df
2023-10-09 03:06:15,309 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 03:06:15,840 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 03:06:15,840 - root -INFO -checking for the files in the Fact...
2023-10-09 03:06:15,841 - root -INFO -reading file which is of > csv
2023-10-09 03:06:15,841 - Ingest -WARNING -load_files method started...
2023-10-09 03:06:19,943 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 03:06:19,943 - root -INFO -displaying the df_fact dataframe
2023-10-09 03:06:20,181 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 03:06:20,708 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 03:06:20,709 - root -INFO -implementing data_processing methods...
2023-10-09 03:06:20,709 - Data_processing -WARNING -data_clean method started...
2023-10-09 03:06:20,709 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 03:06:20,742 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 03:06:20,762 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 03:06:20,772 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 03:06:20,804 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 03:06:20,819 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 03:06:20,832 - Data_processing -WARNING -Checking for null values...
2023-10-09 03:06:20,832 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 03:06:20,848 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 03:06:23,146 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 03:06:23,146 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 03:06:23,482 - root -INFO -validating schema for the dataframes....
2023-10-09 03:06:23,483 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 03:06:23,486 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 03:06:23,486 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 03:06:23,486 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 03:06:23,486 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 03:06:23,486 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 03:06:23,486 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 03:06:23,486 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:06:23,486 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 03:06:23,487 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 03:06:23,488 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 03:06:23,488 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:06:23,488 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 03:06:23,650 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 03:06:40,611 - root -INFO -data transformation executed...
2023-10-09 03:06:40,611 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 03:06:40,616 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 03:06:40,644 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 03:06:40,668 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 03:06:40,706 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 03:06:40,706 - root -INFO -displaying the df_report_1
2023-10-09 03:09:34,416 - root -INFO -i am in the main method..
2023-10-09 03:09:34,416 - root -INFO -calling spark object
2023-10-09 03:09:34,416 - Create_spark -INFO -get_spark_object method started
2023-10-09 03:09:34,416 - Create_spark -INFO -master is local
2023-10-09 03:09:38,635 - root -INFO -Validating spark object..........
2023-10-09 03:09:38,635 - Validate -WARNING -started the get_current_date method...
2023-10-09 03:09:42,317 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 03:09:42,317 - Validate -WARNING -Validation done go frwd...
2023-10-09 03:09:42,317 - root -INFO -reading file which is of > parquet
2023-10-09 03:09:42,317 - Ingest -WARNING -load_files method started...
2023-10-09 03:09:42,902 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 03:09:42,902 - root -INFO -displaying file
2023-10-09 03:09:44,931 - root -INFO -here to validate the df
2023-10-09 03:09:44,931 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 03:09:45,378 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 03:09:45,378 - root -INFO -checking for the files in the Fact...
2023-10-09 03:09:45,378 - root -INFO -reading file which is of > csv
2023-10-09 03:09:45,378 - Ingest -WARNING -load_files method started...
2023-10-09 03:09:49,316 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 03:09:49,317 - root -INFO -displaying the df_fact dataframe
2023-10-09 03:09:49,568 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 03:09:50,119 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 03:09:50,119 - root -INFO -implementing data_processing methods...
2023-10-09 03:09:50,119 - Data_processing -WARNING -data_clean method started...
2023-10-09 03:09:50,119 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 03:09:50,156 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 03:09:50,176 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 03:09:50,186 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 03:09:50,231 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 03:09:50,247 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 03:09:50,263 - Data_processing -WARNING -Checking for null values...
2023-10-09 03:09:50,263 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 03:09:50,279 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 03:09:52,477 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 03:09:52,477 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 03:09:52,829 - root -INFO -validating schema for the dataframes....
2023-10-09 03:09:52,829 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 03:09:52,830 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 03:09:52,830 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 03:09:52,830 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 03:09:52,830 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 03:09:52,830 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 03:09:52,830 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 03:09:52,830 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:09:52,830 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 03:09:52,832 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 03:09:52,832 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:09:52,832 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 03:09:53,035 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 03:10:10,097 - root -INFO -data transformation executed...
2023-10-09 03:10:10,097 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 03:10:10,100 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 03:10:10,131 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 03:10:10,161 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 03:10:10,195 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 03:10:10,195 - root -INFO -displaying the df_report_1
2023-10-09 03:39:20,669 - root -INFO -i am in the main method..
2023-10-09 03:39:20,669 - root -INFO -calling spark object
2023-10-09 03:39:20,669 - Create_spark -INFO -get_spark_object method started
2023-10-09 03:39:20,669 - Create_spark -INFO -master is local
2023-10-09 03:39:24,850 - root -INFO -Validating spark object..........
2023-10-09 03:39:24,851 - Validate -WARNING -started the get_current_date method...
2023-10-09 03:39:28,299 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 03:39:28,299 - Validate -WARNING -Validation done go frwd...
2023-10-09 03:39:28,299 - root -INFO -reading file which is of > parquet
2023-10-09 03:39:28,299 - Ingest -WARNING -load_files method started...
2023-10-09 03:39:28,899 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 03:39:28,899 - root -INFO -displaying file
2023-10-09 03:39:30,820 - root -INFO -here to validate the df
2023-10-09 03:39:30,820 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 03:39:31,341 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 03:39:31,341 - root -INFO -checking for the files in the Fact...
2023-10-09 03:39:31,341 - root -INFO -reading file which is of > csv
2023-10-09 03:39:31,341 - Ingest -WARNING -load_files method started...
2023-10-09 03:39:35,590 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 03:39:35,590 - root -INFO -displaying the df_fact dataframe
2023-10-09 03:39:35,828 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 03:39:36,374 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 03:39:36,374 - root -INFO -implementing data_processing methods...
2023-10-09 03:39:36,374 - Data_processing -WARNING -data_clean method started...
2023-10-09 03:39:36,374 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 03:39:36,413 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 03:39:36,434 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 03:39:36,443 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 03:39:36,484 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 03:39:36,504 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 03:39:36,515 - Data_processing -WARNING -Checking for null values...
2023-10-09 03:39:36,515 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 03:39:36,531 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 03:39:38,821 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 03:39:38,822 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 03:39:39,197 - root -INFO -validating schema for the dataframes....
2023-10-09 03:39:39,197 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 03:39:39,198 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 03:39:39,199 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 03:39:39,199 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 03:39:39,199 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 03:39:39,199 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 03:39:39,199 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 03:39:39,199 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:39:39,199 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 03:39:39,200 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 03:39:39,200 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:39:39,201 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 03:39:39,365 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 03:39:56,660 - root -INFO -data transformation executed...
2023-10-09 03:39:56,661 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 03:39:56,664 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 03:39:56,692 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 03:39:56,720 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 03:39:56,761 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 03:39:56,761 - root -INFO -displaying the df_report_1
2023-10-09 03:50:05,025 - root -INFO -i am in the main method..
2023-10-09 03:50:05,025 - root -INFO -calling spark object
2023-10-09 03:50:05,025 - Create_spark -INFO -get_spark_object method started
2023-10-09 03:50:05,025 - Create_spark -INFO -master is local
2023-10-09 03:50:19,922 - root -INFO -Validating spark object..........
2023-10-09 03:50:19,922 - Validate -WARNING -started the get_current_date method...
2023-10-09 03:50:22,907 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 03:50:22,907 - Validate -WARNING -Validation done go frwd...
2023-10-09 03:50:22,907 - root -INFO -reading file which is of > parquet
2023-10-09 03:50:22,907 - Ingest -WARNING -load_files method started...
2023-10-09 03:50:23,424 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 03:50:23,425 - root -INFO -displaying file
2023-10-09 03:50:25,350 - root -INFO -here to validate the df
2023-10-09 03:50:25,350 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 03:50:25,850 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 03:50:25,850 - root -INFO -checking for the files in the Fact...
2023-10-09 03:50:25,851 - root -INFO -reading file which is of > csv
2023-10-09 03:50:25,851 - Ingest -WARNING -load_files method started...
2023-10-09 03:50:30,043 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 03:50:30,044 - root -INFO -displaying the df_fact dataframe
2023-10-09 03:50:30,280 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 03:50:30,827 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 03:50:30,827 - root -INFO -implementing data_processing methods...
2023-10-09 03:50:30,827 - Data_processing -WARNING -data_clean method started...
2023-10-09 03:50:30,827 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 03:50:30,861 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 03:50:30,881 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 03:50:30,891 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 03:50:30,928 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 03:50:30,943 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 03:50:30,956 - Data_processing -WARNING -Checking for null values...
2023-10-09 03:50:30,957 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 03:50:30,974 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 03:50:33,191 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 03:50:33,191 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 03:50:33,520 - root -INFO -validating schema for the dataframes....
2023-10-09 03:50:33,520 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 03:50:33,522 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 03:50:33,522 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 03:50:33,522 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 03:50:33,522 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 03:50:33,522 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 03:50:33,522 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 03:50:33,522 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:50:33,522 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 03:50:33,524 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 03:50:33,524 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:50:33,524 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 03:50:33,670 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 03:50:50,699 - root -INFO -data transformation executed...
2023-10-09 03:50:50,699 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 03:50:50,704 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 03:50:50,723 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 03:50:50,744 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 03:50:50,776 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 03:50:50,776 - root -INFO -displaying the df_report_1
2023-10-09 03:53:45,919 - root -INFO -i am in the main method..
2023-10-09 03:53:45,919 - root -INFO -calling spark object
2023-10-09 03:53:45,919 - Create_spark -INFO -get_spark_object method started
2023-10-09 03:53:45,919 - Create_spark -INFO -master is local
2023-10-09 03:53:49,660 - root -INFO -Validating spark object..........
2023-10-09 03:53:49,660 - Validate -WARNING -started the get_current_date method...
2023-10-09 03:53:52,968 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 03:53:52,968 - Validate -WARNING -Validation done go frwd...
2023-10-09 03:53:52,969 - root -INFO -reading file which is of > parquet
2023-10-09 03:53:52,969 - Ingest -WARNING -load_files method started...
2023-10-09 03:53:53,514 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 03:53:53,514 - root -INFO -displaying file
2023-10-09 03:53:55,325 - root -INFO -here to validate the df
2023-10-09 03:53:55,325 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 03:53:56,520 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 03:53:56,520 - root -INFO -checking for the files in the Fact...
2023-10-09 03:53:56,521 - root -INFO -reading file which is of > csv
2023-10-09 03:53:56,521 - Ingest -WARNING -load_files method started...
2023-10-09 03:54:09,140 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 03:54:09,140 - root -INFO -displaying the df_fact dataframe
2023-10-09 03:54:10,045 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 03:54:11,813 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 03:54:11,814 - root -INFO -implementing data_processing methods...
2023-10-09 03:54:11,814 - Data_processing -WARNING -data_clean method started...
2023-10-09 03:54:11,814 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 03:54:11,884 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 03:54:12,009 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 03:54:12,041 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 03:54:12,139 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 03:54:12,190 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 03:54:12,216 - Data_processing -WARNING -Checking for null values...
2023-10-09 03:54:12,216 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 03:54:12,256 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 03:54:19,528 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 03:54:19,528 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 03:54:20,683 - root -INFO -validating schema for the dataframes....
2023-10-09 03:54:20,684 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 03:54:20,686 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 03:54:20,686 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 03:54:20,687 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 03:54:20,687 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 03:54:20,687 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 03:54:20,687 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 03:54:20,687 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:54:20,687 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 03:54:20,690 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 03:54:20,690 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 03:54:20,690 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 03:54:20,690 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 03:54:20,690 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 03:54:20,690 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 03:54:20,691 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 03:54:20,691 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 03:54:20,691 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 03:54:20,691 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 03:54:20,691 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 03:54:20,691 - Validate -INFO -print_schema done, go frwd...
2023-10-09 03:54:20,691 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 03:54:21,010 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 03:54:51,970 - root -INFO -data transformation executed...
2023-10-09 03:54:51,970 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 03:54:51,974 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 03:54:52,002 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 03:54:52,025 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 03:54:52,055 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 03:54:52,055 - root -INFO -displaying the df_report_1
2023-10-09 04:06:21,411 - root -INFO -i am in the main method..
2023-10-09 04:06:21,411 - root -INFO -calling spark object
2023-10-09 04:06:21,411 - Create_spark -INFO -get_spark_object method started
2023-10-09 04:06:21,411 - Create_spark -INFO -master is local
2023-10-09 04:06:25,045 - root -INFO -Validating spark object..........
2023-10-09 04:06:25,045 - Validate -WARNING -started the get_current_date method...
2023-10-09 04:06:28,070 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 04:06:28,071 - Validate -WARNING -Validation done go frwd...
2023-10-09 04:06:28,071 - root -INFO -reading file which is of > parquet
2023-10-09 04:06:28,071 - Ingest -WARNING -load_files method started...
2023-10-09 04:06:28,553 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 04:06:28,553 - root -INFO -displaying file
2023-10-09 04:06:30,169 - root -INFO -here to validate the df
2023-10-09 04:06:30,169 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 04:06:30,587 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 04:06:30,587 - root -INFO -checking for the files in the Fact...
2023-10-09 04:06:30,587 - root -INFO -reading file which is of > csv
2023-10-09 04:06:30,588 - Ingest -WARNING -load_files method started...
2023-10-09 04:06:34,569 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 04:06:34,569 - root -INFO -displaying the df_fact dataframe
2023-10-09 04:06:34,796 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 04:06:35,342 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 04:06:35,342 - root -INFO -implementing data_processing methods...
2023-10-09 04:06:35,342 - Data_processing -WARNING -data_clean method started...
2023-10-09 04:06:35,342 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 04:06:35,377 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 04:06:35,400 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 04:06:35,411 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 04:06:35,444 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 04:06:35,461 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 04:06:35,472 - Data_processing -WARNING -Checking for null values...
2023-10-09 04:06:35,472 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 04:06:35,490 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 04:06:37,794 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 04:06:37,794 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 04:06:38,129 - root -INFO -validating schema for the dataframes....
2023-10-09 04:06:38,129 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 04:06:38,130 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 04:06:38,130 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 04:06:38,131 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 04:06:38,131 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 04:06:38,131 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 04:06:38,131 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 04:06:38,131 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:06:38,131 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 04:06:38,132 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 04:06:38,132 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:06:38,132 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 04:06:38,250 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 04:06:55,020 - root -INFO -data transformation executed...
2023-10-09 04:06:55,020 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 04:06:55,025 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 04:06:55,050 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 04:06:55,074 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 04:06:55,113 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 04:06:55,114 - root -INFO -displaying the df_report_1
2023-10-09 04:19:19,525 - root -INFO -i am in the main method..
2023-10-09 04:19:19,525 - root -INFO -calling spark object
2023-10-09 04:19:19,525 - Create_spark -INFO -get_spark_object method started
2023-10-09 04:19:19,525 - Create_spark -INFO -master is local
2023-10-09 04:19:23,770 - root -INFO -Validating spark object..........
2023-10-09 04:19:23,770 - Validate -WARNING -started the get_current_date method...
2023-10-09 04:19:27,374 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 04:19:27,374 - Validate -WARNING -Validation done go frwd...
2023-10-09 04:19:27,374 - root -INFO -reading file which is of > parquet
2023-10-09 04:19:27,374 - Ingest -WARNING -load_files method started...
2023-10-09 04:19:27,972 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 04:19:27,972 - root -INFO -displaying file
2023-10-09 04:19:29,933 - root -INFO -here to validate the df
2023-10-09 04:19:29,933 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 04:19:30,460 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 04:19:30,460 - root -INFO -checking for the files in the Fact...
2023-10-09 04:19:30,460 - root -INFO -reading file which is of > csv
2023-10-09 04:19:30,460 - Ingest -WARNING -load_files method started...
2023-10-09 04:19:35,573 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 04:19:35,574 - root -INFO -displaying the df_fact dataframe
2023-10-09 04:19:36,402 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 04:19:38,114 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 04:19:38,114 - root -INFO -implementing data_processing methods...
2023-10-09 04:19:38,115 - Data_processing -WARNING -data_clean method started...
2023-10-09 04:19:38,115 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 04:19:38,198 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 04:19:38,273 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 04:19:38,303 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 04:19:38,413 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 04:19:38,482 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 04:19:38,535 - Data_processing -WARNING -Checking for null values...
2023-10-09 04:19:38,536 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 04:19:38,600 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 04:19:46,061 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 04:19:46,061 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 04:19:47,497 - root -INFO -validating schema for the dataframes....
2023-10-09 04:19:47,497 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 04:19:47,500 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 04:19:47,501 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 04:19:47,501 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 04:19:47,501 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 04:19:47,501 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 04:19:47,502 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 04:19:47,502 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:19:47,502 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 04:19:47,518 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 04:19:47,520 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 04:19:47,520 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 04:19:47,527 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 04:19:47,528 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:19:47,528 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 04:19:47,931 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 04:20:34,135 - root -INFO -data transformation executed...
2023-10-09 04:20:34,136 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 04:20:34,141 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 04:20:34,264 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 04:20:34,302 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 04:20:34,485 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 04:20:34,485 - root -INFO -displaying the df_report_1
2023-10-09 04:27:56,332 - root -INFO -i am in the main method..
2023-10-09 04:27:56,332 - root -INFO -calling spark object
2023-10-09 04:27:56,332 - Create_spark -INFO -get_spark_object method started
2023-10-09 04:27:56,333 - Create_spark -INFO -master is local
2023-10-09 04:27:59,919 - root -INFO -Validating spark object..........
2023-10-09 04:27:59,919 - Validate -WARNING -started the get_current_date method...
2023-10-09 04:28:03,107 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 04:28:03,107 - Validate -WARNING -Validation done go frwd...
2023-10-09 04:28:03,107 - root -INFO -reading file which is of > parquet
2023-10-09 04:28:03,108 - Ingest -WARNING -load_files method started...
2023-10-09 04:28:03,720 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 04:28:03,720 - root -INFO -displaying file
2023-10-09 04:28:06,744 - root -INFO -here to validate the df
2023-10-09 04:28:06,744 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 04:28:08,073 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 04:28:08,074 - root -INFO -checking for the files in the Fact...
2023-10-09 04:28:08,075 - root -INFO -reading file which is of > csv
2023-10-09 04:28:08,076 - Ingest -WARNING -load_files method started...
2023-10-09 04:28:16,286 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 04:28:16,286 - root -INFO -displaying the df_fact dataframe
2023-10-09 04:28:16,612 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 04:28:17,605 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 04:28:17,606 - root -INFO -implementing data_processing methods...
2023-10-09 04:28:17,606 - Data_processing -WARNING -data_clean method started...
2023-10-09 04:28:17,606 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 04:28:17,695 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 04:28:17,768 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 04:28:17,813 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 04:28:17,905 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 04:28:17,954 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 04:28:17,998 - Data_processing -WARNING -Checking for null values...
2023-10-09 04:28:17,999 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 04:28:18,056 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 04:28:25,042 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 04:28:25,044 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 04:28:26,181 - root -INFO -validating schema for the dataframes....
2023-10-09 04:28:26,181 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 04:28:26,184 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 04:28:26,184 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 04:28:26,184 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 04:28:26,184 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 04:28:26,184 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 04:28:26,185 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 04:28:26,185 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:28:26,185 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 04:28:26,190 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 04:28:26,191 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 04:28:26,191 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 04:28:26,191 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 04:28:26,191 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 04:28:26,191 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 04:28:26,191 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 04:28:26,191 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 04:28:26,192 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 04:28:26,192 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 04:28:26,192 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 04:28:26,192 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:28:26,192 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 04:28:26,583 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 04:29:13,285 - root -INFO -data transformation executed...
2023-10-09 04:29:13,285 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 04:29:13,292 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 04:29:13,316 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 04:29:13,340 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 04:29:13,373 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 04:29:13,373 - root -INFO -displaying the df_report_1
2023-10-09 04:37:48,082 - root -INFO -i am in the main method..
2023-10-09 04:37:48,082 - root -INFO -calling spark object
2023-10-09 04:37:48,082 - Create_spark -INFO -get_spark_object method started
2023-10-09 04:37:48,082 - Create_spark -INFO -master is local
2023-10-09 04:37:51,764 - root -INFO -Validating spark object..........
2023-10-09 04:37:51,764 - Validate -WARNING -started the get_current_date method...
2023-10-09 04:37:54,968 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 04:37:54,968 - Validate -WARNING -Validation done go frwd...
2023-10-09 04:37:54,968 - root -INFO -reading file which is of > parquet
2023-10-09 04:37:54,968 - Ingest -WARNING -load_files method started...
2023-10-09 04:37:55,465 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 04:37:55,466 - root -INFO -displaying file
2023-10-09 04:37:57,121 - root -INFO -here to validate the df
2023-10-09 04:37:57,121 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 04:37:57,578 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 04:37:57,578 - root -INFO -checking for the files in the Fact...
2023-10-09 04:37:57,579 - root -INFO -reading file which is of > csv
2023-10-09 04:37:57,579 - Ingest -WARNING -load_files method started...
2023-10-09 04:38:01,337 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 04:38:01,337 - root -INFO -displaying the df_fact dataframe
2023-10-09 04:38:01,571 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 04:38:02,103 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 04:38:02,103 - root -INFO -implementing data_processing methods...
2023-10-09 04:38:02,104 - Data_processing -WARNING -data_clean method started...
2023-10-09 04:38:02,104 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 04:38:02,145 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 04:38:02,171 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 04:38:02,181 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 04:38:02,217 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 04:38:02,233 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 04:38:02,243 - Data_processing -WARNING -Checking for null values...
2023-10-09 04:38:02,243 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 04:38:02,258 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 04:38:04,454 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 04:38:04,454 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 04:38:04,895 - root -INFO -validating schema for the dataframes....
2023-10-09 04:38:04,895 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 04:38:04,896 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 04:38:04,896 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 04:38:04,896 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 04:38:04,896 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 04:38:04,896 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 04:38:04,897 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 04:38:04,897 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:38:04,897 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 04:38:04,897 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 04:38:04,898 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 04:38:04,898 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:38:04,898 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 04:38:05,019 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 04:38:22,193 - root -INFO -data transformation executed...
2023-10-09 04:38:22,193 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 04:38:22,196 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 04:38:22,221 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 04:38:22,246 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 04:38:22,278 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 04:38:22,278 - root -INFO -displaying the df_report_1
2023-10-09 04:41:02,318 - root -INFO -i am in the main method..
2023-10-09 04:41:02,319 - root -INFO -calling spark object
2023-10-09 04:41:02,319 - Create_spark -INFO -get_spark_object method started
2023-10-09 04:41:02,319 - Create_spark -INFO -master is local
2023-10-09 04:41:16,267 - root -INFO -Validating spark object..........
2023-10-09 04:41:16,267 - Validate -WARNING -started the get_current_date method...
2023-10-09 04:41:19,253 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 04:41:19,253 - Validate -WARNING -Validation done go frwd...
2023-10-09 04:41:19,253 - root -INFO -reading file which is of > parquet
2023-10-09 04:41:19,253 - Ingest -WARNING -load_files method started...
2023-10-09 04:41:19,780 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 04:41:19,780 - root -INFO -displaying file
2023-10-09 04:41:21,219 - root -INFO -here to validate the df
2023-10-09 04:41:21,219 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 04:41:21,665 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 04:41:21,665 - root -INFO -checking for the files in the Fact...
2023-10-09 04:41:21,665 - root -INFO -reading file which is of > csv
2023-10-09 04:41:21,665 - Ingest -WARNING -load_files method started...
2023-10-09 04:41:24,934 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 04:41:24,934 - root -INFO -displaying the df_fact dataframe
2023-10-09 04:41:25,141 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 04:41:25,635 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 04:41:25,635 - root -INFO -implementing data_processing methods...
2023-10-09 04:41:25,635 - Data_processing -WARNING -data_clean method started...
2023-10-09 04:41:25,635 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 04:41:25,667 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 04:41:25,683 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 04:41:25,693 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 04:41:25,729 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 04:41:25,742 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 04:41:25,749 - Data_processing -WARNING -Checking for null values...
2023-10-09 04:41:25,750 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 04:41:25,770 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 04:41:27,430 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 04:41:27,430 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 04:41:27,723 - root -INFO -validating schema for the dataframes....
2023-10-09 04:41:27,723 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 04:41:27,724 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 04:41:27,724 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 04:41:27,724 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 04:41:27,724 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 04:41:27,724 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 04:41:27,724 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 04:41:27,724 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:41:27,724 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 04:41:27,725 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 04:41:27,725 - Validate -INFO -print_schema done, go frwd...
2023-10-09 04:41:27,725 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 04:41:27,827 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 04:41:42,803 - root -INFO -data transformation executed...
2023-10-09 04:41:42,803 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 04:41:42,806 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 04:41:42,838 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 04:41:42,868 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 04:41:42,908 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 04:41:42,908 - root -INFO -displaying the df_report_1
2023-10-09 04:41:53,963 - root -INFO -Application done
2023-10-09 21:04:54,570 - root -INFO -i am in the main method..
2023-10-09 21:04:54,571 - root -INFO -calling spark object
2023-10-09 21:04:54,571 - Create_spark -INFO -get_spark_object method started
2023-10-09 21:04:54,571 - Create_spark -INFO -master is local
2023-10-09 21:05:12,656 - root -INFO -Validating spark object..........
2023-10-09 21:05:12,656 - Validate -WARNING -started the get_current_date method...
2023-10-09 21:05:20,228 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 21:05:20,228 - Validate -WARNING -Validation done go frwd...
2023-10-09 21:05:20,229 - root -INFO -reading file which is of > parquet
2023-10-09 21:05:20,229 - Ingest -WARNING -load_files method started...
2023-10-09 21:05:21,886 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 21:05:21,886 - root -INFO -displaying file
2023-10-09 21:05:27,067 - root -INFO -here to validate the df
2023-10-09 21:05:27,067 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 21:05:28,373 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 21:05:28,373 - root -INFO -checking for the files in the Fact...
2023-10-09 21:05:28,373 - root -INFO -reading file which is of > csv
2023-10-09 21:05:28,374 - Ingest -WARNING -load_files method started...
2023-10-09 21:05:41,272 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 21:05:41,272 - root -INFO -displaying the df_fact dataframe
2023-10-09 21:05:41,978 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 21:05:43,629 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 21:05:43,629 - root -INFO -implementing data_processing methods...
2023-10-09 21:05:43,630 - Data_processing -WARNING -data_clean method started...
2023-10-09 21:05:43,630 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 21:05:43,735 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 21:05:43,793 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 21:05:43,825 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 21:05:43,916 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 21:05:43,955 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 21:05:43,983 - Data_processing -WARNING -Checking for null values...
2023-10-09 21:05:43,984 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 21:05:44,024 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 21:05:51,219 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 21:05:51,219 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 21:05:52,207 - root -INFO -validating schema for the dataframes....
2023-10-09 21:05:52,207 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 21:05:52,210 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 21:05:52,211 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 21:05:52,211 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 21:05:52,211 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 21:05:52,211 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 21:05:52,212 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 21:05:52,212 - Validate -INFO -print_schema done, go frwd...
2023-10-09 21:05:52,212 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 21:05:52,215 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 21:05:52,215 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 21:05:52,215 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 21:05:52,215 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 21:05:52,215 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 21:05:52,215 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 21:05:52,216 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 21:05:52,216 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 21:05:52,216 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 21:05:52,216 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 21:05:52,216 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 21:05:52,216 - Validate -INFO -print_schema done, go frwd...
2023-10-09 21:05:52,216 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 21:05:52,607 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 21:06:22,794 - root -INFO -data transformation executed...
2023-10-09 21:06:22,794 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 21:06:22,797 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 21:06:22,814 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 21:06:22,838 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 21:06:22,875 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 21:06:22,875 - root -INFO -displaying the df_report_1
2023-10-09 21:06:34,339 - root -INFO -Application done
2023-10-09 21:24:59,434 - root -INFO -i am in the main method..
2023-10-09 21:24:59,435 - root -INFO -calling spark object
2023-10-09 21:24:59,435 - Create_spark -INFO -get_spark_object method started
2023-10-09 21:24:59,435 - Create_spark -INFO -master is local
2023-10-09 21:25:03,054 - root -INFO -Validating spark object..........
2023-10-09 21:25:03,054 - Validate -WARNING -started the get_current_date method...
2023-10-09 21:25:06,158 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 9))]
2023-10-09 21:25:06,158 - Validate -WARNING -Validation done go frwd...
2023-10-09 21:25:06,159 - root -INFO -reading file which is of > parquet
2023-10-09 21:25:06,159 - Ingest -WARNING -load_files method started...
2023-10-09 21:25:06,696 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-09 21:25:06,696 - root -INFO -displaying file
2023-10-09 21:25:08,335 - root -INFO -here to validate the df
2023-10-09 21:25:08,335 - Ingest -WARNING -here to count the records in the df_city
2023-10-09 21:25:08,786 - Ingest -WARNING -number of records 28338 :: 
2023-10-09 21:25:08,786 - root -INFO -checking for the files in the Fact...
2023-10-09 21:25:08,787 - root -INFO -reading file which is of > csv
2023-10-09 21:25:08,787 - Ingest -WARNING -load_files method started...
2023-10-09 21:25:12,607 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-09 21:25:12,607 - root -INFO -displaying the df_fact dataframe
2023-10-09 21:25:12,865 - Ingest -WARNING -here to count the records in the df_fact
2023-10-09 21:25:13,412 - Ingest -WARNING -number of records 1329329 :: 
2023-10-09 21:25:13,412 - root -INFO -implementing data_processing methods...
2023-10-09 21:25:13,412 - Data_processing -WARNING -data_clean method started...
2023-10-09 21:25:13,412 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-09 21:25:13,446 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-09 21:25:13,468 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-09 21:25:13,479 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-09 21:25:13,511 - Data_processing -WARNING -Concat fname and lname...
2023-10-09 21:25:13,530 - Data_processing -WARNING -Dropping fname and lname...
2023-10-09 21:25:13,541 - Data_processing -WARNING -Checking for null values...
2023-10-09 21:25:13,541 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-09 21:25:13,559 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-09 21:25:15,801 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-09 21:25:15,801 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-09 21:25:16,127 - root -INFO -validating schema for the dataframes....
2023-10-09 21:25:16,127 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-09 21:25:16,128 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-09 21:25:16,128 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-09 21:25:16,128 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-09 21:25:16,128 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-09 21:25:16,128 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-09 21:25:16,128 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-09 21:25:16,128 - Validate -INFO -print_schema done, go frwd...
2023-10-09 21:25:16,128 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-09 21:25:16,129 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-09 21:25:16,129 - Validate -INFO -print_schema done, go frwd...
2023-10-09 21:25:16,129 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-09 21:25:16,259 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-09 21:25:33,057 - root -INFO -data transformation executed...
2023-10-09 21:25:33,057 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-09 21:25:33,061 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-09 21:25:33,087 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-09 21:25:33,110 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-09 21:25:33,140 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-09 21:25:33,141 - root -INFO -displaying the df_report_1
2023-10-09 21:25:43,048 - root -INFO -Application done
2023-10-10 04:17:06,039 - root -INFO -i am in the main method..
2023-10-10 04:17:06,039 - root -INFO -calling spark object
2023-10-10 04:17:06,040 - Create_spark -INFO -get_spark_object method started
2023-10-10 04:17:06,040 - Create_spark -INFO -master is local
2023-10-10 04:17:10,697 - root -INFO -Validating spark object..........
2023-10-10 04:17:10,697 - Validate -WARNING -started the get_current_date method...
2023-10-10 04:17:14,335 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 10))]
2023-10-10 04:17:14,335 - Validate -WARNING -Validation done go frwd...
2023-10-10 04:17:14,335 - root -INFO -reading file which is of > parquet
2023-10-10 04:17:14,335 - Ingest -WARNING -load_files method started...
2023-10-10 04:17:15,131 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-10 04:17:15,131 - root -INFO -displaying file
2023-10-10 04:17:17,271 - root -INFO -here to validate the df
2023-10-10 04:17:17,271 - Ingest -WARNING -here to count the records in the df_city
2023-10-10 04:17:17,797 - Ingest -WARNING -number of records 28338 :: 
2023-10-10 04:17:17,797 - root -INFO -checking for the files in the Fact...
2023-10-10 04:17:17,797 - root -INFO -reading file which is of > csv
2023-10-10 04:17:17,798 - Ingest -WARNING -load_files method started...
2023-10-10 04:17:22,042 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-10 04:17:22,042 - root -INFO -displaying the df_fact dataframe
2023-10-10 04:17:22,360 - Ingest -WARNING -here to count the records in the df_fact
2023-10-10 04:17:22,918 - Ingest -WARNING -number of records 1329329 :: 
2023-10-10 04:17:22,918 - root -INFO -implementing data_processing methods...
2023-10-10 04:17:22,918 - Data_processing -WARNING -data_clean method started...
2023-10-10 04:17:22,918 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-10 04:17:22,953 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-10 04:17:22,969 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-10 04:17:22,983 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-10 04:17:23,018 - Data_processing -WARNING -Concat fname and lname...
2023-10-10 04:17:23,040 - Data_processing -WARNING -Dropping fname and lname...
2023-10-10 04:17:23,048 - Data_processing -WARNING -Checking for null values...
2023-10-10 04:17:23,048 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-10 04:17:23,066 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-10 04:17:25,529 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-10 04:17:25,529 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-10 04:17:25,846 - root -INFO -validating schema for the dataframes....
2023-10-10 04:17:25,846 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-10 04:17:25,847 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-10 04:17:25,847 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-10 04:17:25,847 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-10 04:17:25,847 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-10 04:17:25,847 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-10 04:17:25,847 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-10 04:17:25,847 - Validate -INFO -print_schema done, go frwd...
2023-10-10 04:17:25,847 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-10 04:17:25,848 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-10 04:17:25,848 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-10 04:17:25,848 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-10 04:17:25,848 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-10 04:17:25,848 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-10 04:17:25,849 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-10 04:17:25,849 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-10 04:17:25,849 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-10 04:17:25,849 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-10 04:17:25,849 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-10 04:17:25,849 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-10 04:17:25,849 - Validate -INFO -print_schema done, go frwd...
2023-10-10 04:17:25,849 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-10 04:17:25,964 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-10 04:17:43,845 - root -INFO -data transformation executed...
2023-10-10 04:17:43,845 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-10 04:17:43,848 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-10 04:17:43,876 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-10 04:17:43,903 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-10 04:17:43,934 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-10 04:17:43,934 - root -INFO -displaying the df_report_1
2023-10-10 04:17:55,052 - root -INFO -Displaying data_report2 method....
2023-10-10 04:17:55,052 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-10 04:17:55,053 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-10 04:17:55,151 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-10 04:18:02,614 - root -INFO -Total amount of time taken : 56.57 seconds
2023-10-10 04:18:02,614 - root -INFO -Application done
2023-10-11 03:58:15,995 - root -INFO -i am in the main method..
2023-10-11 03:58:15,995 - root -INFO -calling spark object
2023-10-11 03:58:15,995 - Create_spark -INFO -get_spark_object method started
2023-10-11 03:58:15,995 - Create_spark -INFO -master is local
2023-10-11 03:58:33,484 - root -INFO -Validating spark object..........
2023-10-11 03:58:33,484 - Validate -WARNING -started the get_current_date method...
2023-10-11 03:58:37,678 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 11))]
2023-10-11 03:58:37,678 - Validate -WARNING -Validation done go frwd...
2023-10-11 03:58:37,678 - root -INFO -reading file which is of > parquet
2023-10-11 03:58:37,678 - Ingest -WARNING -load_files method started...
2023-10-11 03:58:38,388 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-11 03:58:38,388 - root -INFO -displaying file
2023-10-11 03:58:40,564 - root -INFO -here to validate the df
2023-10-11 03:58:40,564 - Ingest -WARNING -here to count the records in the df_city
2023-10-11 03:58:41,110 - Ingest -WARNING -number of records 28338 :: 
2023-10-11 03:58:41,110 - root -INFO -checking for the files in the Fact...
2023-10-11 03:58:41,110 - root -INFO -reading file which is of > csv
2023-10-11 03:58:41,110 - Ingest -WARNING -load_files method started...
2023-10-11 03:58:45,085 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-11 03:58:45,085 - root -INFO -displaying the df_fact dataframe
2023-10-11 03:58:45,328 - Ingest -WARNING -here to count the records in the df_fact
2023-10-11 03:58:45,896 - Ingest -WARNING -number of records 1329329 :: 
2023-10-11 03:58:45,896 - root -INFO -implementing data_processing methods...
2023-10-11 03:58:45,896 - Data_processing -WARNING -data_clean method started...
2023-10-11 03:58:45,896 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-11 03:58:45,930 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-11 03:58:45,952 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-11 03:58:45,965 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-11 03:58:46,002 - Data_processing -WARNING -Concat fname and lname...
2023-10-11 03:58:46,019 - Data_processing -WARNING -Dropping fname and lname...
2023-10-11 03:58:46,030 - Data_processing -WARNING -Checking for null values...
2023-10-11 03:58:46,030 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-11 03:58:46,053 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-11 03:58:48,231 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-11 03:58:48,231 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-11 03:58:48,618 - root -INFO -validating schema for the dataframes....
2023-10-11 03:58:48,619 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-11 03:58:48,620 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-11 03:58:48,620 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-11 03:58:48,620 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-11 03:58:48,620 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-11 03:58:48,620 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-11 03:58:48,620 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-11 03:58:48,620 - Validate -INFO -print_schema done, go frwd...
2023-10-11 03:58:48,620 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-11 03:58:48,622 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-11 03:58:48,622 - Validate -INFO -print_schema done, go frwd...
2023-10-11 03:58:48,622 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-11 03:58:48,770 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-11 03:59:04,499 - root -INFO -data transformation executed...
2023-10-11 03:59:04,499 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-11 03:59:04,501 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-11 03:59:04,527 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-11 03:59:04,552 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-11 03:59:04,583 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-11 03:59:04,583 - root -INFO -displaying the df_report_1
2023-10-11 03:59:15,905 - root -INFO -Displaying data_report2 method....
2023-10-11 03:59:15,905 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-11 03:59:15,905 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-11 03:59:15,992 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-11 03:59:22,925 - root -INFO -extracting files to output...
2023-10-11 03:59:22,926 - Extraction -WARNING -Executing extract_files method...
2023-10-11 04:35:52,292 - root -INFO -i am in the main method..
2023-10-11 04:35:52,292 - root -INFO -calling spark object
2023-10-11 04:35:52,292 - Create_spark -INFO -get_spark_object method started
2023-10-11 04:35:52,292 - Create_spark -INFO -master is local
2023-10-11 04:35:56,647 - root -INFO -Validating spark object..........
2023-10-11 04:35:56,647 - Validate -WARNING -started the get_current_date method...
2023-10-11 04:36:00,224 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 11))]
2023-10-11 04:36:00,224 - Validate -WARNING -Validation done go frwd...
2023-10-11 04:36:00,224 - root -INFO -reading file which is of > parquet
2023-10-11 04:36:00,224 - Ingest -WARNING -load_files method started...
2023-10-11 04:36:00,746 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-11 04:36:00,746 - root -INFO -displaying file
2023-10-11 04:36:02,463 - root -INFO -here to validate the df
2023-10-11 04:36:02,463 - Ingest -WARNING -here to count the records in the df_city
2023-10-11 04:36:03,013 - Ingest -WARNING -number of records 28338 :: 
2023-10-11 04:36:03,013 - root -INFO -checking for the files in the Fact...
2023-10-11 04:36:03,013 - root -INFO -reading file which is of > csv
2023-10-11 04:36:03,013 - Ingest -WARNING -load_files method started...
2023-10-11 04:36:07,019 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-11 04:36:07,019 - root -INFO -displaying the df_fact dataframe
2023-10-11 04:36:07,271 - Ingest -WARNING -here to count the records in the df_fact
2023-10-11 04:36:07,803 - Ingest -WARNING -number of records 1329329 :: 
2023-10-11 04:36:07,803 - root -INFO -implementing data_processing methods...
2023-10-11 04:36:07,803 - Data_processing -WARNING -data_clean method started...
2023-10-11 04:36:07,803 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-11 04:36:07,838 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-11 04:36:07,860 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-11 04:36:07,870 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-11 04:36:07,909 - Data_processing -WARNING -Concat fname and lname...
2023-10-11 04:36:07,927 - Data_processing -WARNING -Dropping fname and lname...
2023-10-11 04:36:07,935 - Data_processing -WARNING -Checking for null values...
2023-10-11 04:36:07,935 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-11 04:36:07,952 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-11 04:36:10,209 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-11 04:36:10,209 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-11 04:36:10,635 - root -INFO -validating schema for the dataframes....
2023-10-11 04:36:10,635 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-11 04:36:10,636 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-11 04:36:10,636 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-11 04:36:10,636 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-11 04:36:10,636 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-11 04:36:10,636 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-11 04:36:10,636 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-11 04:36:10,636 - Validate -INFO -print_schema done, go frwd...
2023-10-11 04:36:10,636 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-11 04:36:10,637 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-11 04:36:10,637 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-11 04:36:10,637 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-11 04:36:10,637 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-11 04:36:10,638 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-11 04:36:10,638 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-11 04:36:10,638 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-11 04:36:10,638 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-11 04:36:10,638 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-11 04:36:10,638 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-11 04:36:10,638 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-11 04:36:10,638 - Validate -INFO -print_schema done, go frwd...
2023-10-11 04:36:10,638 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-11 04:36:10,785 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-11 04:36:27,066 - root -INFO -data transformation executed...
2023-10-11 04:36:27,066 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-11 04:36:27,069 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-11 04:36:27,093 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-11 04:36:27,118 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-11 04:36:27,151 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-11 04:36:27,151 - root -INFO -displaying the df_report_1
2023-10-11 04:36:38,081 - root -INFO -Displaying data_report2 method....
2023-10-11 04:36:38,082 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-11 04:36:38,082 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-11 04:36:38,192 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-11 04:36:44,788 - root -INFO -extracting files to output...
2023-10-11 04:36:44,788 - Extraction -WARNING -Executing extract_files method...
2023-10-11 04:38:25,352 - root -INFO -i am in the main method..
2023-10-11 04:38:25,352 - root -INFO -calling spark object
2023-10-11 04:38:25,352 - Create_spark -INFO -get_spark_object method started
2023-10-11 04:38:25,352 - Create_spark -INFO -master is local
2023-10-11 04:38:29,234 - root -INFO -Validating spark object..........
2023-10-11 04:38:29,234 - Validate -WARNING -started the get_current_date method...
2023-10-11 04:38:32,429 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 11))]
2023-10-11 04:38:32,429 - Validate -WARNING -Validation done go frwd...
2023-10-11 04:38:32,429 - root -INFO -reading file which is of > parquet
2023-10-11 04:38:32,429 - Ingest -WARNING -load_files method started...
2023-10-11 04:38:33,013 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-11 04:38:33,013 - root -INFO -displaying file
2023-10-11 04:38:35,117 - root -INFO -here to validate the df
2023-10-11 04:38:35,117 - Ingest -WARNING -here to count the records in the df_city
2023-10-11 04:38:35,633 - Ingest -WARNING -number of records 28338 :: 
2023-10-11 04:38:35,633 - root -INFO -checking for the files in the Fact...
2023-10-11 04:38:35,633 - root -INFO -reading file which is of > csv
2023-10-11 04:38:35,633 - Ingest -WARNING -load_files method started...
2023-10-11 04:38:41,476 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-11 04:38:41,476 - root -INFO -displaying the df_fact dataframe
2023-10-11 04:38:42,265 - Ingest -WARNING -here to count the records in the df_fact
2023-10-11 04:38:44,063 - Ingest -WARNING -number of records 1329329 :: 
2023-10-11 04:38:44,063 - root -INFO -implementing data_processing methods...
2023-10-11 04:38:44,063 - Data_processing -WARNING -data_clean method started...
2023-10-11 04:38:44,063 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-11 04:38:44,158 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-11 04:38:44,218 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-11 04:38:44,281 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-11 04:38:44,423 - Data_processing -WARNING -Concat fname and lname...
2023-10-11 04:38:44,470 - Data_processing -WARNING -Dropping fname and lname...
2023-10-11 04:38:44,502 - Data_processing -WARNING -Checking for null values...
2023-10-11 04:38:44,502 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-11 04:38:44,559 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-11 04:38:51,924 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-11 04:38:51,924 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-11 04:38:53,059 - root -INFO -validating schema for the dataframes....
2023-10-11 04:38:53,059 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -print_schema done, go frwd...
2023-10-11 04:38:53,059 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-11 04:38:53,059 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-11 04:38:53,059 - Validate -INFO -print_schema done, go frwd...
2023-10-11 04:38:53,059 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-11 04:38:53,481 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-11 04:39:43,521 - root -INFO -data transformation executed...
2023-10-11 04:39:43,521 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-11 04:39:43,525 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-11 04:39:43,553 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-11 04:39:43,583 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-11 04:39:43,622 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-11 04:39:43,622 - root -INFO -displaying the df_report_1
2023-10-11 04:39:53,871 - root -INFO -Displaying data_report2 method....
2023-10-11 04:39:53,872 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-11 04:39:53,872 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-11 04:39:53,952 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-11 04:40:00,578 - root -INFO -extracting files to output...
2023-10-11 04:40:00,578 - Extraction -WARNING -Executing extract_files method...
2023-10-11 04:51:19,574 - root -INFO -i am in the main method..
2023-10-11 04:51:19,574 - root -INFO -calling spark object
2023-10-11 04:51:19,574 - Create_spark -INFO -get_spark_object method started
2023-10-11 04:51:19,574 - Create_spark -INFO -master is local
2023-10-11 04:51:23,286 - root -INFO -Validating spark object..........
2023-10-11 04:51:23,286 - Validate -WARNING -started the get_current_date method...
2023-10-11 04:51:26,349 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 11))]
2023-10-11 04:51:26,349 - Validate -WARNING -Validation done go frwd...
2023-10-11 04:51:26,350 - root -INFO -reading file which is of > parquet
2023-10-11 04:51:26,350 - Ingest -WARNING -load_files method started...
2023-10-11 04:51:26,842 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-11 04:51:26,842 - root -INFO -displaying file
2023-10-11 04:51:28,406 - root -INFO -here to validate the df
2023-10-11 04:51:28,406 - Ingest -WARNING -here to count the records in the df_city
2023-10-11 04:51:28,814 - Ingest -WARNING -number of records 28338 :: 
2023-10-11 04:51:28,814 - root -INFO -checking for the files in the Fact...
2023-10-11 04:51:28,814 - root -INFO -reading file which is of > csv
2023-10-11 04:51:28,814 - Ingest -WARNING -load_files method started...
2023-10-11 04:51:32,729 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-11 04:51:32,729 - root -INFO -displaying the df_fact dataframe
2023-10-11 04:51:32,982 - Ingest -WARNING -here to count the records in the df_fact
2023-10-11 04:51:33,527 - Ingest -WARNING -number of records 1329329 :: 
2023-10-11 04:51:33,527 - root -INFO -implementing data_processing methods...
2023-10-11 04:51:33,527 - Data_processing -WARNING -data_clean method started...
2023-10-11 04:51:33,527 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-11 04:51:33,560 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-11 04:51:33,579 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-11 04:51:33,589 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-11 04:51:33,630 - Data_processing -WARNING -Concat fname and lname...
2023-10-11 04:51:33,647 - Data_processing -WARNING -Dropping fname and lname...
2023-10-11 04:51:33,657 - Data_processing -WARNING -Checking for null values...
2023-10-11 04:51:33,657 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-11 04:51:33,675 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-11 04:51:35,920 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-11 04:51:35,920 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-11 04:51:36,315 - root -INFO -validating schema for the dataframes....
2023-10-11 04:51:36,315 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-11 04:51:36,316 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-11 04:51:36,316 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-11 04:51:36,316 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-11 04:51:36,316 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-11 04:51:36,316 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-11 04:51:36,316 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-11 04:51:36,316 - Validate -INFO -print_schema done, go frwd...
2023-10-11 04:51:36,316 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-11 04:51:36,318 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-11 04:51:36,318 - Validate -INFO -print_schema done, go frwd...
2023-10-11 04:51:36,318 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-11 04:51:36,457 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-11 04:51:52,666 - root -INFO -data transformation executed...
2023-10-11 04:51:52,666 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-11 04:51:52,670 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-11 04:51:52,703 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-11 04:51:52,729 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-11 04:51:52,767 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-11 04:51:52,767 - root -INFO -displaying the df_report_1
2023-10-11 04:52:03,112 - root -INFO -Displaying data_report2 method....
2023-10-11 04:52:03,112 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-11 04:52:03,112 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-11 04:52:03,196 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-11 04:52:09,622 - root -INFO -extracting files to output...
2023-10-11 04:52:09,622 - Extraction -WARNING -Executing extract_files method...
2023-10-11 05:01:19,957 - root -INFO -i am in the main method..
2023-10-11 05:01:19,957 - root -INFO -calling spark object
2023-10-11 05:01:19,958 - Create_spark -INFO -get_spark_object method started
2023-10-11 05:01:19,958 - Create_spark -INFO -master is local
2023-10-11 05:01:42,283 - root -INFO -Validating spark object..........
2023-10-11 05:01:42,283 - Validate -WARNING -started the get_current_date method...
2023-10-11 05:01:50,812 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 11))]
2023-10-11 05:01:50,813 - Validate -WARNING -Validation done go frwd...
2023-10-11 05:01:50,813 - root -INFO -reading file which is of > parquet
2023-10-11 05:01:50,813 - Ingest -WARNING -load_files method started...
2023-10-11 05:01:52,330 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-11 05:01:52,330 - root -INFO -displaying file
2023-10-11 05:01:56,633 - root -INFO -here to validate the df
2023-10-11 05:01:56,633 - Ingest -WARNING -here to count the records in the df_city
2023-10-11 05:01:57,896 - Ingest -WARNING -number of records 28338 :: 
2023-10-11 05:01:57,896 - root -INFO -checking for the files in the Fact...
2023-10-11 05:01:57,897 - root -INFO -reading file which is of > csv
2023-10-11 05:01:57,897 - Ingest -WARNING -load_files method started...
2023-10-11 05:02:10,007 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-11 05:02:10,007 - root -INFO -displaying the df_fact dataframe
2023-10-11 05:02:10,824 - Ingest -WARNING -here to count the records in the df_fact
2023-10-11 05:02:12,507 - Ingest -WARNING -number of records 1329329 :: 
2023-10-11 05:02:12,507 - root -INFO -implementing data_processing methods...
2023-10-11 05:02:12,507 - Data_processing -WARNING -data_clean method started...
2023-10-11 05:02:12,507 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-11 05:02:12,601 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-11 05:02:12,665 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-11 05:02:12,697 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-11 05:02:12,823 - Data_processing -WARNING -Concat fname and lname...
2023-10-11 05:02:12,896 - Data_processing -WARNING -Dropping fname and lname...
2023-10-11 05:02:12,969 - Data_processing -WARNING -Checking for null values...
2023-10-11 05:02:12,970 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-11 05:02:13,026 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-11 05:02:20,174 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-11 05:02:20,174 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-11 05:02:21,086 - root -INFO -validating schema for the dataframes....
2023-10-11 05:02:21,086 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-11 05:02:21,089 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-11 05:02:21,089 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-11 05:02:21,089 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-11 05:02:21,089 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-11 05:02:21,089 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-11 05:02:21,089 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-11 05:02:21,089 - Validate -INFO -print_schema done, go frwd...
2023-10-11 05:02:21,090 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-11 05:02:21,092 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-11 05:02:21,092 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-11 05:02:21,092 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-11 05:02:21,092 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-11 05:02:21,092 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-11 05:02:21,094 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-11 05:02:21,094 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-11 05:02:21,094 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-11 05:02:21,094 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-11 05:02:21,094 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-11 05:02:21,094 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-11 05:02:21,094 - Validate -INFO -print_schema done, go frwd...
2023-10-11 05:02:21,094 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-11 05:02:21,402 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-11 05:03:17,442 - root -INFO -data transformation executed...
2023-10-11 05:03:17,442 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-11 05:03:17,449 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-11 05:03:17,512 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-11 05:03:17,645 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-11 05:03:17,751 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-11 05:03:17,751 - root -INFO -displaying the df_report_1
2023-10-11 05:03:42,007 - root -INFO -Displaying data_report2 method....
2023-10-11 05:03:42,007 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-11 05:03:42,008 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-11 05:03:42,244 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-11 05:04:02,579 - root -INFO -extracting files to output...
2023-10-11 05:04:02,580 - Extraction -WARNING -Executing extract_files method...
2023-10-11 05:04:23,748 - Extraction -WARNING -extract_files method successfully executed...
2023-10-11 05:04:23,748 - Extraction -WARNING -Executing extract_files method...
2023-10-11 05:04:35,794 - Extraction -WARNING -extract_files method successfully executed...
2023-10-11 05:04:35,794 - root -INFO -Extracting files to output completed...
2023-10-11 05:04:35,794 - root -INFO -Total amount of time taken : 195.84 seconds
2023-10-11 05:04:35,794 - root -INFO -Application done
2023-10-12 02:13:48,536 - root -INFO -i am in the main method..
2023-10-12 02:13:48,537 - root -INFO -calling spark object
2023-10-12 02:13:48,537 - Create_spark -INFO -get_spark_object method started
2023-10-12 02:13:48,537 - Create_spark -INFO -master is local
2023-10-12 02:13:52,442 - root -INFO -Validating spark object..........
2023-10-12 02:13:52,442 - Validate -WARNING -started the get_current_date method...
2023-10-12 02:13:55,666 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 12))]
2023-10-12 02:13:55,666 - Validate -WARNING -Validation done go frwd...
2023-10-12 02:13:55,666 - root -INFO -reading file which is of > parquet
2023-10-12 02:13:55,666 - Ingest -WARNING -load_files method started...
2023-10-12 02:13:56,275 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-12 02:13:56,275 - root -INFO -displaying file
2023-10-12 02:13:57,924 - root -INFO -here to validate the df
2023-10-12 02:13:57,924 - Ingest -WARNING -here to count the records in the df_city
2023-10-12 02:13:58,422 - Ingest -WARNING -number of records 28338 :: 
2023-10-12 02:13:58,422 - root -INFO -checking for the files in the Fact...
2023-10-12 02:13:58,422 - root -INFO -reading file which is of > csv
2023-10-12 02:13:58,422 - Ingest -WARNING -load_files method started...
2023-10-12 02:14:02,311 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-12 02:14:02,311 - root -INFO -displaying the df_fact dataframe
2023-10-12 02:14:02,579 - Ingest -WARNING -here to count the records in the df_fact
2023-10-12 02:14:03,147 - Ingest -WARNING -number of records 1329329 :: 
2023-10-12 02:14:03,147 - root -INFO -implementing data_processing methods...
2023-10-12 02:14:03,147 - Data_processing -WARNING -data_clean method started...
2023-10-12 02:14:03,147 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-12 02:14:03,176 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-12 02:14:03,200 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-12 02:14:03,210 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-12 02:14:03,244 - Data_processing -WARNING -Concat fname and lname...
2023-10-12 02:14:03,260 - Data_processing -WARNING -Dropping fname and lname...
2023-10-12 02:14:03,271 - Data_processing -WARNING -Checking for null values...
2023-10-12 02:14:03,272 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-12 02:14:03,290 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-12 02:14:05,499 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-12 02:14:05,500 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-12 02:14:05,855 - root -INFO -validating schema for the dataframes....
2023-10-12 02:14:05,855 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-12 02:14:05,856 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-12 02:14:05,856 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-12 02:14:05,856 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-12 02:14:05,856 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-12 02:14:05,856 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-12 02:14:05,856 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-12 02:14:05,856 - Validate -INFO -print_schema done, go frwd...
2023-10-12 02:14:05,856 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-12 02:14:05,857 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-12 02:14:05,857 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-12 02:14:05,858 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-12 02:14:05,858 - Validate -INFO -print_schema done, go frwd...
2023-10-12 02:14:05,858 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-12 02:14:05,986 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-12 02:14:22,788 - root -INFO -data transformation executed...
2023-10-12 02:14:22,788 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-12 02:14:22,791 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-12 02:14:22,818 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-12 02:14:22,848 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-12 02:14:22,886 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-12 02:14:22,887 - root -INFO -displaying the df_report_1
2023-10-12 02:14:33,980 - root -INFO -Displaying data_report2 method....
2023-10-12 02:14:33,980 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-12 02:14:33,980 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-12 02:14:34,068 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-12 02:14:40,978 - root -INFO -extracting files to output...
2023-10-12 02:14:40,978 - Extraction -WARNING -Executing extract_files method...
2023-10-12 02:14:51,104 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 02:14:51,104 - Extraction -WARNING -Executing extract_files method...
2023-10-12 02:14:58,195 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 02:14:58,195 - root -INFO -Extracting files to output completed...
2023-10-12 02:14:58,195 - root -INFO -Writing data into Hive_table
2023-10-12 02:14:58,195 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-12 02:14:58,195 - Persist -WARNING -Creating Database
2023-10-12 02:15:02,158 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-12 02:15:14,039 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 02:15:14,039 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-12 02:15:14,039 - Persist -WARNING -Creating Database
2023-10-12 02:15:14,069 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-12 02:15:21,631 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 02:15:21,631 - root -INFO -Successfully written into Hive
2023-10-12 02:15:21,632 - root -INFO -Total amount of time taken : 93.10 seconds
2023-10-12 02:15:21,632 - root -INFO -Application done
2023-10-12 03:53:21,385 - root -INFO -i am in the main method..
2023-10-12 03:53:21,385 - root -INFO -calling spark object
2023-10-12 03:53:21,385 - Create_spark -INFO -get_spark_object method started
2023-10-12 03:53:21,385 - Create_spark -INFO -master is local
2023-10-12 03:53:37,981 - root -INFO -Validating spark object..........
2023-10-12 03:53:37,981 - Validate -WARNING -started the get_current_date method...
2023-10-12 03:53:41,372 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 12))]
2023-10-12 03:53:41,372 - Validate -WARNING -Validation done go frwd...
2023-10-12 03:53:41,372 - root -INFO -reading file which is of > parquet
2023-10-12 03:53:41,372 - Ingest -WARNING -load_files method started...
2023-10-12 03:53:41,864 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-12 03:53:41,864 - root -INFO -displaying file
2023-10-12 03:53:43,407 - root -INFO -here to validate the df
2023-10-12 03:53:43,407 - Ingest -WARNING -here to count the records in the df_city
2023-10-12 03:53:43,841 - Ingest -WARNING -number of records 28338 :: 
2023-10-12 03:53:43,841 - root -INFO -checking for the files in the Fact...
2023-10-12 03:53:43,841 - root -INFO -reading file which is of > csv
2023-10-12 03:53:43,841 - Ingest -WARNING -load_files method started...
2023-10-12 03:53:47,678 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-12 03:53:47,678 - root -INFO -displaying the df_fact dataframe
2023-10-12 03:53:47,878 - Ingest -WARNING -here to count the records in the df_fact
2023-10-12 03:53:48,506 - Ingest -WARNING -number of records 1329329 :: 
2023-10-12 03:53:48,506 - root -INFO -implementing data_processing methods...
2023-10-12 03:53:48,506 - Data_processing -WARNING -data_clean method started...
2023-10-12 03:53:48,506 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-12 03:53:48,538 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-12 03:53:48,554 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-12 03:53:48,569 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-12 03:53:48,609 - Data_processing -WARNING -Concat fname and lname...
2023-10-12 03:53:48,623 - Data_processing -WARNING -Dropping fname and lname...
2023-10-12 03:53:48,633 - Data_processing -WARNING -Checking for null values...
2023-10-12 03:53:48,633 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-12 03:53:48,653 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-12 03:53:50,969 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-12 03:53:50,969 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-12 03:53:51,331 - root -INFO -validating schema for the dataframes....
2023-10-12 03:53:51,331 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-12 03:53:51,331 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-12 03:53:51,332 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-12 03:53:51,332 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-12 03:53:51,332 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-12 03:53:51,332 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-12 03:53:51,332 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-12 03:53:51,332 - Validate -INFO -print_schema done, go frwd...
2023-10-12 03:53:51,332 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-12 03:53:51,333 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-12 03:53:51,333 - Validate -INFO -print_schema done, go frwd...
2023-10-12 03:53:51,334 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-12 03:53:51,450 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-12 03:54:07,818 - root -INFO -data transformation executed...
2023-10-12 03:54:07,818 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-12 03:54:07,822 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-12 03:54:07,853 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-12 03:54:07,881 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-12 03:54:07,914 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-12 03:54:07,914 - root -INFO -displaying the df_report_1
2023-10-12 03:54:18,321 - root -INFO -Displaying data_report2 method....
2023-10-12 03:54:18,321 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-12 03:54:18,321 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-12 03:54:18,419 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-12 03:54:24,798 - root -INFO -extracting files to output...
2023-10-12 03:54:24,799 - Extraction -WARNING -Executing extract_files method...
2023-10-12 03:54:33,927 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 03:54:33,927 - Extraction -WARNING -Executing extract_files method...
2023-10-12 03:54:40,471 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 03:54:40,471 - root -INFO -Extracting files to output completed...
2023-10-12 03:54:40,471 - root -INFO -Writing data into Hive_table
2023-10-12 03:54:40,471 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-12 03:54:40,471 - Persist -WARNING -Creating Database
2023-10-12 03:54:43,855 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-12 03:54:53,537 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 03:54:53,538 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-12 03:54:53,538 - Persist -WARNING -Creating Database
2023-10-12 03:54:53,581 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-12 03:55:00,315 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 03:55:00,315 - root -INFO -Successfully written into Hive
2023-10-12 03:55:00,315 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-12 20:58:17,976 - root -INFO -i am in the main method..
2023-10-12 20:58:17,976 - root -INFO -calling spark object
2023-10-12 20:58:17,976 - Create_spark -INFO -get_spark_object method started
2023-10-12 20:58:17,976 - Create_spark -INFO -master is local
2023-10-12 20:58:36,044 - root -INFO -Validating spark object..........
2023-10-12 20:58:36,044 - Validate -WARNING -started the get_current_date method...
2023-10-12 20:58:39,518 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 12))]
2023-10-12 20:58:39,518 - Validate -WARNING -Validation done go frwd...
2023-10-12 20:58:39,518 - root -INFO -reading file which is of > parquet
2023-10-12 20:58:39,518 - Ingest -WARNING -load_files method started...
2023-10-12 20:58:40,110 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-12 20:58:40,111 - root -INFO -displaying file
2023-10-12 20:58:41,944 - root -INFO -here to validate the df
2023-10-12 20:58:41,944 - Ingest -WARNING -here to count the records in the df_city
2023-10-12 20:58:42,401 - Ingest -WARNING -number of records 28338 :: 
2023-10-12 20:58:42,402 - root -INFO -checking for the files in the Fact...
2023-10-12 20:58:42,402 - root -INFO -reading file which is of > csv
2023-10-12 20:58:42,402 - Ingest -WARNING -load_files method started...
2023-10-12 20:58:46,236 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-12 20:58:46,236 - root -INFO -displaying the df_fact dataframe
2023-10-12 20:58:46,449 - Ingest -WARNING -here to count the records in the df_fact
2023-10-12 20:58:46,986 - Ingest -WARNING -number of records 1329329 :: 
2023-10-12 20:58:46,987 - root -INFO -implementing data_processing methods...
2023-10-12 20:58:46,987 - Data_processing -WARNING -data_clean method started...
2023-10-12 20:58:46,987 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-12 20:58:47,017 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-12 20:58:47,036 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-12 20:58:47,050 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-12 20:58:47,084 - Data_processing -WARNING -Concat fname and lname...
2023-10-12 20:58:47,099 - Data_processing -WARNING -Dropping fname and lname...
2023-10-12 20:58:47,110 - Data_processing -WARNING -Checking for null values...
2023-10-12 20:58:47,110 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-12 20:58:47,129 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-12 20:58:49,410 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-12 20:58:49,411 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-12 20:58:49,785 - root -INFO -validating schema for the dataframes....
2023-10-12 20:58:49,785 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-12 20:58:49,786 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-12 20:58:49,786 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-12 20:58:49,786 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-12 20:58:49,786 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-12 20:58:49,786 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-12 20:58:49,786 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-12 20:58:49,786 - Validate -INFO -print_schema done, go frwd...
2023-10-12 20:58:49,786 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-12 20:58:49,787 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-12 20:58:49,787 - Validate -INFO -print_schema done, go frwd...
2023-10-12 20:58:49,787 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-12 20:58:49,900 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-12 20:59:06,598 - root -INFO -data transformation executed...
2023-10-12 20:59:06,598 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-12 20:59:06,600 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-12 20:59:06,627 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-12 20:59:06,653 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-12 20:59:06,684 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-12 20:59:06,684 - root -INFO -displaying the df_report_1
2023-10-12 20:59:18,023 - root -INFO -Displaying data_report2 method....
2023-10-12 20:59:18,023 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-12 20:59:18,023 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-12 20:59:18,113 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-12 20:59:25,243 - root -INFO -extracting files to output...
2023-10-12 20:59:25,243 - Extraction -WARNING -Executing extract_files method...
2023-10-12 20:59:35,597 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 20:59:35,598 - Extraction -WARNING -Executing extract_files method...
2023-10-12 20:59:42,891 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 20:59:42,891 - root -INFO -Extracting files to output completed...
2023-10-12 20:59:42,892 - root -INFO -Writing data into Hive_table
2023-10-12 20:59:42,892 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-12 20:59:42,892 - Persist -WARNING -Creating Database
2023-10-12 20:59:46,029 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-12 20:59:59,690 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 20:59:59,690 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-12 20:59:59,690 - Persist -WARNING -Creating Database
2023-10-12 20:59:59,745 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-12 21:00:09,057 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 21:00:09,057 - root -INFO -Successfully written into Hive
2023-10-12 21:00:09,057 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-12 21:22:11,193 - root -INFO -i am in the main method..
2023-10-12 21:22:11,194 - root -INFO -calling spark object
2023-10-12 21:22:11,194 - Create_spark -INFO -get_spark_object method started
2023-10-12 21:22:11,194 - Create_spark -INFO -master is local
2023-10-12 21:22:14,571 - root -INFO -Validating spark object..........
2023-10-12 21:22:14,572 - Validate -WARNING -started the get_current_date method...
2023-10-12 21:22:17,375 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 12))]
2023-10-12 21:22:17,375 - Validate -WARNING -Validation done go frwd...
2023-10-12 21:22:17,375 - root -INFO -reading file which is of > parquet
2023-10-12 21:22:17,375 - Ingest -WARNING -load_files method started...
2023-10-12 21:22:17,889 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-12 21:22:17,889 - root -INFO -displaying file
2023-10-12 21:22:19,384 - root -INFO -here to validate the df
2023-10-12 21:22:19,384 - Ingest -WARNING -here to count the records in the df_city
2023-10-12 21:22:19,824 - Ingest -WARNING -number of records 28338 :: 
2023-10-12 21:22:19,824 - root -INFO -checking for the files in the Fact...
2023-10-12 21:22:19,825 - root -INFO -reading file which is of > csv
2023-10-12 21:22:19,825 - Ingest -WARNING -load_files method started...
2023-10-12 21:22:23,622 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-12 21:22:23,622 - root -INFO -displaying the df_fact dataframe
2023-10-12 21:22:23,881 - Ingest -WARNING -here to count the records in the df_fact
2023-10-12 21:22:24,405 - Ingest -WARNING -number of records 1329329 :: 
2023-10-12 21:22:24,405 - root -INFO -implementing data_processing methods...
2023-10-12 21:22:24,405 - Data_processing -WARNING -data_clean method started...
2023-10-12 21:22:24,405 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-12 21:22:24,436 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-12 21:22:24,456 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-12 21:22:24,467 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-12 21:22:24,499 - Data_processing -WARNING -Concat fname and lname...
2023-10-12 21:22:24,515 - Data_processing -WARNING -Dropping fname and lname...
2023-10-12 21:22:24,525 - Data_processing -WARNING -Checking for null values...
2023-10-12 21:22:24,526 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-12 21:22:24,541 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-12 21:22:26,929 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-12 21:22:26,930 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-12 21:22:27,285 - root -INFO -validating schema for the dataframes....
2023-10-12 21:22:27,285 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-12 21:22:27,286 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-12 21:22:27,286 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-12 21:22:27,286 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-12 21:22:27,286 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-12 21:22:27,286 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-12 21:22:27,287 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-12 21:22:27,287 - Validate -INFO -print_schema done, go frwd...
2023-10-12 21:22:27,287 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-12 21:22:27,287 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-12 21:22:27,288 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-12 21:22:27,288 - Validate -INFO -print_schema done, go frwd...
2023-10-12 21:22:27,288 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-12 21:22:27,394 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-12 21:22:44,324 - root -INFO -data transformation executed...
2023-10-12 21:22:44,325 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-12 21:22:44,328 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-12 21:22:44,355 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-12 21:22:44,380 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-12 21:22:44,408 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-12 21:22:44,408 - root -INFO -displaying the df_report_1
2023-10-12 21:22:54,869 - root -INFO -Displaying data_report2 method....
2023-10-12 21:22:54,870 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-12 21:22:54,870 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-12 21:22:54,972 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-12 21:23:01,663 - root -INFO -extracting files to output...
2023-10-12 21:23:01,663 - Extraction -WARNING -Executing extract_files method...
2023-10-12 21:23:11,600 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 21:23:11,600 - Extraction -WARNING -Executing extract_files method...
2023-10-12 21:23:18,188 - Extraction -WARNING -extract_files method successfully executed...
2023-10-12 21:23:18,188 - root -INFO -Extracting files to output completed...
2023-10-12 21:23:18,188 - root -INFO -Writing data into Hive_table
2023-10-12 21:23:18,188 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-12 21:23:18,188 - Persist -WARNING -Creating Database
2023-10-12 21:23:20,995 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-12 21:23:32,745 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 21:23:32,746 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-12 21:23:32,746 - Persist -WARNING -Creating Database
2023-10-12 21:23:32,776 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-12 21:23:39,599 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-12 21:23:39,599 - root -INFO -Successfully written into Hive
2023-10-12 21:23:39,599 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-12 21:23:51,498 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-12 21:23:51,498 - root -INFO -Successfully Data written into Mysql
2023-10-12 21:23:51,498 - root -INFO -Total amount of time taken : 100.30 seconds
2023-10-12 21:23:51,499 - root -INFO -Application done
2023-10-13 01:58:42,778 - root -INFO -i am in the main method..
2023-10-13 01:58:42,778 - root -INFO -calling spark object
2023-10-13 01:58:42,778 - Create_spark -INFO -get_spark_object method started
2023-10-13 01:58:42,779 - Create_spark -INFO -master is local
2023-10-13 01:58:46,818 - root -INFO -Validating spark object..........
2023-10-13 01:58:46,818 - Validate -WARNING -started the get_current_date method...
2023-10-13 01:58:50,011 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 13))]
2023-10-13 01:58:50,011 - Validate -WARNING -Validation done go frwd...
2023-10-13 01:58:50,011 - root -INFO -reading file which is of > parquet
2023-10-13 01:58:50,011 - Ingest -WARNING -load_files method started...
2023-10-13 01:58:50,574 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-13 01:58:50,574 - root -INFO -displaying file
2023-10-13 01:58:52,127 - root -INFO -here to validate the df
2023-10-13 01:58:52,127 - Ingest -WARNING -here to count the records in the df_city
2023-10-13 01:58:52,550 - Ingest -WARNING -number of records 28338 :: 
2023-10-13 01:58:52,550 - root -INFO -checking for the files in the Fact...
2023-10-13 01:58:52,550 - root -INFO -reading file which is of > csv
2023-10-13 01:58:52,550 - Ingest -WARNING -load_files method started...
2023-10-13 01:58:56,452 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-13 01:58:56,452 - root -INFO -displaying the df_fact dataframe
2023-10-13 01:58:56,698 - Ingest -WARNING -here to count the records in the df_fact
2023-10-13 01:58:57,272 - Ingest -WARNING -number of records 1329329 :: 
2023-10-13 01:58:57,272 - root -INFO -implementing data_processing methods...
2023-10-13 01:58:57,272 - Data_processing -WARNING -data_clean method started...
2023-10-13 01:58:57,272 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-13 01:58:57,308 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-13 01:58:57,326 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-13 01:58:57,341 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-13 01:58:57,375 - Data_processing -WARNING -Concat fname and lname...
2023-10-13 01:58:57,389 - Data_processing -WARNING -Dropping fname and lname...
2023-10-13 01:58:57,401 - Data_processing -WARNING -Checking for null values...
2023-10-13 01:58:57,401 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-13 01:58:57,419 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-13 01:58:59,801 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-13 01:58:59,802 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-13 01:59:00,126 - root -INFO -validating schema for the dataframes....
2023-10-13 01:59:00,126 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-13 01:59:00,127 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-13 01:59:00,127 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-13 01:59:00,127 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-13 01:59:00,127 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-13 01:59:00,127 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-13 01:59:00,127 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-13 01:59:00,127 - Validate -INFO -print_schema done, go frwd...
2023-10-13 01:59:00,127 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-13 01:59:00,128 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-13 01:59:00,128 - Validate -INFO -print_schema done, go frwd...
2023-10-13 01:59:00,128 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-13 01:59:00,263 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-13 01:59:17,166 - root -INFO -data transformation executed...
2023-10-13 01:59:17,166 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-13 01:59:17,169 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-13 01:59:17,192 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-13 01:59:17,216 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-13 01:59:17,246 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-13 01:59:17,246 - root -INFO -displaying the df_report_1
2023-10-13 01:59:28,434 - root -INFO -Displaying data_report2 method....
2023-10-13 01:59:28,434 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-13 01:59:28,434 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-13 01:59:28,533 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-13 01:59:35,567 - root -INFO -extracting files to output...
2023-10-13 01:59:35,567 - Extraction -WARNING -Executing extract_files method...
2023-10-13 01:59:46,333 - Extraction -WARNING -extract_files method successfully executed...
2023-10-13 01:59:46,333 - Extraction -WARNING -Executing extract_files method...
2023-10-13 01:59:53,519 - Extraction -WARNING -extract_files method successfully executed...
2023-10-13 01:59:53,519 - root -INFO -Extracting files to output completed...
2023-10-13 01:59:53,519 - root -INFO -Writing data into Hive_table
2023-10-13 01:59:53,519 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-13 01:59:53,519 - Persist -WARNING -Creating Database
2023-10-13 01:59:56,795 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-13 02:00:07,661 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-13 02:00:07,661 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-13 02:00:07,661 - Persist -WARNING -Creating Database
2023-10-13 02:00:07,685 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-13 02:00:14,362 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-13 02:00:14,362 - root -INFO -Successfully written into Hive
2023-10-13 02:00:14,362 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-13 02:00:24,906 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-13 02:00:24,906 - root -INFO -Successfully Data written into Mysql
2023-10-13 02:00:24,906 - root -INFO -Total amount of time taken : 102.13 seconds
2023-10-13 02:00:24,907 - root -INFO -Application done
2023-10-13 02:49:33,792 - root -INFO -i am in the main method..
2023-10-13 02:49:33,792 - root -INFO -calling spark object
2023-10-13 02:49:33,792 - Create_spark -INFO -get_spark_object method started
2023-10-13 02:49:33,792 - Create_spark -INFO -master is local
2023-10-13 02:49:37,306 - root -INFO -Validating spark object..........
2023-10-13 02:49:37,306 - Validate -WARNING -started the get_current_date method...
2023-10-13 02:49:40,144 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 13))]
2023-10-13 02:49:40,144 - Validate -WARNING -Validation done go frwd...
2023-10-13 02:49:40,144 - root -INFO -reading file which is of > parquet
2023-10-13 02:49:40,144 - Ingest -WARNING -load_files method started...
2023-10-13 02:49:40,649 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-13 02:49:40,650 - root -INFO -displaying file
2023-10-13 02:49:42,252 - root -INFO -here to validate the df
2023-10-13 02:49:42,252 - Ingest -WARNING -here to count the records in the df_city
2023-10-13 02:49:42,667 - Ingest -WARNING -number of records 28338 :: 
2023-10-13 02:49:42,667 - root -INFO -checking for the files in the Fact...
2023-10-13 02:49:42,668 - root -INFO -reading file which is of > csv
2023-10-13 02:49:42,668 - Ingest -WARNING -load_files method started...
2023-10-13 02:49:46,494 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-13 02:49:46,494 - root -INFO -displaying the df_fact dataframe
2023-10-13 02:49:46,707 - Ingest -WARNING -here to count the records in the df_fact
2023-10-13 02:49:47,208 - Ingest -WARNING -number of records 1329329 :: 
2023-10-13 02:49:47,209 - root -INFO -implementing data_processing methods...
2023-10-13 02:49:47,209 - Data_processing -WARNING -data_clean method started...
2023-10-13 02:49:47,209 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-13 02:49:47,244 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-13 02:49:47,263 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-13 02:49:47,275 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-13 02:49:47,317 - Data_processing -WARNING -Concat fname and lname...
2023-10-13 02:49:47,334 - Data_processing -WARNING -Dropping fname and lname...
2023-10-13 02:49:47,346 - Data_processing -WARNING -Checking for null values...
2023-10-13 02:49:47,347 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-13 02:49:47,365 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-13 02:49:49,687 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-13 02:49:49,688 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-13 02:49:49,978 - root -INFO -validating schema for the dataframes....
2023-10-13 02:49:49,979 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-13 02:49:49,980 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-13 02:49:49,980 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-13 02:49:49,980 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-13 02:49:49,980 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-13 02:49:49,981 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-13 02:49:49,981 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-13 02:49:49,981 - Validate -INFO -print_schema done, go frwd...
2023-10-13 02:49:49,981 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-13 02:49:49,983 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-13 02:49:49,983 - Validate -INFO -print_schema done, go frwd...
2023-10-13 02:49:49,983 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-13 02:49:50,126 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-13 02:50:06,764 - root -INFO -data transformation executed...
2023-10-13 02:50:06,764 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-13 02:50:06,767 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-13 02:50:06,786 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-13 02:50:06,808 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-13 02:50:06,838 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-13 02:50:06,838 - root -INFO -displaying the df_report_1
2023-10-13 02:50:18,008 - root -INFO -Displaying data_report2 method....
2023-10-13 02:50:18,009 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-13 02:50:18,009 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-13 02:50:18,119 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-13 02:50:24,809 - root -INFO -extracting files to output...
2023-10-13 02:50:24,809 - Extraction -WARNING -Executing extract_files method...
2023-10-13 02:50:34,980 - Extraction -WARNING -extract_files method successfully executed...
2023-10-13 02:50:34,980 - Extraction -WARNING -Executing extract_files method...
2023-10-13 02:50:41,882 - Extraction -WARNING -extract_files method successfully executed...
2023-10-13 02:50:41,882 - root -INFO -Extracting files to output completed...
2023-10-13 02:50:41,882 - root -INFO -Writing data into Hive_table
2023-10-13 02:50:41,882 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-13 02:50:41,882 - Persist -WARNING -Creating Database
2023-10-13 02:50:44,768 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-13 02:50:55,368 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-13 02:50:55,368 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-13 02:50:55,368 - Persist -WARNING -Creating Database
2023-10-13 02:50:55,392 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-13 02:51:02,690 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-13 02:51:02,691 - root -INFO -Successfully written into Hive
2023-10-13 02:51:02,691 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-13 02:51:23,927 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-13 02:51:23,928 - root -INFO -Successfully Data written into Mysql
2023-10-13 02:51:23,928 - root -INFO -Total amount of time taken : 110.14 seconds
2023-10-13 02:51:23,928 - root -INFO -Application done
2023-10-13 23:50:24,071 - root -INFO -i am in the main method..
2023-10-13 23:50:24,072 - root -INFO -calling spark object
2023-10-13 23:50:24,072 - Create_spark -INFO -get_spark_object method started
2023-10-13 23:50:24,072 - Create_spark -INFO -master is local
2023-10-13 23:50:40,693 - root -INFO -Validating spark object..........
2023-10-13 23:50:40,694 - Validate -WARNING -started the get_current_date method...
2023-10-13 23:50:44,007 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 13))]
2023-10-13 23:50:44,007 - Validate -WARNING -Validation done go frwd...
2023-10-13 23:50:44,007 - root -INFO -reading file which is of > parquet
2023-10-13 23:50:44,007 - Ingest -WARNING -load_files method started...
2023-10-13 23:50:44,569 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-13 23:50:44,570 - root -INFO -displaying file
2023-10-13 23:50:46,155 - root -INFO -here to validate the df
2023-10-13 23:50:46,155 - Ingest -WARNING -here to count the records in the df_city
2023-10-13 23:50:46,617 - Ingest -WARNING -number of records 28338 :: 
2023-10-13 23:50:46,617 - root -INFO -checking for the files in the Fact...
2023-10-13 23:50:46,617 - root -INFO -reading file which is of > csv
2023-10-13 23:50:46,617 - Ingest -WARNING -load_files method started...
2023-10-13 23:50:50,488 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-13 23:50:50,488 - root -INFO -displaying the df_fact dataframe
2023-10-13 23:50:50,706 - Ingest -WARNING -here to count the records in the df_fact
2023-10-13 23:50:51,252 - Ingest -WARNING -number of records 1329329 :: 
2023-10-13 23:50:51,252 - root -INFO -implementing data_processing methods...
2023-10-13 23:50:51,252 - Data_processing -WARNING -data_clean method started...
2023-10-13 23:50:51,252 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-13 23:50:51,285 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-13 23:50:51,301 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-13 23:50:51,314 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-13 23:50:51,348 - Data_processing -WARNING -Concat fname and lname...
2023-10-13 23:50:51,361 - Data_processing -WARNING -Dropping fname and lname...
2023-10-13 23:50:51,371 - Data_processing -WARNING -Checking for null values...
2023-10-13 23:50:51,371 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-13 23:50:51,390 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-13 23:50:53,628 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-13 23:50:53,628 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-13 23:50:53,947 - root -INFO -validating schema for the dataframes....
2023-10-13 23:50:53,947 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-13 23:50:53,948 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-13 23:50:53,948 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-13 23:50:53,948 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-13 23:50:53,948 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-13 23:50:53,948 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-13 23:50:53,948 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-13 23:50:53,948 - Validate -INFO -print_schema done, go frwd...
2023-10-13 23:50:53,948 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-13 23:50:53,951 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-13 23:50:53,951 - Validate -INFO -print_schema done, go frwd...
2023-10-13 23:50:53,951 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-13 23:50:54,059 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-13 23:51:10,809 - root -INFO -data transformation executed...
2023-10-13 23:51:10,809 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-13 23:51:10,813 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-13 23:51:10,837 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-13 23:51:10,868 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-13 23:51:10,896 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-13 23:51:10,896 - root -INFO -displaying the df_report_1
2023-10-13 23:51:22,598 - root -INFO -Displaying data_report2 method....
2023-10-13 23:51:22,599 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-13 23:51:22,599 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-13 23:51:22,697 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-13 23:51:29,514 - root -INFO -extracting files to output...
2023-10-13 23:51:29,514 - Extraction -WARNING -Executing extract_files method...
2023-10-13 23:51:39,186 - Extraction -WARNING -extract_files method successfully executed...
2023-10-13 23:51:39,186 - Extraction -WARNING -Executing extract_files method...
2023-10-13 23:51:46,011 - Extraction -WARNING -extract_files method successfully executed...
2023-10-13 23:51:46,011 - root -INFO -Extracting files to output completed...
2023-10-13 23:51:46,011 - root -INFO -Writing data into Hive_table
2023-10-13 23:51:46,011 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-13 23:51:46,011 - Persist -WARNING -Creating Database
2023-10-13 23:51:49,062 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-13 23:51:59,858 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-13 23:51:59,858 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-13 23:51:59,859 - Persist -WARNING -Creating Database
2023-10-13 23:51:59,893 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-13 23:52:06,560 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-13 23:52:06,560 - root -INFO -Successfully written into Hive
2023-10-13 23:52:06,560 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-13 23:52:17,895 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-13 23:52:17,895 - root -INFO -Successfully Data written into Mysql
2023-10-13 23:52:17,895 - root -INFO -Total amount of time taken : 113.82 seconds
2023-10-13 23:52:17,895 - root -INFO -Application done
2023-10-14 00:08:16,380 - root -INFO -i am in the main method..
2023-10-14 00:08:16,380 - root -INFO -calling spark object
2023-10-14 00:08:16,381 - Create_spark -INFO -get_spark_object method started
2023-10-14 00:08:16,381 - Create_spark -INFO -master is local
2023-10-14 00:08:19,744 - root -INFO -Validating spark object..........
2023-10-14 00:08:19,744 - Validate -WARNING -started the get_current_date method...
2023-10-14 00:08:22,569 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 00:08:22,569 - Validate -WARNING -Validation done go frwd...
2023-10-14 00:08:22,569 - root -INFO -reading file which is of > parquet
2023-10-14 00:08:22,569 - Ingest -WARNING -load_files method started...
2023-10-14 00:08:23,095 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 00:08:23,095 - root -INFO -displaying file
2023-10-14 00:08:24,694 - root -INFO -here to validate the df
2023-10-14 00:08:24,694 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 00:10:46,076 - root -INFO -i am in the main method..
2023-10-14 00:10:46,077 - root -INFO -calling spark object
2023-10-14 00:10:46,077 - Create_spark -INFO -get_spark_object method started
2023-10-14 00:10:46,077 - Create_spark -INFO -master is local
2023-10-14 00:10:49,432 - root -ERROR -KeyboardInterrupt while sending command.
Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\python\python3.11\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 538, in send_command
    logger.info("Error while receiving.", exc_info=True)
  File "D:\python\python3.11\Lib\logging\__init__.py", line 1479, in info
    def info(self, msg, *args, **kwargs):
    
KeyboardInterrupt
2023-10-14 00:11:44,930 - root -INFO -i am in the main method..
2023-10-14 00:11:44,931 - root -INFO -calling spark object
2023-10-14 00:11:44,931 - Create_spark -INFO -get_spark_object method started
2023-10-14 00:11:44,931 - Create_spark -INFO -master is local
2023-10-14 00:11:48,367 - root -INFO -Validating spark object..........
2023-10-14 00:11:48,367 - Validate -WARNING -started the get_current_date method...
2023-10-14 00:11:51,447 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 00:11:51,447 - Validate -WARNING -Validation done go frwd...
2023-10-14 00:11:51,447 - root -INFO -reading file which is of > parquet
2023-10-14 00:11:51,447 - Ingest -WARNING -load_files method started...
2023-10-14 00:11:51,961 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 00:11:51,962 - root -INFO -displaying file df_city
2023-10-14 00:11:53,569 - root -INFO -here to validate the df
2023-10-14 00:11:53,569 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 00:11:53,973 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 00:11:53,973 - root -INFO -checking for the files in the Fact...
2023-10-14 00:11:53,973 - root -INFO -reading file which is of > csv
2023-10-14 00:11:53,973 - Ingest -WARNING -load_files method started...
2023-10-14 00:11:57,990 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 00:11:57,990 - root -INFO -displaying the df_fact dataframe
2023-10-14 00:11:58,214 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 00:11:58,783 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 00:11:58,783 - root -INFO -implementing data_processing methods...
2023-10-14 00:11:58,783 - Data_processing -WARNING -data_clean method started...
2023-10-14 00:11:58,783 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 00:11:58,817 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 00:11:58,833 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 00:11:58,845 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 00:11:58,874 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 00:11:58,886 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 00:11:58,895 - Data_processing -WARNING -Checking for null values...
2023-10-14 00:11:58,895 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 00:11:58,911 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 00:12:01,443 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 00:12:01,443 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 00:12:01,810 - root -INFO -validating schema for the dataframes....
2023-10-14 00:12:01,811 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 00:12:01,812 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 00:12:01,812 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 00:12:01,812 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 00:12:01,812 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 00:12:01,812 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 00:12:01,812 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 00:12:01,812 - Validate -INFO -print_schema done, go frwd...
2023-10-14 00:12:01,812 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-14 00:12:01,814 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-14 00:12:01,814 - Validate -INFO -print_schema done, go frwd...
2023-10-14 00:12:01,815 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 00:12:01,941 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 00:12:19,126 - root -INFO -data transformation executed...
2023-10-14 00:12:19,126 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 00:12:19,128 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 00:12:19,157 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 00:12:19,184 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 00:12:19,218 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 00:12:19,218 - root -INFO -displaying the df_report_1
2023-10-14 00:12:30,836 - root -INFO -Displaying data_report2 method....
2023-10-14 00:12:30,836 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-14 00:12:30,836 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-14 00:12:30,958 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-14 00:12:37,710 - root -INFO -extracting files to output...
2023-10-14 00:12:37,711 - Extraction -WARNING -Executing extract_files method...
2023-10-14 00:12:49,415 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 00:12:49,415 - Extraction -WARNING -Executing extract_files method...
2023-10-14 00:12:50,806 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: reentrant call inside <_io.BufferedReader name=680>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-10-14 00:12:50,808 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\python\python3.11\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\pyspark\context.py", line 381, in signal_handler
    self.cancelAllJobs()
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\pyspark\context.py", line 2446, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\pyspark\errors\exceptions\captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o18.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-10-14 00:13:58,193 - root -INFO -i am in the main method..
2023-10-14 00:13:58,193 - root -INFO -calling spark object
2023-10-14 00:13:58,193 - Create_spark -INFO -get_spark_object method started
2023-10-14 00:13:58,193 - Create_spark -INFO -master is local
2023-10-14 00:14:01,756 - root -INFO -Validating spark object..........
2023-10-14 00:14:01,756 - Validate -WARNING -started the get_current_date method...
2023-10-14 00:14:04,835 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 00:14:04,835 - Validate -WARNING -Validation done go frwd...
2023-10-14 00:14:04,835 - root -INFO -reading file which is of > parquet
2023-10-14 00:14:04,835 - Ingest -WARNING -load_files method started...
2023-10-14 00:14:05,337 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 00:14:05,337 - root -INFO -displaying file df_city
2023-10-14 00:14:07,070 - root -INFO -here to validate the df
2023-10-14 00:14:07,070 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 00:14:07,544 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 00:14:07,544 - root -INFO -checking for the files in the Fact...
2023-10-14 00:14:07,544 - root -INFO -reading file which is of > csv
2023-10-14 00:14:07,544 - Ingest -WARNING -load_files method started...
2023-10-14 00:14:11,479 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 00:14:11,479 - root -INFO -displaying the df_fact dataframe
2023-10-14 00:14:11,700 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 00:14:12,285 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 00:14:12,286 - root -INFO -implementing data_processing methods...
2023-10-14 00:14:12,286 - Data_processing -WARNING -data_clean method started...
2023-10-14 00:14:12,286 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 00:14:12,318 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 00:14:12,336 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 00:14:12,349 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 00:14:12,387 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 00:14:12,402 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 00:14:12,410 - Data_processing -WARNING -Checking for null values...
2023-10-14 00:14:12,411 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 00:14:12,431 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 00:14:14,730 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 00:14:14,730 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 00:14:15,082 - root -INFO -validating schema for the dataframes....
2023-10-14 00:14:15,082 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 00:14:15,084 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 00:14:15,084 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 00:14:15,084 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 00:14:15,084 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 00:14:15,084 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 00:14:15,084 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 00:14:15,084 - Validate -INFO -print_schema done, go frwd...
2023-10-14 00:14:15,084 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-14 00:14:15,085 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-14 00:14:15,085 - Validate -INFO -print_schema done, go frwd...
2023-10-14 00:14:15,085 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 00:14:15,222 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 00:14:32,251 - root -INFO -data transformation executed...
2023-10-14 00:14:32,251 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 00:14:32,254 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 00:14:32,284 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 00:14:32,311 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 00:14:32,345 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 00:14:32,345 - root -INFO -displaying the df_report_1
2023-10-14 00:14:43,107 - root -INFO -Displaying data_report2 method....
2023-10-14 00:14:43,107 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-14 00:14:43,107 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-14 00:14:43,274 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-14 00:14:50,158 - root -INFO -extracting files to output...
2023-10-14 00:14:50,158 - Extraction -WARNING -Executing extract_files method...
2023-10-14 00:15:00,187 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 00:15:00,187 - Extraction -WARNING -Executing extract_files method...
2023-10-14 00:15:06,405 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 00:15:06,405 - root -INFO -Extracting files to output completed...
2023-10-14 00:15:06,405 - root -INFO -Writing data into Hive_table
2023-10-14 00:15:06,405 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-14 00:15:06,405 - Persist -WARNING -Creating Database
2023-10-14 00:15:09,418 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-14 00:15:20,337 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 00:15:20,337 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-14 00:15:20,337 - Persist -WARNING -Creating Database
2023-10-14 00:15:20,364 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-14 00:15:27,237 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 00:15:27,237 - root -INFO -Successfully written into Hive
2023-10-14 00:15:27,238 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-14 00:15:38,594 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-14 00:15:38,594 - root -INFO -Successfully Data written into Mysql
2023-10-14 00:15:38,594 - root -INFO -Total amount of time taken : 100.40 seconds
2023-10-14 00:15:38,594 - root -INFO -Application done
2023-10-14 01:42:31,182 - root -INFO -i am in the main method..
2023-10-14 01:42:31,182 - root -INFO -calling spark object
2023-10-14 01:42:31,182 - Create_spark -INFO -get_spark_object method started
2023-10-14 01:42:31,182 - Create_spark -INFO -master is local
2023-10-14 01:42:34,570 - root -INFO -Validating spark object..........
2023-10-14 01:42:34,570 - Validate -WARNING -started the get_current_date method...
2023-10-14 01:42:37,404 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 01:42:37,404 - Validate -WARNING -Validation done go frwd...
2023-10-14 01:42:37,404 - root -INFO -reading file which is of > parquet
2023-10-14 01:42:37,404 - Ingest -WARNING -load_files method started...
2023-10-14 01:42:37,897 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 01:42:37,897 - root -INFO -displaying file df_city
2023-10-14 01:42:39,310 - root -INFO -here to validate the df
2023-10-14 01:42:39,310 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 01:42:39,698 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 01:42:39,698 - root -INFO -checking for the files in the Fact...
2023-10-14 01:42:39,698 - root -INFO -reading file which is of > csv
2023-10-14 01:42:39,698 - Ingest -WARNING -load_files method started...
2023-10-14 01:42:43,614 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 01:42:43,615 - root -INFO -displaying the df_fact dataframe
2023-10-14 01:42:43,819 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 01:42:44,443 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 01:42:44,443 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 01:42:44,617 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 01:43:15,587 - root -INFO -implementing data_processing methods...
2023-10-14 01:43:15,588 - Data_processing -WARNING -data_clean method started...
2023-10-14 01:43:15,588 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 01:43:15,613 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 01:43:15,627 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 01:43:15,640 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 01:43:15,676 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 01:43:15,690 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 01:43:15,701 - Data_processing -WARNING -Checking for null values...
2023-10-14 01:43:15,701 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 01:43:15,720 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 01:43:18,031 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 01:43:18,031 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 01:43:18,345 - root -INFO -validating schema for the dataframes....
2023-10-14 01:43:18,345 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 01:43:18,346 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 01:43:18,346 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 01:43:18,346 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 01:43:18,346 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 01:43:18,346 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 01:43:18,346 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 01:43:18,346 - Validate -INFO -print_schema done, go frwd...
2023-10-14 01:43:18,346 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-14 01:43:18,347 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-14 01:43:18,347 - Validate -INFO -print_schema done, go frwd...
2023-10-14 01:43:18,347 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 01:43:18,418 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 01:43:35,487 - root -INFO -data transformation executed...
2023-10-14 01:43:35,487 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 01:43:35,489 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 01:43:35,511 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 01:43:35,546 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 01:43:35,581 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 01:43:35,582 - root -INFO -displaying the df_report_1
2023-10-14 01:43:50,827 - root -INFO -Displaying data_report2 method....
2023-10-14 01:43:50,827 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-14 01:43:50,827 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-14 01:43:51,051 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-14 01:44:03,998 - root -INFO -extracting files to output...
2023-10-14 01:44:03,999 - Extraction -WARNING -Executing extract_files method...
2023-10-14 01:44:16,299 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 01:44:16,299 - Extraction -WARNING -Executing extract_files method...
2023-10-14 01:44:23,707 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 01:44:23,707 - root -INFO -Extracting files to output completed...
2023-10-14 01:44:23,707 - root -INFO -Writing data into Hive_table
2023-10-14 01:44:23,707 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-14 01:44:23,707 - Persist -WARNING -Creating Database
2023-10-14 01:44:26,797 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-14 01:44:45,038 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 01:44:45,039 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-14 01:44:45,039 - Persist -WARNING -Creating Database
2023-10-14 01:44:45,104 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-14 01:45:00,618 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 01:45:00,618 - root -INFO -Successfully written into Hive
2023-10-14 01:45:00,619 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-14 01:45:12,308 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-14 01:45:12,308 - root -INFO -Successfully Data written into Mysql
2023-10-14 01:45:12,308 - root -INFO -Total amount of time taken : 161.13 seconds
2023-10-14 01:45:12,308 - root -INFO -Application done
2023-10-14 01:45:27,168 - root -INFO -i am in the main method..
2023-10-14 01:45:27,168 - root -INFO -calling spark object
2023-10-14 01:45:27,168 - Create_spark -INFO -get_spark_object method started
2023-10-14 01:45:27,168 - Create_spark -INFO -master is local
2023-10-14 01:45:30,600 - root -INFO -Validating spark object..........
2023-10-14 01:45:30,600 - Validate -WARNING -started the get_current_date method...
2023-10-14 01:45:33,553 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 01:45:33,553 - Validate -WARNING -Validation done go frwd...
2023-10-14 01:45:33,553 - root -INFO -reading file which is of > parquet
2023-10-14 01:45:33,553 - Ingest -WARNING -load_files method started...
2023-10-14 01:45:34,093 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 01:45:34,093 - root -INFO -displaying file df_city
2023-10-14 01:45:35,676 - root -INFO -here to validate the df
2023-10-14 01:45:35,676 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 01:45:36,077 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 01:45:36,077 - root -INFO -checking for the files in the Fact...
2023-10-14 01:45:36,078 - root -INFO -reading file which is of > csv
2023-10-14 01:45:36,078 - Ingest -WARNING -load_files method started...
2023-10-14 01:45:39,961 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 01:45:39,961 - root -INFO -displaying the df_fact dataframe
2023-10-14 01:45:40,235 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 01:45:40,813 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 01:45:40,813 - root -INFO -implementing data_processing methods...
2023-10-14 01:45:40,813 - Data_processing -WARNING -data_clean method started...
2023-10-14 01:45:40,813 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 01:45:40,842 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 01:45:40,860 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 01:45:40,872 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 01:45:40,904 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 01:45:40,923 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 01:45:40,932 - Data_processing -WARNING -Checking for null values...
2023-10-14 01:45:40,932 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 01:45:40,949 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 01:45:43,549 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 01:45:43,549 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 01:45:43,852 - root -INFO -validating schema for the dataframes....
2023-10-14 01:45:43,852 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 01:45:43,853 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 01:45:43,853 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 01:45:43,853 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 01:45:43,853 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 01:45:43,853 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 01:45:43,853 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 01:45:43,853 - Validate -INFO -print_schema done, go frwd...
2023-10-14 01:45:43,853 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-14 01:45:43,854 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-14 01:45:43,855 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-14 01:45:43,855 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-14 01:45:43,855 - Validate -INFO -print_schema done, go frwd...
2023-10-14 01:45:43,855 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 01:45:43,972 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 01:46:01,162 - root -INFO -data transformation executed...
2023-10-14 01:46:01,162 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 01:46:01,164 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 01:46:01,184 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 01:46:01,209 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 01:46:01,241 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 01:46:01,241 - root -INFO -displaying the df_report_1
2023-10-14 01:46:12,008 - root -INFO -Displaying data_report2 method....
2023-10-14 01:46:12,008 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-14 01:46:12,008 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-14 01:46:12,110 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-14 01:46:18,321 - root -INFO -extracting files to output...
2023-10-14 01:46:18,321 - Extraction -WARNING -Executing extract_files method...
2023-10-14 01:46:29,935 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 01:46:29,936 - Extraction -WARNING -Executing extract_files method...
2023-10-14 01:46:42,452 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 01:46:42,452 - root -INFO -Extracting files to output completed...
2023-10-14 01:46:42,452 - root -INFO -Writing data into Hive_table
2023-10-14 01:46:42,452 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-14 01:46:42,452 - Persist -WARNING -Creating Database
2023-10-14 01:46:52,340 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-14 01:47:17,426 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 01:47:17,426 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-14 01:47:17,426 - Persist -WARNING -Creating Database
2023-10-14 01:47:17,483 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-14 01:47:38,839 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 01:47:38,839 - root -INFO -Successfully written into Hive
2023-10-14 01:47:38,841 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-14 01:47:54,079 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-14 01:47:54,079 - root -INFO -Successfully Data written into Mysql
2023-10-14 01:47:54,079 - root -INFO -Total amount of time taken : 146.91 seconds
2023-10-14 01:47:54,079 - root -INFO -Application done
2023-10-14 02:29:36,287 - root -INFO -i am in the main method..
2023-10-14 02:29:36,287 - root -INFO -calling spark object
2023-10-14 02:29:36,287 - Create_spark -INFO -get_spark_object method started
2023-10-14 02:29:36,287 - Create_spark -INFO -master is local
2023-10-14 02:29:40,090 - root -INFO -Validating spark object..........
2023-10-14 02:29:40,091 - Validate -WARNING -started the get_current_date method...
2023-10-14 02:29:43,022 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 02:29:43,022 - Validate -WARNING -Validation done go frwd...
2023-10-14 02:29:43,023 - root -INFO -reading file which is of > parquet
2023-10-14 02:29:43,023 - Ingest -WARNING -load_files method started...
2023-10-14 02:29:43,530 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 02:29:43,531 - root -INFO -displaying file df_city
2023-10-14 02:29:45,047 - root -INFO -here to validate the df
2023-10-14 02:29:45,047 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 02:29:45,477 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 02:29:45,477 - root -INFO -checking for the files in the Fact...
2023-10-14 02:29:45,477 - root -INFO -reading file which is of > csv
2023-10-14 02:29:45,478 - Ingest -WARNING -load_files method started...
2023-10-14 02:29:49,322 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 02:29:49,323 - root -INFO -displaying the df_fact dataframe
2023-10-14 02:29:49,549 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 02:29:50,073 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 02:29:50,074 - root -INFO -implementing data_processing methods...
2023-10-14 02:29:50,074 - Data_processing -WARNING -data_clean method started...
2023-10-14 02:29:50,074 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 02:29:50,103 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 02:29:50,121 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 02:29:50,133 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 02:29:50,167 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 02:29:50,184 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 02:29:50,193 - Data_processing -WARNING -Checking for null values...
2023-10-14 02:30:07,324 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 02:30:07,352 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 02:30:12,078 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 02:30:12,078 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 02:30:28,728 - root -INFO -validating schema for the dataframes....
2023-10-14 02:30:28,728 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 02:30:28,729 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 02:30:28,730 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 02:30:28,730 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 02:30:28,730 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 02:30:28,730 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 02:30:28,730 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 02:30:28,730 - Validate -INFO -print_schema done, go frwd...
2023-10-14 02:30:28,730 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('presc_id', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('presc_city', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('presc_state', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('presc_spclt', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('drug_name', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('tx_cnt', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('total_day_supply', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('total_drug_cost', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('years_of_exp', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('Country_name', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -	StructField('presc_fullname', LongType(), False)
2023-10-14 02:30:28,731 - Validate -INFO -print_schema done, go frwd...
2023-10-14 02:30:28,731 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 02:30:28,796 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 02:30:46,868 - root -INFO -data transformation executed...
2023-10-14 02:30:46,868 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 02:30:46,872 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 02:30:46,913 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 02:30:46,938 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 02:30:46,984 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 02:30:46,985 - root -INFO -displaying the df_report_1
2023-10-14 02:30:58,315 - root -INFO -Displaying data_report2 method....
2023-10-14 02:30:58,315 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-14 02:30:58,315 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-14 02:30:58,466 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-14 02:31:10,682 - root -INFO -extracting files to output...
2023-10-14 02:31:10,683 - Extraction -WARNING -Executing extract_files method...
2023-10-14 02:31:23,403 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 02:31:23,403 - Extraction -WARNING -Executing extract_files method...
2023-10-14 02:31:38,958 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 02:31:38,958 - root -INFO -Extracting files to output completed...
2023-10-14 02:31:38,959 - root -INFO -Writing data into Hive_table
2023-10-14 02:31:38,959 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-14 02:31:38,959 - Persist -WARNING -Creating Database
2023-10-14 02:31:45,130 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-14 02:32:03,768 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 02:32:03,768 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-14 02:32:03,768 - Persist -WARNING -Creating Database
2023-10-14 02:32:03,816 - Persist -WARNING -Now writing DataFrame[presc_id: bigint, presc_fullname: bigint, presc_state: bigint, Country_name: bigint, years_of_exp: bigint, tx_cnt: bigint, total_day_supply: bigint, total_drug_cost: bigint, dense_rank: int] into Hive_table by presc_state 
2023-10-14 02:32:43,912 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 02:32:43,912 - root -INFO -Successfully written into Hive
2023-10-14 02:32:43,916 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-14 02:33:17,767 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-14 02:33:17,768 - root -INFO -Successfully Data written into Mysql
2023-10-14 02:33:17,768 - root -INFO -Total amount of time taken : 221.48 seconds
2023-10-14 02:33:17,768 - root -INFO -Application done
2023-10-14 02:40:59,613 - root -INFO -i am in the main method..
2023-10-14 02:40:59,613 - root -INFO -calling spark object
2023-10-14 02:40:59,613 - Create_spark -INFO -get_spark_object method started
2023-10-14 02:40:59,614 - Create_spark -INFO -master is local
2023-10-14 02:41:02,824 - root -INFO -Validating spark object..........
2023-10-14 02:41:02,824 - Validate -WARNING -started the get_current_date method...
2023-10-14 02:41:05,717 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 02:41:05,717 - Validate -WARNING -Validation done go frwd...
2023-10-14 02:41:05,717 - root -INFO -reading file which is of > parquet
2023-10-14 02:41:05,717 - Ingest -WARNING -load_files method started...
2023-10-14 02:41:06,238 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 02:41:06,238 - root -INFO -displaying file df_city
2023-10-14 02:41:07,819 - root -INFO -here to validate the df
2023-10-14 02:41:07,819 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 02:41:08,225 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 02:41:08,225 - root -INFO -checking for the files in the Fact...
2023-10-14 02:41:08,225 - root -INFO -reading file which is of > csv
2023-10-14 02:41:08,225 - Ingest -WARNING -load_files method started...
2023-10-14 02:41:12,489 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 02:41:12,489 - root -INFO -displaying the df_fact dataframe
2023-10-14 02:41:12,748 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 02:41:13,293 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 02:41:13,294 - root -INFO -implementing data_processing methods...
2023-10-14 02:41:13,295 - Data_processing -WARNING -data_clean method started...
2023-10-14 02:41:13,295 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 02:41:13,345 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 02:41:13,366 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 02:41:13,376 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 02:41:13,412 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 02:41:13,425 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 02:41:13,433 - Data_processing -WARNING -Checking for null values...
2023-10-14 02:41:13,533 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 02:41:13,556 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 02:41:18,772 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 02:41:18,772 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 02:41:37,151 - root -INFO -validating schema for the dataframes....
2023-10-14 02:41:37,152 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 02:41:37,153 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 02:41:37,153 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 02:41:37,153 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 02:41:37,153 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 02:41:37,153 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 02:41:37,153 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 02:41:37,153 - Validate -INFO -print_schema done, go frwd...
2023-10-14 02:41:37,153 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 02:41:37,154 - Validate -INFO -	StructField('presc_id', LongType(), False)
2023-10-14 02:41:37,154 - Validate -INFO -	StructField('presc_city', LongType(), False)
2023-10-14 02:41:37,154 - Validate -INFO -	StructField('presc_state', LongType(), False)
2023-10-14 02:41:37,154 - Validate -INFO -	StructField('presc_spclt', LongType(), False)
2023-10-14 02:41:37,154 - Validate -INFO -	StructField('drug_name', LongType(), False)
2023-10-14 02:41:37,154 - Validate -INFO -	StructField('tx_cnt', LongType(), False)
2023-10-14 02:41:37,155 - Validate -INFO -	StructField('total_day_supply', LongType(), False)
2023-10-14 02:41:37,155 - Validate -INFO -	StructField('total_drug_cost', LongType(), False)
2023-10-14 02:41:37,155 - Validate -INFO -	StructField('years_of_exp', LongType(), False)
2023-10-14 02:41:37,155 - Validate -INFO -	StructField('Country_name', LongType(), False)
2023-10-14 02:41:37,155 - Validate -INFO -	StructField('presc_fullname', LongType(), False)
2023-10-14 02:41:37,155 - Validate -INFO -print_schema done, go frwd...
2023-10-14 02:41:37,155 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 02:41:37,265 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 02:41:54,905 - root -INFO -data transformation executed...
2023-10-14 02:41:54,906 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 02:41:54,909 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 02:41:54,942 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 02:41:54,984 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 02:41:55,058 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 02:41:55,059 - root -INFO -displaying the df_report_1
2023-10-14 02:41:56,269 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: reentrant call inside <_io.BufferedReader name=480>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-10-14 02:41:56,272 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\python\python3.11\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\pyspark\context.py", line 381, in signal_handler
    self.cancelAllJobs()
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\pyspark\context.py", line 2446, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\pyspark\errors\exceptions\captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o18.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\spark\spark-3.5.0-bin-hadoop3\python\lib\py4j-0.10.9.7-src.zip\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-10-14 02:44:53,204 - root -INFO -i am in the main method..
2023-10-14 02:44:53,204 - root -INFO -calling spark object
2023-10-14 02:44:53,204 - Create_spark -INFO -get_spark_object method started
2023-10-14 02:44:53,204 - Create_spark -INFO -master is local
2023-10-14 02:44:56,706 - root -INFO -Validating spark object..........
2023-10-14 02:44:56,706 - Validate -WARNING -started the get_current_date method...
2023-10-14 02:44:59,658 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 02:44:59,658 - Validate -WARNING -Validation done go frwd...
2023-10-14 02:44:59,658 - root -INFO -reading file which is of > parquet
2023-10-14 02:44:59,658 - Ingest -WARNING -load_files method started...
2023-10-14 02:45:00,130 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 02:45:00,130 - root -INFO -displaying file df_city
2023-10-14 02:45:01,603 - root -INFO -here to validate the df
2023-10-14 02:45:01,603 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 02:45:02,947 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 02:45:02,947 - root -INFO -checking for the files in the Fact...
2023-10-14 02:45:02,948 - root -INFO -reading file which is of > csv
2023-10-14 02:45:02,948 - Ingest -WARNING -load_files method started...
2023-10-14 02:45:17,114 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 02:45:17,115 - root -INFO -displaying the df_fact dataframe
2023-10-14 02:45:17,820 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 02:45:19,390 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 02:45:19,390 - root -INFO -implementing data_processing methods...
2023-10-14 02:45:19,390 - Data_processing -WARNING -data_clean method started...
2023-10-14 02:45:19,390 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 02:45:19,469 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 02:45:19,533 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 02:45:19,570 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 02:45:19,663 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 02:45:19,703 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 02:45:19,730 - Data_processing -WARNING -Checking for null values...
2023-10-14 02:45:19,730 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 02:45:19,776 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 02:45:27,902 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 02:45:27,902 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 02:45:28,819 - root -INFO -validating schema for the dataframes....
2023-10-14 02:45:28,819 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 02:45:28,821 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 02:45:28,821 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 02:45:28,822 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 02:45:28,822 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 02:45:28,822 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 02:45:28,822 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 02:45:28,822 - Validate -INFO -print_schema done, go frwd...
2023-10-14 02:45:28,822 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 02:45:28,825 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-14 02:45:28,825 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-14 02:45:28,826 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-14 02:45:28,826 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-14 02:45:28,826 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-14 02:45:28,826 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-14 02:45:28,827 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-14 02:45:28,827 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-14 02:45:28,827 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-14 02:45:28,827 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-14 02:45:28,827 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-14 02:45:28,827 - Validate -INFO -print_schema done, go frwd...
2023-10-14 02:45:28,827 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 02:45:29,176 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 02:46:27,932 - root -INFO -data transformation executed...
2023-10-14 02:46:27,933 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 02:46:27,940 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 02:46:28,008 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 02:46:28,114 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 02:46:28,206 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 02:46:28,206 - root -INFO -displaying the df_report_1
2023-10-14 02:46:51,756 - root -INFO -Displaying data_report2 method....
2023-10-14 02:46:51,756 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-14 02:46:51,757 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-14 02:46:52,032 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-14 02:47:12,573 - root -INFO -extracting files to output...
2023-10-14 02:47:12,573 - Extraction -WARNING -Executing extract_files method...
2023-10-14 02:47:33,181 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 02:47:33,181 - Extraction -WARNING -Executing extract_files method...
2023-10-14 02:47:53,424 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 02:47:53,425 - root -INFO -Extracting files to output completed...
2023-10-14 02:47:53,425 - root -INFO -Writing data into Hive_table
2023-10-14 02:47:53,425 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-14 02:47:53,425 - Persist -WARNING -Creating Database
2023-10-14 02:48:01,566 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-14 02:48:24,502 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 02:48:24,502 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-14 02:48:24,502 - Persist -WARNING -Creating Database
2023-10-14 02:48:24,533 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-14 02:48:31,867 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 02:48:31,867 - root -INFO -Successfully written into Hive
2023-10-14 02:48:31,868 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-14 02:48:54,353 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-14 02:48:54,353 - root -INFO -Successfully Data written into Mysql
2023-10-14 02:48:54,353 - root -INFO -Total amount of time taken : 241.15 seconds
2023-10-14 02:48:54,353 - root -INFO -Application done
2023-10-14 03:15:38,416 - root -INFO -i am in the main method..
2023-10-14 03:15:38,416 - root -INFO -calling spark object
2023-10-14 03:15:38,416 - Create_spark -INFO -get_spark_object method started
2023-10-14 03:15:38,416 - Create_spark -INFO -master is local
2023-10-14 03:15:41,863 - root -INFO -Validating spark object..........
2023-10-14 03:15:41,863 - Validate -WARNING -started the get_current_date method...
2023-10-14 03:15:44,895 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 03:15:44,895 - Validate -WARNING -Validation done go frwd...
2023-10-14 03:15:44,895 - root -INFO -reading file which is of > parquet
2023-10-14 03:15:44,895 - Ingest -WARNING -load_files method started...
2023-10-14 03:15:45,424 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 03:15:45,424 - root -INFO -displaying file df_city
2023-10-14 03:15:47,021 - root -INFO -here to validate the df
2023-10-14 03:15:47,021 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 03:15:47,432 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 03:15:47,433 - root -INFO -checking for the files in the Fact...
2023-10-14 03:15:47,433 - root -INFO -reading file which is of > csv
2023-10-14 03:15:47,433 - Ingest -WARNING -load_files method started...
2023-10-14 03:15:51,378 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 03:15:51,378 - root -INFO -displaying the df_fact dataframe
2023-10-14 03:15:51,564 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 03:15:52,120 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 03:15:52,120 - root -INFO -implementing data_processing methods...
2023-10-14 03:15:52,120 - Data_processing -WARNING -data_clean method started...
2023-10-14 03:15:52,120 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 03:15:52,149 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 03:15:52,170 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 03:15:52,181 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 03:15:52,211 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 03:15:52,223 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 03:15:52,233 - Data_processing -WARNING -Checking for null values...
2023-10-14 03:15:52,233 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 03:15:52,255 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 03:15:54,623 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 03:15:54,623 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 03:15:54,912 - root -INFO -validating schema for the dataframes....
2023-10-14 03:15:54,912 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 03:15:54,913 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 03:15:54,913 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 03:15:54,913 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 03:15:54,913 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 03:15:54,913 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 03:15:54,913 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 03:15:54,914 - Validate -INFO -print_schema done, go frwd...
2023-10-14 03:15:54,914 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 03:15:54,915 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-14 03:15:54,916 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-14 03:15:54,916 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-14 03:15:54,916 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-14 03:15:54,916 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-14 03:15:54,916 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-14 03:15:54,917 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-14 03:15:54,917 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-14 03:15:54,917 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-14 03:15:54,917 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-14 03:15:54,917 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-14 03:15:54,917 - Validate -INFO -print_schema done, go frwd...
2023-10-14 03:15:54,918 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 03:15:55,084 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 03:16:12,655 - root -INFO -data transformation executed...
2023-10-14 03:16:12,655 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 03:16:12,658 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 03:23:48,024 - root -INFO -i am in the main method..
2023-10-14 03:23:48,024 - root -INFO -calling spark object
2023-10-14 03:23:48,024 - Create_spark -INFO -get_spark_object method started
2023-10-14 03:23:48,024 - Create_spark -INFO -master is local
2023-10-14 03:23:51,473 - root -INFO -Validating spark object..........
2023-10-14 03:23:51,473 - Validate -WARNING -started the get_current_date method...
2023-10-14 03:23:54,502 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 14))]
2023-10-14 03:23:54,502 - Validate -WARNING -Validation done go frwd...
2023-10-14 03:23:54,502 - root -INFO -reading file which is of > parquet
2023-10-14 03:23:54,503 - Ingest -WARNING -load_files method started...
2023-10-14 03:23:55,034 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-14 03:23:55,034 - root -INFO -displaying file df_city
2023-10-14 03:23:56,531 - root -INFO -here to validate the df
2023-10-14 03:23:56,531 - Ingest -WARNING -here to count the records in the df_city
2023-10-14 03:23:56,912 - Ingest -WARNING -number of records 28338 :: 
2023-10-14 03:23:56,912 - root -INFO -checking for the files in the Fact...
2023-10-14 03:23:56,912 - root -INFO -reading file which is of > csv
2023-10-14 03:23:56,912 - Ingest -WARNING -load_files method started...
2023-10-14 03:24:00,685 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-14 03:24:00,685 - root -INFO -displaying the df_fact dataframe
2023-10-14 03:24:00,887 - Ingest -WARNING -here to count the records in the df_fact
2023-10-14 03:24:01,427 - Ingest -WARNING -number of records 1329329 :: 
2023-10-14 03:24:01,428 - root -INFO -implementing data_processing methods...
2023-10-14 03:24:01,428 - Data_processing -WARNING -data_clean method started...
2023-10-14 03:24:01,428 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-14 03:24:01,468 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-14 03:24:01,486 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-14 03:24:01,505 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-14 03:24:01,550 - Data_processing -WARNING -Concat fname and lname...
2023-10-14 03:24:01,569 - Data_processing -WARNING -Dropping fname and lname...
2023-10-14 03:24:01,578 - Data_processing -WARNING -Checking for null values...
2023-10-14 03:24:01,578 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-14 03:24:01,599 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-14 03:24:04,120 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-14 03:24:04,120 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-14 03:24:04,419 - root -INFO -validating schema for the dataframes....
2023-10-14 03:24:04,419 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-14 03:24:04,420 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-14 03:24:04,420 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-14 03:24:04,420 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-14 03:24:04,420 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-14 03:24:04,420 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-14 03:24:04,420 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-14 03:24:04,420 - Validate -INFO -print_schema done, go frwd...
2023-10-14 03:24:04,420 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-14 03:24:04,422 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-14 03:24:04,422 - Validate -INFO -print_schema done, go frwd...
2023-10-14 03:24:04,422 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-14 03:24:04,559 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-14 03:24:21,614 - root -INFO -data transformation executed...
2023-10-14 03:24:21,615 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-14 03:24:21,617 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-14 03:24:21,642 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-14 03:24:21,667 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-14 03:24:21,697 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-14 03:24:21,698 - root -INFO -displaying the df_report_1
2023-10-14 03:24:33,122 - root -INFO -Displaying data_report2 method....
2023-10-14 03:24:33,122 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-14 03:24:33,122 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-14 03:24:33,231 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-14 03:24:40,348 - root -INFO -extracting files to output...
2023-10-14 03:24:40,348 - Extraction -WARNING -Executing extract_files method...
2023-10-14 03:24:51,995 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 03:24:51,995 - Extraction -WARNING -Executing extract_files method...
2023-10-14 03:24:59,194 - Extraction -WARNING -extract_files method successfully executed...
2023-10-14 03:24:59,194 - root -INFO -Extracting files to output completed...
2023-10-14 03:24:59,194 - root -INFO -Writing data into Hive_table
2023-10-14 03:24:59,194 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-14 03:24:59,194 - Persist -WARNING -Creating Database
2023-10-14 03:25:02,059 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-14 03:25:13,629 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 03:25:13,629 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-14 03:25:13,629 - Persist -WARNING -Creating Database
2023-10-14 03:25:13,654 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-14 03:25:20,609 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-14 03:25:20,609 - root -INFO -Successfully written into Hive
2023-10-14 03:25:20,610 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-14 03:25:33,524 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-14 03:25:33,524 - root -INFO -Successfully Data written into Mysql
2023-10-14 03:25:33,524 - root -INFO -Total amount of time taken : 105.50 seconds
2023-10-14 03:25:33,524 - root -INFO -Application done
2023-10-15 03:43:04,828 - root -INFO -i am in the main method..
2023-10-15 03:43:04,829 - root -INFO -calling spark object
2023-10-15 03:43:04,829 - Create_spark -INFO -get_spark_object method started
2023-10-15 03:43:04,829 - Create_spark -INFO -master is local
2023-10-15 03:43:23,698 - root -INFO -Validating spark object..........
2023-10-15 03:43:23,699 - Validate -WARNING -started the get_current_date method...
2023-10-15 03:43:32,386 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 10, 15))]
2023-10-15 03:43:32,387 - Validate -WARNING -Validation done go frwd...
2023-10-15 03:43:32,387 - root -INFO -reading file which is of > parquet
2023-10-15 03:43:32,387 - Ingest -WARNING -load_files method started...
2023-10-15 03:43:33,940 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-10-15 03:43:33,941 - root -INFO -displaying file df_city
2023-10-15 03:43:39,291 - root -INFO -here to validate the df
2023-10-15 03:43:39,292 - Ingest -WARNING -here to count the records in the df_city
2023-10-15 03:43:40,717 - Ingest -WARNING -number of records 28338 :: 
2023-10-15 03:43:40,717 - root -INFO -checking for the files in the Fact...
2023-10-15 03:43:40,718 - root -INFO -reading file which is of > csv
2023-10-15 03:43:40,718 - Ingest -WARNING -load_files method started...
2023-10-15 03:43:50,856 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-10-15 03:43:50,856 - root -INFO -displaying the df_fact dataframe
2023-10-15 03:43:51,088 - Ingest -WARNING -here to count the records in the df_fact
2023-10-15 03:43:51,669 - Ingest -WARNING -number of records 1329329 :: 
2023-10-15 03:43:51,669 - root -INFO -implementing data_processing methods...
2023-10-15 03:43:51,669 - Data_processing -WARNING -data_clean method started...
2023-10-15 03:43:51,669 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-10-15 03:43:51,708 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-10-15 03:43:51,727 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-10-15 03:43:51,738 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-10-15 03:43:51,778 - Data_processing -WARNING -Concat fname and lname...
2023-10-15 03:43:51,792 - Data_processing -WARNING -Dropping fname and lname...
2023-10-15 03:43:51,800 - Data_processing -WARNING -Checking for null values...
2023-10-15 03:43:51,801 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-10-15 03:43:51,821 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-10-15 03:43:54,089 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-10-15 03:43:54,089 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-10-15 03:43:54,395 - root -INFO -validating schema for the dataframes....
2023-10-15 03:43:54,395 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-10-15 03:43:54,396 - Validate -INFO -	StructField('city', StringType(), True)
2023-10-15 03:43:54,396 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-10-15 03:43:54,396 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-10-15 03:43:54,396 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-10-15 03:43:54,396 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-10-15 03:43:54,396 - Validate -INFO -	StructField('zips', StringType(), True)
2023-10-15 03:43:54,396 - Validate -INFO -print_schema done, go frwd...
2023-10-15 03:43:54,396 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-10-15 03:43:54,398 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-10-15 03:43:54,398 - Validate -INFO -print_schema done, go frwd...
2023-10-15 03:43:54,398 - Validate -INFO -check for nulls method executing.......for df_fact
2023-10-15 03:43:54,548 - Validate -WARNING -Check_for_nulls executed successfully...
2023-10-15 03:44:17,138 - root -INFO -data transformation executed...
2023-10-15 03:44:17,138 - Data_transformation -WARNING -Processing data_report1 method...
2023-10-15 03:44:17,141 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-10-15 03:44:17,167 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-10-15 03:44:17,192 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-10-15 03:44:17,229 - Data_transformation -WARNING -data_report1 successfully executed...
2023-10-15 03:44:17,230 - root -INFO -displaying the df_report_1
2023-10-15 03:44:29,029 - root -INFO -Displaying data_report2 method....
2023-10-15 03:44:29,029 - Data_transformation -WARNING -Executing data_report2 method...
2023-10-15 03:44:29,030 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-10-15 03:44:29,122 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-10-15 03:44:36,142 - root -INFO -extracting files to output...
2023-10-15 03:44:36,142 - Extraction -WARNING -Executing extract_files method...
2023-10-15 03:44:46,285 - Extraction -WARNING -extract_files method successfully executed...
2023-10-15 03:44:46,285 - Extraction -WARNING -Executing extract_files method...
2023-10-15 03:44:53,223 - Extraction -WARNING -extract_files method successfully executed...
2023-10-15 03:44:53,224 - root -INFO -Extracting files to output completed...
2023-10-15 03:44:53,224 - root -INFO -Writing data into Hive_table
2023-10-15 03:44:53,224 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-10-15 03:44:53,224 - Persist -WARNING -Creating Database
2023-10-15 03:44:56,409 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-10-15 03:45:08,213 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-15 03:45:08,213 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-10-15 03:45:08,213 - Persist -WARNING -Creating Database
2023-10-15 03:45:08,238 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-10-15 03:45:15,484 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-10-15 03:45:15,485 - root -INFO -Successfully written into Hive
2023-10-15 03:45:15,485 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-10-15 03:45:27,757 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-10-15 03:45:27,757 - root -INFO -Successfully Data written into Mysql
2023-10-15 03:45:27,757 - root -INFO -Total amount of time taken : 142.93 seconds
2023-10-15 03:45:27,757 - root -INFO -Application done
2023-12-12 02:13:50,924 - root -INFO -i am in the main method..
2023-12-12 02:13:50,925 - root -INFO -calling spark object
2023-12-12 02:13:50,925 - Create_spark -INFO -get_spark_object method started
2023-12-12 02:13:50,925 - Create_spark -INFO -master is local
2023-12-12 02:14:58,539 - root -INFO -i am in the main method..
2023-12-12 02:14:58,539 - root -INFO -calling spark object
2023-12-12 02:14:58,539 - Create_spark -INFO -get_spark_object method started
2023-12-12 02:14:58,540 - Create_spark -INFO -master is local
2023-12-12 02:15:01,890 - root -INFO -i am in the main method..
2023-12-12 02:15:01,891 - root -INFO -calling spark object
2023-12-12 02:15:01,891 - Create_spark -INFO -get_spark_object method started
2023-12-12 02:15:01,891 - Create_spark -INFO -master is local
2023-12-12 02:18:10,494 - root -INFO -i am in the main method..
2023-12-12 02:18:10,494 - root -INFO -calling spark object
2023-12-12 02:18:10,494 - Create_spark -INFO -get_spark_object method started
2023-12-12 02:18:10,494 - Create_spark -INFO -master is local
2023-12-12 02:19:21,740 - root -INFO -i am in the main method..
2023-12-12 02:19:21,740 - root -INFO -calling spark object
2023-12-12 02:19:21,740 - Create_spark -INFO -get_spark_object method started
2023-12-12 02:19:21,740 - Create_spark -INFO -master is local
2023-12-12 02:19:40,525 - root -INFO -Validating spark object..........
2023-12-12 02:19:40,525 - Validate -WARNING -started the get_current_date method...
2023-12-12 02:19:42,972 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 02:19:42,972 - Validate -WARNING -Validation done go frwd...
2023-12-12 02:19:42,973 - root -INFO -reading file which is of > parquet
2023-12-12 02:19:42,973 - Ingest -WARNING -load_files method started...
2023-12-12 02:19:43,533 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 02:19:43,533 - root -INFO -displaying file df_city
2023-12-12 02:19:45,177 - root -INFO -here to validate the df
2023-12-12 02:19:45,177 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 02:19:45,572 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 02:19:45,572 - root -INFO -checking for the files in the Fact...
2023-12-12 02:19:45,573 - root -INFO -reading file which is of > csv
2023-12-12 02:19:45,573 - Ingest -WARNING -load_files method started...
2023-12-12 02:19:53,633 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 02:19:53,634 - root -INFO -displaying the df_fact dataframe
2023-12-12 02:19:53,984 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 02:19:54,537 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 02:19:54,537 - root -INFO -implementing data_processing methods...
2023-12-12 02:19:54,537 - Data_processing -WARNING -data_clean method started...
2023-12-12 02:19:54,537 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 02:19:54,563 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 02:19:54,581 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 02:19:54,595 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 02:19:54,627 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 02:19:54,639 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 02:19:54,648 - Data_processing -WARNING -Checking for null values...
2023-12-12 02:19:54,648 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 02:19:54,667 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 02:19:57,059 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 02:19:57,059 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 02:19:57,406 - root -INFO -validating schema for the dataframes....
2023-12-12 02:19:57,406 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 02:19:57,407 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 02:19:57,407 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 02:19:57,407 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 02:19:57,407 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 02:19:57,407 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 02:19:57,407 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 02:19:57,407 - Validate -INFO -print_schema done, go frwd...
2023-12-12 02:19:57,407 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 02:19:57,408 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 02:19:57,409 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 02:19:57,409 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 02:19:57,409 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 02:19:57,409 - Validate -INFO -print_schema done, go frwd...
2023-12-12 02:19:57,409 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 02:19:57,522 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 02:20:14,384 - root -INFO -data transformation executed...
2023-12-12 02:20:14,384 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 02:20:14,387 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 02:20:14,419 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 02:20:14,454 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 02:20:14,493 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 02:20:14,493 - root -INFO -displaying the df_report_1
2023-12-12 02:25:22,511 - root -INFO -Displaying data_report2 method....
2023-12-12 02:25:22,511 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 02:25:22,511 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 02:25:22,704 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 02:25:30,028 - root -INFO -extracting files to output...
2023-12-12 02:25:30,029 - Extraction -WARNING -Executing extract_files method...
2023-12-12 02:29:59,389 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 02:29:59,390 - Extraction -WARNING -Executing extract_files method...
2023-12-12 02:30:12,285 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 02:30:12,285 - root -INFO -Extracting files to output completed...
2023-12-12 02:30:12,285 - root -INFO -Writing data into Hive_table
2023-12-12 02:30:12,285 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-12-12 02:30:12,285 - Persist -WARNING -Creating Database
2023-12-12 02:30:18,202 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-12-12 02:35:51,445 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-12-12 02:35:51,445 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-12-12 02:35:51,445 - Persist -WARNING -Creating Database
2023-12-12 02:35:51,504 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-12-12 02:36:09,180 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-12-12 02:36:09,180 - root -INFO -Successfully written into Hive
2023-12-12 02:36:09,182 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-12-12 02:41:42,421 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-12-12 02:41:42,422 - root -INFO -Successfully Data written into Mysql
2023-12-12 02:41:42,422 - root -INFO -Total amount of time taken : 1340.68 seconds
2023-12-12 02:41:42,422 - root -INFO -Application done
2023-12-12 02:42:35,805 - root -INFO -i am in the main method..
2023-12-12 02:42:35,805 - root -INFO -calling spark object
2023-12-12 02:42:35,805 - Create_spark -INFO -get_spark_object method started
2023-12-12 02:42:35,805 - Create_spark -INFO -master is local
2023-12-12 02:42:40,014 - root -INFO -Validating spark object..........
2023-12-12 02:42:40,015 - Validate -WARNING -started the get_current_date method...
2023-12-12 02:42:42,197 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 02:42:42,197 - Validate -WARNING -Validation done go frwd...
2023-12-12 02:42:42,197 - root -INFO -reading file which is of > parquet
2023-12-12 02:42:42,197 - Ingest -WARNING -load_files method started...
2023-12-12 02:42:42,729 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 02:42:42,729 - root -INFO -displaying file df_city
2023-12-12 02:42:44,205 - root -INFO -here to validate the df
2023-12-12 02:42:44,205 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 02:42:44,533 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 02:42:44,534 - root -INFO -checking for the files in the Fact...
2023-12-12 02:42:44,534 - root -INFO -reading file which is of > csv
2023-12-12 02:42:44,534 - Ingest -WARNING -load_files method started...
2023-12-12 02:42:48,366 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 02:42:48,366 - root -INFO -displaying the df_fact dataframe
2023-12-12 02:42:48,616 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 02:42:49,148 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 02:42:49,148 - root -INFO -implementing data_processing methods...
2023-12-12 02:42:49,149 - Data_processing -WARNING -data_clean method started...
2023-12-12 02:42:49,149 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 02:42:49,177 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 02:42:49,199 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 02:42:49,209 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 02:42:49,246 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 02:42:49,260 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 02:42:49,268 - Data_processing -WARNING -Checking for null values...
2023-12-12 02:42:49,268 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 02:42:49,287 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 02:42:51,588 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 02:42:51,588 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 02:42:51,902 - root -INFO -validating schema for the dataframes....
2023-12-12 02:42:51,902 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 02:42:51,903 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 02:42:51,903 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 02:42:51,904 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 02:42:51,904 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 02:42:51,904 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 02:42:51,904 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 02:42:51,904 - Validate -INFO -print_schema done, go frwd...
2023-12-12 02:42:51,904 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 02:42:51,905 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 02:42:51,905 - Validate -INFO -print_schema done, go frwd...
2023-12-12 02:42:51,905 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 02:42:52,021 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 02:43:11,434 - root -INFO -data transformation executed...
2023-12-12 02:43:11,434 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 02:43:11,437 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 02:43:11,458 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 02:43:11,489 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 02:43:11,537 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 02:43:11,537 - root -INFO -displaying the df_report_1
2023-12-12 02:48:34,984 - root -INFO -Displaying data_report2 method....
2023-12-12 02:48:34,985 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 02:48:34,985 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 02:48:35,178 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 02:48:42,871 - root -INFO -extracting files to output...
2023-12-12 02:48:42,872 - Extraction -WARNING -Executing extract_files method...
2023-12-12 02:53:08,242 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 02:53:08,242 - Extraction -WARNING -Executing extract_files method...
2023-12-12 02:53:20,808 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 02:53:20,808 - root -INFO -Extracting files to output completed...
2023-12-12 02:53:20,808 - root -INFO -Writing data into Hive_table
2023-12-12 02:53:20,808 - Persist -WARNING -Persisting the data into Hive Table for df_city
2023-12-12 02:53:20,808 - Persist -WARNING -Creating Database
2023-12-12 02:53:26,715 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipscounts: int, presc_counts: bigint] into Hive_table by state_name 
2023-12-12 02:58:29,016 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-12-12 02:58:29,016 - Persist -WARNING -Persisting the data into Hive Table for df_presc
2023-12-12 02:58:29,017 - Persist -WARNING -Creating Database
2023-12-12 02:58:29,088 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into Hive_table by presc_state 
2023-12-12 02:58:45,512 - Persist -WARNING -Data Successfully persisted into Hive_table...
2023-12-12 02:58:45,512 - root -INFO -Successfully written into Hive
2023-12-12 02:58:45,513 - Persist -WARNING -Executing persist_data_mysql method with df_city
2023-12-12 03:03:25,946 - Persist -WARNING -Data Successfully persisted into MySQL...
2023-12-12 03:03:25,946 - root -INFO -Successfully Data written into Mysql
2023-12-12 03:03:25,947 - root -INFO -Total amount of time taken : 1250.14 seconds
2023-12-12 03:03:25,947 - root -INFO -Application done
2023-12-12 20:27:13,686 - root -INFO -i am in the main method..
2023-12-12 20:27:13,686 - root -INFO -calling spark object
2023-12-12 20:27:13,686 - Create_spark -INFO -get_spark_object method started
2023-12-12 20:27:13,686 - Create_spark -INFO -master is local
2023-12-12 20:27:30,674 - root -INFO -Validating spark object..........
2023-12-12 20:27:30,674 - Validate -WARNING -started the get_current_date method...
2023-12-12 20:27:34,079 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 20:27:34,079 - Validate -WARNING -Validation done go frwd...
2023-12-12 20:27:34,079 - root -INFO -reading file which is of > parquet
2023-12-12 20:27:34,079 - Ingest -WARNING -load_files method started...
2023-12-12 20:27:34,724 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 20:27:34,724 - root -INFO -displaying file df_city
2023-12-12 20:27:36,488 - root -INFO -here to validate the df
2023-12-12 20:27:36,488 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 20:27:36,999 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 20:27:36,999 - root -INFO -checking for the files in the Fact...
2023-12-12 20:27:36,999 - root -INFO -reading file which is of > csv
2023-12-12 20:27:36,999 - Ingest -WARNING -load_files method started...
2023-12-12 20:27:40,768 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 20:27:40,768 - root -INFO -displaying the df_fact dataframe
2023-12-12 20:27:40,962 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 20:27:41,516 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 20:27:41,516 - root -INFO -implementing data_processing methods...
2023-12-12 20:27:41,517 - Data_processing -WARNING -data_clean method started...
2023-12-12 20:27:41,517 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 20:27:41,555 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 20:27:41,575 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 20:27:41,587 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 20:27:41,627 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 20:27:41,643 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 20:27:41,657 - Data_processing -WARNING -Checking for null values...
2023-12-12 20:27:41,657 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 20:27:41,674 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 20:27:43,971 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 20:27:43,971 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 20:27:44,342 - root -INFO -validating schema for the dataframes....
2023-12-12 20:27:44,342 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 20:27:44,343 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 20:27:44,343 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 20:27:44,343 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 20:27:44,344 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 20:27:44,344 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 20:27:44,344 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 20:27:44,344 - Validate -INFO -print_schema done, go frwd...
2023-12-12 20:27:44,344 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 20:27:44,345 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 20:27:44,345 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 20:27:44,345 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 20:27:44,345 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 20:27:44,345 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 20:27:44,346 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 20:27:44,346 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 20:27:44,346 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 20:27:44,346 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 20:27:44,346 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 20:27:44,346 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 20:27:44,346 - Validate -INFO -print_schema done, go frwd...
2023-12-12 20:27:44,346 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 20:27:44,462 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 20:28:01,145 - root -INFO -data transformation executed...
2023-12-12 20:28:01,145 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 20:28:01,149 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 20:28:01,174 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 20:28:01,197 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 20:28:01,232 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 20:28:01,232 - root -INFO -displaying the df_report_1
2023-12-12 20:28:13,133 - root -INFO -Displaying data_report2 method....
2023-12-12 20:28:13,133 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 20:28:13,134 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 20:28:13,227 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 20:28:20,329 - root -INFO -extracting files to output...
2023-12-12 20:28:20,329 - Extraction -WARNING -Executing extract_files method...
2023-12-12 20:28:30,499 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 20:28:30,499 - Extraction -WARNING -Executing extract_files method...
2023-12-12 20:28:37,470 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 20:28:37,470 - root -INFO -Extracting files to output completed...
2023-12-12 20:28:37,471 - root -INFO -Total amount of time taken : 83.79 seconds
2023-12-12 20:28:37,471 - root -INFO -Application done
2023-12-12 20:45:52,801 - root -INFO -i am in the main method..
2023-12-12 20:45:52,801 - root -INFO -calling spark object
2023-12-12 20:45:52,801 - Create_spark -INFO -get_spark_object method started
2023-12-12 20:45:52,801 - Create_spark -INFO -master is local
2023-12-12 20:46:10,536 - root -INFO -Validating spark object..........
2023-12-12 20:46:10,536 - Validate -WARNING -started the get_current_date method...
2023-12-12 20:46:13,683 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 20:46:13,683 - Validate -WARNING -Validation done go frwd...
2023-12-12 20:46:13,683 - root -INFO -reading file which is of > parquet
2023-12-12 20:46:13,684 - Ingest -WARNING -load_files method started...
2023-12-12 20:46:14,178 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 20:46:14,178 - root -INFO -reading file df_city : 21.38 seconds
2023-12-12 20:46:14,178 - root -INFO -displaying file df_city
2023-12-12 20:46:15,920 - root -INFO -displaying file df_city : 23.12 seconds
2023-12-12 20:46:15,920 - root -INFO -here to validate the df
2023-12-12 20:46:15,920 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 20:46:16,348 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 20:46:16,348 - root -INFO -checking for the files in the Fact...
2023-12-12 20:46:16,349 - root -INFO -reading file which is of > csv
2023-12-12 20:46:16,349 - Ingest -WARNING -load_files method started...
2023-12-12 20:46:20,477 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 20:46:20,477 - root -INFO -reading file df_fact : 27.68 seconds
2023-12-12 20:46:20,477 - root -INFO -displaying the df_fact dataframe
2023-12-12 20:46:20,733 - root -INFO -displaying file df_fact : 27.93 seconds
2023-12-12 20:46:20,733 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 20:46:21,293 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 20:46:21,293 - root -INFO -implementing data_processing methods...
2023-12-12 20:46:21,293 - Data_processing -WARNING -data_clean method started...
2023-12-12 20:46:21,293 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 20:46:21,325 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 20:46:21,343 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 20:46:21,353 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 20:46:21,386 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 20:46:21,403 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 20:46:21,414 - Data_processing -WARNING -Checking for null values...
2023-12-12 20:46:21,414 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 20:46:21,433 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 20:46:24,142 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 20:46:24,142 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 20:46:24,474 - root -INFO -implementing data_processing methods (data_clean) : 31.67 seconds
2023-12-12 20:46:24,474 - root -INFO -validating schema for the dataframes....
2023-12-12 20:46:24,475 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 20:46:24,476 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 20:46:24,476 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 20:46:24,476 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 20:46:24,476 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 20:46:24,476 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 20:46:24,476 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 20:46:24,476 - Validate -INFO -print_schema done, go frwd...
2023-12-12 20:46:24,476 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 20:46:24,478 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 20:46:24,478 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 20:46:24,478 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 20:46:24,478 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 20:46:24,479 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 20:46:24,479 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 20:46:24,479 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 20:46:24,479 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 20:46:24,479 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 20:46:24,479 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 20:46:24,479 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 20:46:24,479 - Validate -INFO -print_schema done, go frwd...
2023-12-12 20:46:24,479 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 20:46:24,603 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 20:46:43,644 - root -INFO - check_for_nulls : 50.84 seconds
2023-12-12 20:46:43,644 - root -INFO -data transformation executed...
2023-12-12 20:46:43,644 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 20:46:43,650 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 20:46:43,672 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 20:46:43,698 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 20:46:43,728 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 20:46:43,728 - root -INFO -displaying the df_report_1
2023-12-12 20:46:55,193 - root -INFO -displaying the df_report_1 : 62.39 seconds
2023-12-12 20:46:55,194 - root -INFO -Displaying data_report2 method....
2023-12-12 20:46:55,194 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 20:46:55,194 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 20:46:55,288 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 20:47:02,587 - root -INFO -Displaying data_report2 : 69.79 seconds
2023-12-12 20:47:02,587 - root -INFO -extracting files to output...
2023-12-12 20:47:02,587 - Extraction -WARNING -Executing extract_files method...
2023-12-12 20:47:13,586 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 20:47:13,586 - Extraction -WARNING -Executing extract_files method...
2023-12-12 20:47:21,058 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 20:47:21,058 - root -INFO -Extracting files to output completed...
2023-12-12 20:47:21,058 - root -INFO -extracting files to output : 88.26 seconds
2023-12-12 20:47:21,058 - root -INFO -Total amount of time taken : 88.26 seconds
2023-12-12 20:47:21,058 - root -INFO -Application done
2023-12-12 21:19:47,614 - root -INFO -i am in the main method..
2023-12-12 21:19:47,614 - root -INFO -calling spark object
2023-12-12 21:19:47,614 - Create_spark -INFO -get_spark_object method started
2023-12-12 21:19:47,614 - Create_spark -INFO -master is local
2023-12-12 21:19:51,971 - root -INFO -Validating spark object..........
2023-12-12 21:19:51,971 - Validate -WARNING -started the get_current_date method...
2023-12-12 21:19:55,610 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 21:19:55,610 - Validate -WARNING -Validation done go frwd...
2023-12-12 21:19:55,610 - root -INFO -reading file which is of > parquet
2023-12-12 21:19:55,610 - Ingest -WARNING -load_files method started...
2023-12-12 21:19:56,210 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 21:19:56,210 - root -INFO -reading file df_city : 8.60 seconds
2023-12-12 21:19:56,210 - root -INFO -displaying file df_city
2023-12-12 21:19:58,098 - root -INFO -displaying file df_city : 10.48 seconds
2023-12-12 21:19:58,098 - root -INFO -here to validate the df
2023-12-12 21:19:58,098 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 21:19:58,605 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 21:19:58,605 - root -INFO -checking for the files in the Fact...
2023-12-12 21:19:58,605 - root -INFO -reading file which is of > csv
2023-12-12 21:19:58,605 - Ingest -WARNING -load_files method started...
2023-12-12 21:20:02,807 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 21:20:02,807 - root -INFO -reading file df_fact : 15.19 seconds
2023-12-12 21:20:02,807 - root -INFO -displaying the df_fact dataframe
2023-12-12 21:20:03,047 - root -INFO -displaying file df_fact : 15.43 seconds
2023-12-12 21:20:03,047 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 21:20:03,596 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 21:20:03,596 - root -INFO -implementing data_processing methods...
2023-12-12 21:20:03,596 - Data_processing -WARNING -data_clean method started...
2023-12-12 21:20:03,596 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 21:20:03,635 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 21:20:03,656 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 21:20:03,670 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 21:20:03,701 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 21:20:03,716 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 21:20:03,726 - Data_processing -WARNING -Checking for null values...
2023-12-12 21:20:03,726 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 21:20:03,744 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 21:20:06,017 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 21:20:06,017 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 21:20:06,384 - root -INFO -implementing data_processing methods (data_clean) : 18.77 seconds
2023-12-12 21:20:06,385 - root -INFO -validating schema for the dataframes....
2023-12-12 21:20:06,385 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 21:20:06,386 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 21:20:06,386 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 21:20:06,386 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 21:20:06,386 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 21:20:06,386 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 21:20:06,386 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 21:20:06,387 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:20:06,387 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 21:20:06,388 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 21:20:06,389 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 21:20:06,389 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 21:20:06,389 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 21:20:06,389 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:20:06,389 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 21:20:06,493 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 21:20:10,194 - root -INFO - check_for_nulls : 22.58 seconds
2023-12-12 21:20:10,195 - root -INFO -data transformation executed...
2023-12-12 21:20:10,195 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 21:20:10,198 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 21:20:10,243 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 21:20:10,285 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 21:20:10,380 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 21:20:10,380 - root -INFO -displaying the df_report_1
2023-12-12 21:20:21,546 - root -INFO -displaying the df_report_1 : 33.93 seconds
2023-12-12 21:20:21,546 - root -INFO -Displaying data_report2 method....
2023-12-12 21:20:21,546 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 21:20:21,546 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 21:20:21,619 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 21:20:28,274 - root -INFO -Displaying data_report2 : 40.66 seconds
2023-12-12 21:20:28,274 - root -INFO -extracting files to output...
2023-12-12 21:20:28,274 - Extraction -WARNING -Executing extract_files method...
2023-12-12 21:20:38,452 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 21:20:38,453 - Extraction -WARNING -Executing extract_files method...
2023-12-12 21:20:52,433 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 21:20:52,434 - root -INFO -Extracting files to output completed...
2023-12-12 21:20:52,434 - root -INFO -extracting files to output : 64.82 seconds
2023-12-12 21:20:52,434 - root -INFO -Total amount of time taken : 64.82 seconds
2023-12-12 21:20:52,435 - root -INFO -Application done
2023-12-12 21:31:17,679 - root -INFO -i am in the main method..
2023-12-12 21:31:17,679 - root -INFO -calling spark object
2023-12-12 21:31:17,679 - Create_spark -INFO -get_spark_object method started
2023-12-12 21:31:17,679 - Create_spark -INFO -master is local
2023-12-12 21:31:21,409 - root -INFO -Validating spark object..........
2023-12-12 21:31:21,409 - Validate -WARNING -started the get_current_date method...
2023-12-12 21:31:24,737 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 21:31:24,737 - Validate -WARNING -Validation done go frwd...
2023-12-12 21:31:24,737 - root -INFO -reading file which is of > parquet
2023-12-12 21:31:24,737 - Ingest -WARNING -load_files method started...
2023-12-12 21:31:25,334 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 21:31:25,335 - root -INFO -reading file df_city : 7.66 seconds
2023-12-12 21:31:25,335 - root -INFO -displaying file df_city
2023-12-12 21:31:27,227 - root -INFO -displaying file df_city : 9.55 seconds
2023-12-12 21:31:27,227 - root -INFO -here to validate the df
2023-12-12 21:31:27,227 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 21:31:27,769 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 21:31:27,769 - root -INFO -checking for the files in the Fact...
2023-12-12 21:31:27,770 - root -INFO -reading file which is of > csv
2023-12-12 21:31:27,770 - Ingest -WARNING -load_files method started...
2023-12-12 21:31:31,809 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 21:31:31,810 - root -INFO -reading file df_fact : 14.13 seconds
2023-12-12 21:31:31,810 - root -INFO -displaying the df_fact dataframe
2023-12-12 21:31:32,073 - root -INFO -displaying file df_fact : 14.39 seconds
2023-12-12 21:31:32,073 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 21:31:32,641 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 21:31:32,641 - root -INFO -implementing data_processing methods...
2023-12-12 21:31:32,641 - Data_processing -WARNING -data_clean method started...
2023-12-12 21:31:32,641 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 21:31:32,670 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 21:31:32,687 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 21:31:32,699 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 21:31:32,736 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 21:31:32,756 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 21:31:32,765 - Data_processing -WARNING -Checking for null values...
2023-12-12 21:31:36,680 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 21:31:36,698 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 21:31:39,152 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 21:31:39,152 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 21:31:39,495 - root -INFO -implementing data_processing methods (data_clean) : 21.82 seconds
2023-12-12 21:31:39,495 - root -INFO -validating schema for the dataframes....
2023-12-12 21:31:39,495 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 21:31:39,496 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 21:31:39,496 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 21:31:39,497 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 21:31:39,497 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 21:31:39,497 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 21:31:39,497 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 21:31:39,497 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:31:39,497 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 21:31:39,498 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 21:31:39,498 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:31:39,498 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 21:31:39,531 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 21:31:42,923 - root -INFO - check_for_nulls : 25.25 seconds
2023-12-12 21:31:42,923 - root -INFO -data transformation executed...
2023-12-12 21:31:42,923 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 21:31:42,927 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 21:31:42,950 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 21:31:42,976 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 21:31:43,026 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 21:31:43,026 - root -INFO -displaying the df_report_1
2023-12-12 21:31:54,456 - root -INFO -displaying the df_report_1 : 36.78 seconds
2023-12-12 21:31:54,456 - root -INFO -Displaying data_report2 method....
2023-12-12 21:31:54,456 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 21:31:54,456 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 21:31:54,545 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 21:32:01,046 - root -INFO -Displaying data_report2 : 43.37 seconds
2023-12-12 21:32:01,046 - root -INFO -extracting files to output...
2023-12-12 21:32:01,046 - Extraction -WARNING -Executing extract_files method...
2023-12-12 21:32:11,112 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 21:32:11,112 - Extraction -WARNING -Executing extract_files method...
2023-12-12 21:32:25,114 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 21:32:25,114 - root -INFO -Extracting files to output completed...
2023-12-12 21:32:25,115 - root -INFO -extracting files to output : 67.44 seconds
2023-12-12 21:32:25,115 - root -INFO -Total amount of time taken : 67.44 seconds
2023-12-12 21:32:25,115 - root -INFO -Application done
2023-12-12 21:46:31,793 - root -INFO -i am in the main method..
2023-12-12 21:46:31,794 - root -INFO -calling spark object
2023-12-12 21:46:31,794 - Create_spark -INFO -get_spark_object method started
2023-12-12 21:46:31,794 - Create_spark -INFO -master is local
2023-12-12 21:46:35,333 - root -INFO -Validating spark object..........
2023-12-12 21:46:35,333 - Validate -WARNING -started the get_current_date method...
2023-12-12 21:46:38,285 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 21:46:38,285 - Validate -WARNING -Validation done go frwd...
2023-12-12 21:46:38,285 - root -INFO -reading file which is of > parquet
2023-12-12 21:46:38,285 - Ingest -WARNING -load_files method started...
2023-12-12 21:46:38,790 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 21:46:38,790 - root -INFO -reading file df_city : 7.00 seconds
2023-12-12 21:46:38,790 - root -INFO -displaying file df_city
2023-12-12 21:46:40,471 - root -INFO -displaying file df_city : 8.68 seconds
2023-12-12 21:46:40,471 - root -INFO -here to validate the df
2023-12-12 21:46:40,471 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 21:46:40,912 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 21:46:40,912 - root -INFO -checking for the files in the Fact...
2023-12-12 21:46:40,912 - root -INFO -reading file which is of > csv
2023-12-12 21:46:40,912 - Ingest -WARNING -load_files method started...
2023-12-12 21:46:45,238 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 21:46:45,238 - root -INFO -reading file df_fact : 13.44 seconds
2023-12-12 21:46:45,238 - root -INFO -displaying the df_fact dataframe
2023-12-12 21:46:45,483 - root -INFO -displaying file df_fact : 13.69 seconds
2023-12-12 21:46:45,483 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 21:46:46,044 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 21:46:46,044 - root -INFO -implementing data_processing methods...
2023-12-12 21:46:46,045 - Data_processing -WARNING -data_clean method started...
2023-12-12 21:46:46,045 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 21:46:46,084 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 21:46:46,105 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 21:46:46,118 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 21:46:46,171 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 21:46:46,191 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 21:46:46,203 - Data_processing -WARNING -Checking for null values...
2023-12-12 21:46:46,604 - root -INFO -implementing data_processing methods (data_clean) : 14.81 seconds
2023-12-12 21:46:46,604 - root -INFO -validating schema for the dataframes....
2023-12-12 21:46:46,604 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:46:46,605 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 21:46:46,605 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 21:46:46,605 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:46:46,605 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 21:50:18,414 - root -INFO -i am in the main method..
2023-12-12 21:50:18,415 - root -INFO -calling spark object
2023-12-12 21:50:18,415 - Create_spark -INFO -get_spark_object method started
2023-12-12 21:50:18,415 - Create_spark -INFO -master is local
2023-12-12 21:50:22,408 - root -INFO -Validating spark object..........
2023-12-12 21:50:22,408 - Validate -WARNING -started the get_current_date method...
2023-12-12 21:50:25,717 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 21:50:25,717 - Validate -WARNING -Validation done go frwd...
2023-12-12 21:50:25,717 - root -INFO -reading file which is of > parquet
2023-12-12 21:50:25,717 - Ingest -WARNING -load_files method started...
2023-12-12 21:50:26,355 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 21:50:26,355 - root -INFO -reading file df_city : 7.94 seconds
2023-12-12 21:50:26,355 - root -INFO -displaying file df_city
2023-12-12 21:50:28,301 - root -INFO -displaying file df_city : 9.89 seconds
2023-12-12 21:50:28,301 - root -INFO -here to validate the df
2023-12-12 21:50:28,301 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 21:50:28,791 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 21:50:28,791 - root -INFO -checking for the files in the Fact...
2023-12-12 21:50:28,793 - root -INFO -reading file which is of > csv
2023-12-12 21:50:28,793 - Ingest -WARNING -load_files method started...
2023-12-12 21:50:33,276 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 21:50:33,276 - root -INFO -reading file df_fact : 14.86 seconds
2023-12-12 21:50:33,276 - root -INFO -displaying the df_fact dataframe
2023-12-12 21:50:33,521 - root -INFO -displaying file df_fact : 15.11 seconds
2023-12-12 21:50:33,521 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 21:50:34,076 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 21:50:34,076 - root -INFO -implementing data_processing methods...
2023-12-12 21:50:34,076 - Data_processing -WARNING -data_clean method started...
2023-12-12 21:50:34,077 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 21:50:34,114 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 21:50:34,132 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 21:50:34,146 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 21:50:34,178 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 21:50:34,198 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 21:50:34,207 - Data_processing -WARNING -Checking for null values...
2023-12-12 21:50:38,326 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 21:50:38,346 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 21:50:40,931 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 21:50:40,933 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 21:50:41,278 - root -INFO -implementing data_processing methods (data_clean) : 22.86 seconds
2023-12-12 21:50:41,278 - root -INFO -validating schema for the dataframes....
2023-12-12 21:50:41,278 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 21:50:41,279 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 21:50:41,279 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 21:50:41,279 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 21:50:41,279 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 21:50:41,279 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 21:50:41,279 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 21:50:41,279 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:50:41,279 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 21:50:41,281 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 21:50:41,281 - Validate -INFO -print_schema done, go frwd...
2023-12-12 21:50:41,281 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 21:50:41,323 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 21:50:45,255 - root -INFO - check_for_nulls : 26.84 seconds
2023-12-12 21:50:45,255 - root -INFO -data transformation executed...
2023-12-12 21:50:45,255 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 21:50:45,260 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 21:50:45,288 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 21:50:45,311 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 21:50:45,360 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 21:50:45,360 - root -INFO -displaying the df_report_1
2023-12-12 21:50:58,177 - root -INFO -displaying the df_report_1 : 39.76 seconds
2023-12-12 21:50:58,177 - root -INFO -Displaying data_report2 method....
2023-12-12 21:50:58,177 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 21:50:58,177 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 21:50:58,256 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 21:51:05,444 - root -INFO -Displaying data_report2 : 47.03 seconds
2023-12-12 21:51:05,444 - root -INFO -extracting files to output...
2023-12-12 21:51:05,444 - Extraction -WARNING -Executing extract_files method...
2023-12-12 21:51:16,271 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 21:51:16,271 - Extraction -WARNING -Executing extract_files method...
2023-12-12 21:51:23,206 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 21:51:23,206 - root -INFO -Extracting files to output completed...
2023-12-12 21:51:23,206 - root -INFO -extracting files to output : 64.79 seconds
2023-12-12 21:51:23,206 - root -INFO -Total amount of time taken : 64.79 seconds
2023-12-12 21:51:23,206 - root -INFO -Application done
2023-12-12 22:03:18,035 - root -INFO -i am in the main method..
2023-12-12 22:03:18,035 - root -INFO -calling spark object
2023-12-12 22:03:18,035 - Create_spark -INFO -get_spark_object method started
2023-12-12 22:03:18,035 - Create_spark -INFO -master is local
2023-12-12 22:03:21,864 - root -INFO -Validating spark object..........
2023-12-12 22:03:21,864 - Validate -WARNING -started the get_current_date method...
2023-12-12 22:03:25,079 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 22:03:25,079 - Validate -WARNING -Validation done go frwd...
2023-12-12 22:03:25,080 - root -INFO -reading file which is of > parquet
2023-12-12 22:03:25,080 - Ingest -WARNING -load_files method started...
2023-12-12 22:03:25,606 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 22:03:25,606 - root -INFO -reading file df_city : 7.57 seconds
2023-12-12 22:03:25,606 - root -INFO -displaying file df_city
2023-12-12 22:03:27,372 - root -INFO -displaying file df_city : 9.34 seconds
2023-12-12 22:03:27,372 - root -INFO -here to validate the df
2023-12-12 22:03:27,372 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 22:03:27,828 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 22:03:27,828 - root -INFO -checking for the files in the Fact...
2023-12-12 22:03:27,828 - root -INFO -reading file which is of > csv
2023-12-12 22:03:27,828 - Ingest -WARNING -load_files method started...
2023-12-12 22:03:32,318 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 22:03:32,318 - root -INFO -reading file df_fact : 14.28 seconds
2023-12-12 22:03:32,318 - root -INFO -displaying the df_fact dataframe
2023-12-12 22:03:32,586 - root -INFO -displaying file df_fact : 14.55 seconds
2023-12-12 22:03:32,586 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 22:03:33,150 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 22:03:33,150 - root -INFO -implementing data_processing methods...
2023-12-12 22:03:33,150 - Data_processing -WARNING -data_clean method started...
2023-12-12 22:03:33,151 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 22:03:33,187 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 22:03:33,206 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 22:03:33,220 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 22:03:33,258 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 22:03:33,271 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 22:03:33,283 - Data_processing -WARNING -Checking for null values...
2023-12-12 22:03:37,677 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 22:03:37,702 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 22:03:40,290 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 22:03:40,290 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 22:03:40,670 - root -INFO -implementing data_processing methods (data_clean) : 22.63 seconds
2023-12-12 22:03:40,670 - root -INFO -validating schema for the dataframes....
2023-12-12 22:03:40,670 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 22:03:40,673 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 22:03:40,673 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 22:03:40,674 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 22:03:40,674 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 22:03:40,674 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 22:03:40,674 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 22:03:40,674 - Validate -INFO -print_schema done, go frwd...
2023-12-12 22:03:40,674 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 22:03:40,677 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 22:03:40,678 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 22:03:40,678 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 22:03:40,678 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 22:03:40,678 - Validate -INFO -print_schema done, go frwd...
2023-12-12 22:03:40,678 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 22:03:40,735 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 22:03:44,595 - root -INFO - check_for_nulls : 26.56 seconds
2023-12-12 22:03:44,596 - root -INFO -data transformation executed...
2023-12-12 22:03:44,596 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 22:03:44,599 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 22:03:44,621 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 22:03:44,648 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 22:03:44,687 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 22:03:44,687 - root -INFO -displaying the df_report_1
2023-12-12 22:03:56,338 - root -INFO -displaying the df_report_1 : 38.30 seconds
2023-12-12 22:03:56,339 - root -INFO -Displaying data_report2 method....
2023-12-12 22:03:56,339 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 22:03:56,339 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 22:03:56,451 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 22:04:03,733 - root -INFO -Displaying data_report2 : 45.70 seconds
2023-12-12 22:04:03,733 - root -INFO -extracting files to output...
2023-12-12 22:04:03,733 - Extraction -WARNING -Executing extract_files method...
2023-12-12 22:04:15,433 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 22:04:15,433 - Extraction -WARNING -Executing extract_files method...
2023-12-12 22:04:22,526 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 22:04:22,527 - root -INFO -Extracting files to output completed...
2023-12-12 22:04:22,527 - root -INFO -extracting files to output : 64.49 seconds
2023-12-12 22:04:22,527 - root -INFO -Total amount of time taken : 64.49 seconds
2023-12-12 22:04:22,527 - root -INFO -Application done
2023-12-12 22:10:31,110 - root -INFO -i am in the main method..
2023-12-12 22:10:31,110 - root -INFO -calling spark object
2023-12-12 22:10:31,110 - Create_spark -INFO -get_spark_object method started
2023-12-12 22:10:31,110 - Create_spark -INFO -master is local
2023-12-12 22:10:48,107 - root -INFO -Validating spark object..........
2023-12-12 22:10:48,107 - Validate -WARNING -started the get_current_date method...
2023-12-12 22:10:51,419 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 22:10:51,419 - Validate -WARNING -Validation done go frwd...
2023-12-12 22:10:51,419 - root -INFO -reading file which is of > parquet
2023-12-12 22:10:51,419 - Ingest -WARNING -load_files method started...
2023-12-12 22:10:51,936 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 22:10:51,936 - root -INFO -reading file df_city : 20.83 seconds
2023-12-12 22:10:51,936 - root -INFO -displaying file df_city
2023-12-12 22:10:53,642 - root -INFO -displaying file df_city : 22.53 seconds
2023-12-12 22:10:53,642 - root -INFO -here to validate the df
2023-12-12 22:10:53,642 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 22:10:54,076 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 22:10:54,076 - root -INFO -checking for the files in the Fact...
2023-12-12 22:10:54,076 - root -INFO -reading file which is of > csv
2023-12-12 22:10:54,076 - Ingest -WARNING -load_files method started...
2023-12-12 22:10:58,481 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 22:10:58,481 - root -INFO -reading file df_fact : 27.37 seconds
2023-12-12 22:10:58,481 - root -INFO -displaying the df_fact dataframe
2023-12-12 22:10:58,719 - root -INFO -displaying file df_fact : 27.61 seconds
2023-12-12 22:10:58,719 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 22:10:59,277 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 22:10:59,277 - root -INFO -implementing data_processing methods...
2023-12-12 22:10:59,277 - Data_processing -WARNING -data_clean method started...
2023-12-12 22:10:59,278 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 22:10:59,306 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 22:10:59,327 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 22:10:59,337 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 22:10:59,368 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 22:10:59,382 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 22:10:59,393 - Data_processing -WARNING -Checking for null values...
2023-12-12 22:11:18,610 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 22:11:18,623 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 22:11:21,086 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 22:11:21,087 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 22:11:21,410 - root -INFO -implementing data_processing methods (data_clean) : 50.30 seconds
2023-12-12 22:11:21,410 - root -INFO -validating schema for the dataframes....
2023-12-12 22:11:21,410 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 22:11:21,411 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 22:11:21,411 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 22:11:21,411 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 22:11:21,411 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 22:11:21,411 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 22:11:21,411 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 22:11:21,411 - Validate -INFO -print_schema done, go frwd...
2023-12-12 22:11:21,411 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 22:11:21,412 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 22:11:21,412 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 22:11:21,412 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 22:11:21,413 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 22:11:21,413 - Validate -INFO -print_schema done, go frwd...
2023-12-12 22:11:21,413 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 22:11:21,501 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 22:11:39,931 - root -INFO - check_for_nulls : 68.82 seconds
2023-12-12 22:11:39,931 - root -INFO -data transformation executed...
2023-12-12 22:11:39,932 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 22:11:39,934 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 22:11:39,958 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 22:11:39,985 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 22:11:40,023 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 22:11:40,024 - root -INFO -displaying the df_report_1
2023-12-12 22:11:51,978 - root -INFO -displaying the df_report_1 : 80.87 seconds
2023-12-12 22:11:51,978 - root -INFO -Displaying data_report2 method....
2023-12-12 22:11:51,978 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 22:11:51,978 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 22:11:52,051 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 22:11:59,455 - root -INFO -Displaying data_report2 : 88.35 seconds
2023-12-12 22:11:59,457 - root -INFO -extracting files to output...
2023-12-12 22:11:59,457 - Extraction -WARNING -Executing extract_files method...
2023-12-12 22:12:11,599 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 22:12:11,600 - Extraction -WARNING -Executing extract_files method...
2023-12-12 22:12:19,197 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 22:12:19,197 - root -INFO -Extracting files to output completed...
2023-12-12 22:12:19,198 - root -INFO -extracting files to output : 108.09 seconds
2023-12-12 22:12:19,198 - root -INFO -Total amount of time taken : 108.09 seconds
2023-12-12 22:12:19,198 - root -INFO -Application done
2023-12-12 22:12:28,400 - root -INFO -i am in the main method..
2023-12-12 22:12:28,400 - root -INFO -calling spark object
2023-12-12 22:12:28,400 - Create_spark -INFO -get_spark_object method started
2023-12-12 22:12:28,400 - Create_spark -INFO -master is local
2023-12-12 22:12:31,910 - root -INFO -Validating spark object..........
2023-12-12 22:12:31,910 - Validate -WARNING -started the get_current_date method...
2023-12-12 22:12:35,045 - Validate -WARNING -Validating spark object by current date : [Row(current_date()=datetime.date(2023, 12, 12))]
2023-12-12 22:12:35,045 - Validate -WARNING -Validation done go frwd...
2023-12-12 22:12:35,047 - root -INFO -reading file which is of > parquet
2023-12-12 22:12:35,047 - Ingest -WARNING -load_files method started...
2023-12-12 22:12:35,586 - Ingest -WARNING -Dataframe created successfully which is of format : parquet
2023-12-12 22:12:35,586 - root -INFO -reading file df_city : 7.19 seconds
2023-12-12 22:12:35,586 - root -INFO -displaying file df_city
2023-12-12 22:12:37,210 - root -INFO -displaying file df_city : 8.81 seconds
2023-12-12 22:12:37,210 - root -INFO -here to validate the df
2023-12-12 22:12:37,210 - Ingest -WARNING -here to count the records in the df_city
2023-12-12 22:12:37,634 - Ingest -WARNING -number of records 28338 :: 
2023-12-12 22:12:37,634 - root -INFO -checking for the files in the Fact...
2023-12-12 22:12:37,634 - root -INFO -reading file which is of > csv
2023-12-12 22:12:37,634 - Ingest -WARNING -load_files method started...
2023-12-12 22:12:43,353 - Ingest -WARNING -Dataframe created successfully which is of format : csv
2023-12-12 22:12:43,353 - root -INFO -reading file df_fact : 14.95 seconds
2023-12-12 22:12:43,353 - root -INFO -displaying the df_fact dataframe
2023-12-12 22:12:43,728 - root -INFO -displaying file df_fact : 15.33 seconds
2023-12-12 22:12:43,728 - Ingest -WARNING -here to count the records in the df_fact
2023-12-12 22:12:44,907 - Ingest -WARNING -number of records 1329329 :: 
2023-12-12 22:12:44,907 - root -INFO -implementing data_processing methods...
2023-12-12 22:12:44,907 - Data_processing -WARNING -data_clean method started...
2023-12-12 22:12:44,907 - Data_processing -WARNING -selecting required columns and converting them to uppercase..
2023-12-12 22:12:44,967 - Data_processing -WARNING -working on oltp dataset and renaming couple of columns...
2023-12-12 22:12:45,011 - Data_processing -WARNING -ADding a new column in df_presc_sel..
2023-12-12 22:12:45,042 - Data_processing -WARNING -Replacing = in Year_of_exp and converting it into string..
2023-12-12 22:12:45,117 - Data_processing -WARNING -Concat fname and lname...
2023-12-12 22:12:45,149 - Data_processing -WARNING -Dropping fname and lname...
2023-12-12 22:12:45,165 - Data_processing -WARNING -Checking for null values...
2023-12-12 22:13:08,077 - Data_processing -WARNING -Dropping Null values in Respective columns...
2023-12-12 22:13:08,103 - Data_processing -WARNING -Fill the Null values in tax_cnt with avg values...
2023-12-12 22:13:11,259 - Data_processing -WARNING -Successfully Dropped Null values in Respective columns...
2023-12-12 22:13:11,259 - Data_processing -WARNING -data_clean method execution done , go frwd...
2023-12-12 22:13:11,722 - root -INFO -implementing data_processing methods (data_clean) : 43.32 seconds
2023-12-12 22:13:11,723 - root -INFO -validating schema for the dataframes....
2023-12-12 22:13:11,723 - Validate -WARNING -print_schema method executing...df_city_sel 
2023-12-12 22:13:11,725 - Validate -INFO -	StructField('city', StringType(), True)
2023-12-12 22:13:11,727 - Validate -INFO -	StructField('state_id', StringType(), True)
2023-12-12 22:13:11,727 - Validate -INFO -	StructField('state_name', StringType(), True)
2023-12-12 22:13:11,728 - Validate -INFO -	StructField('county_name', StringType(), True)
2023-12-12 22:13:11,728 - Validate -INFO -	StructField('population', IntegerType(), True)
2023-12-12 22:13:11,729 - Validate -INFO -	StructField('zips', StringType(), True)
2023-12-12 22:13:11,730 - Validate -INFO -print_schema done, go frwd...
2023-12-12 22:13:11,730 - Validate -WARNING -print_schema method executing...df_presc_Sel 
2023-12-12 22:13:11,735 - Validate -INFO -	StructField('presc_id', IntegerType(), True)
2023-12-12 22:13:11,736 - Validate -INFO -	StructField('presc_city', StringType(), True)
2023-12-12 22:13:11,736 - Validate -INFO -	StructField('presc_state', StringType(), True)
2023-12-12 22:13:11,736 - Validate -INFO -	StructField('presc_spclt', StringType(), True)
2023-12-12 22:13:11,736 - Validate -INFO -	StructField('drug_name', StringType(), True)
2023-12-12 22:13:11,737 - Validate -INFO -	StructField('tx_cnt', IntegerType(), True)
2023-12-12 22:13:11,737 - Validate -INFO -	StructField('total_day_supply', IntegerType(), True)
2023-12-12 22:13:11,737 - Validate -INFO -	StructField('total_drug_cost', DoubleType(), True)
2023-12-12 22:13:11,737 - Validate -INFO -	StructField('years_of_exp', IntegerType(), True)
2023-12-12 22:13:11,737 - Validate -INFO -	StructField('Country_name', StringType(), False)
2023-12-12 22:13:11,737 - Validate -INFO -	StructField('presc_fullname', StringType(), False)
2023-12-12 22:13:11,737 - Validate -INFO -print_schema done, go frwd...
2023-12-12 22:13:11,737 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-12 22:13:11,928 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-12 22:13:32,954 - root -INFO - check_for_nulls : 64.55 seconds
2023-12-12 22:13:32,954 - root -INFO -data transformation executed...
2023-12-12 22:13:32,954 - Data_transformation -WARNING -Processing data_report1 method...
2023-12-12 22:13:32,958 - Data_transformation -WARNING -Calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-12 22:13:33,007 - Data_transformation -WARNING -Calculating distinct prescribers and total tx_count...
2023-12-12 22:13:33,059 - Data_transformation -WARNING -Don't report city if no prescriber assigned to it...therefore let's join df_city_sel and df_presc_sel 
2023-12-12 22:13:33,109 - Data_transformation -WARNING -data_report1 successfully executed...
2023-12-12 22:13:33,109 - root -INFO -displaying the df_report_1
2023-12-12 22:13:47,587 - root -INFO -displaying the df_report_1 : 79.19 seconds
2023-12-12 22:13:47,588 - root -INFO -Displaying data_report2 method....
2023-12-12 22:13:47,588 - Data_transformation -WARNING -Executing data_report2 method...
2023-12-12 22:13:47,588 - Data_transformation -WARNING -Executing the task::: vonsider the prescriber only from 20 to 50 years_of_exp andrank the prescribers based on their tx_cnt for each state
2023-12-12 22:13:47,699 - Data_transformation -WARNING -data_report2 method Executed , go frwd...
2023-12-12 22:13:57,857 - root -INFO -Displaying data_report2 : 89.46 seconds
2023-12-12 22:13:57,857 - root -INFO -extracting files to output...
2023-12-12 22:13:57,858 - Extraction -WARNING -Executing extract_files method...
2023-12-12 22:14:13,029 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 22:14:13,029 - Extraction -WARNING -Executing extract_files method...
2023-12-12 22:14:23,629 - Extraction -WARNING -extract_files method successfully executed...
2023-12-12 22:14:23,630 - root -INFO -Extracting files to output completed...
2023-12-12 22:14:23,630 - root -INFO -extracting files to output : 115.23 seconds
2023-12-12 22:14:23,630 - root -INFO -Total amount of time taken : 115.23 seconds
2023-12-12 22:14:23,630 - root -INFO -Application done
